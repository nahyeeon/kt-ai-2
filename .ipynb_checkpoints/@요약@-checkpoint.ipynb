{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec11f1-d725-4f69-9547-6169fc46267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¥ì—ì„œ ë§ì´ì”€(ì„±ëŠ¥ì´ ì¢‹ê¸°ë•Œë¬¸) => RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6586a9b-b735-473d-b739-6811b33bedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params \n",
    "KNN { 'n_neighbors' : range(3,51,2), 'metric' : ['euclidean', 'manhattan']  }\n",
    "DecisionTree { 'max_depth':range(2,11), 'min_samples_leaf':range(10,101,10) }\n",
    "RandomForest { 'n_estimators':[20,50,100], 'max_features':range(1,21) }\n",
    "XGBoost {'learning_rate' : np.linspace(0.01,0.2, 20), 'n_estimators':range(60,200,20), 'max_depth':[3,4,5,6]}\n",
    "SVM { 'C' : np.linspace(0.01, 100, 50), 'gamma':[0.001,0.01,.1,1] }\n",
    "\n",
    "GridSearchCV(m, params, cv=5, scoring = 'neg_mean_absolute_error')\n",
    "XGBRegressor(objective = 'reg:squarederror')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21635a-7ffc-458a-8c3f-1153adb17a03",
   "metadata": {},
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b2fbff-8574-435a-8be6-f587fc7a189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ë¶ˆëŸ¬ì˜¤ì.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ì „ì²˜ë¦¬\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import * \n",
    "\n",
    "# ë¹„ì§€ë„ í•™ìŠµ\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c3a6c-841d-4042-bb6e-c7c3520e15f7",
   "metadata": {},
   "source": [
    "## target ë³€ìˆ˜ ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31aedfe-394b-4ab8-8096-622dad5d30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Creditability'].value_counts())\n",
    "print(data['Creditability'].value_counts()/ data.shape[0])\n",
    "\n",
    "data['Creditability'].value_counts().plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d154d6a-7f80-40dc-aa6e-c437c8391566",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cdeb5-e440-42eb-9823-186597581100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ë¶„í• 1\n",
    "target = 'Sales'\n",
    "x = data.drop(target, axis=1)\n",
    "y = data.loc[:, target]\n",
    "\n",
    "# ê°€ë³€ìˆ˜í™”\n",
    "dumm_cols = ['ShelveLoc','Education','Urban', 'US']\n",
    "x = pd.get_dummies(x, columns = dumm_cols, drop_first = True)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• 2\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.2\n",
    "                                                  , random_state = 2022)\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "scaler = MinMaxScaler()\n",
    "x_train_s = scaler.fit_transform(x_train)\n",
    "x_val_s = scaler.transform(x_val)\n",
    "\n",
    "x_train_s = pd.DataFrame(x_train_s, columns=list(x))\n",
    "x_val_s = pd.DataFrame(x_val_s, columns=list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64255320-fd98-4f20-b828-d87efa0f4db4",
   "metadata": {},
   "source": [
    "## Fitting Graph ->Elbow Method [ëª¨ë¸ê³¼ì í•©]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ec031-30e5-4a94-8c13-8a7602d610b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "* ê°€ì¥ ë‹¨ìˆœí•œ ëª¨ë¸(í‰ê· ëª¨ë¸)\n",
    "** knn : kë¥¼ ìµœëŒ€ë¡œ í¬ê²Œí•˜ë©´ í‰ê·  ëª¨ë¸ì´ ë¨.\n",
    "** kì˜ ìµœëŒ€ê°’ì€ í•™ìŠµ ë°ì´í„°ì˜ í–‰ ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe7a64-aa84-4141-8d05-a60747447be9",
   "metadata": {},
   "source": [
    "* Decision Tree\n",
    "** Decision TreeëŠ” ë‚˜ë¬´ì˜ í¬ê¸°ê°€ í´ ìˆ˜ë¡ ë³µì¡í•œ ëª¨ë¸\n",
    "** í¬ê¸°ë¥¼ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°ëŠ” max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff7702-02a6-428e-aca3-0b02b207cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ë§\n",
    "n = x_train_s.shape[0]\n",
    "model = KNeighborsRegressor(n_neighbors = n) # train setì˜ í–‰ ìˆ˜\n",
    "model.fit(x_train_s, y_train)\n",
    "pred_train = model.predict(x_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc2d5d-ca76-4a77-aaf1-45bf0b8c5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = [] # train setì„ ê°€ì§€ê³  ì˜ˆì¸¡í•œ ê²°ê³¼\n",
    "result_val = [] # val setì„ ê°€ì§€ê³  ì˜ˆì¸¡í•œ ê²°ê³¼\n",
    "k_values = list(range(1,101))\n",
    "\n",
    "# KNN\n",
    "for d in k_values :\n",
    "    model = KNeighborsClassifier(n_neighbors= d)\n",
    "    model.fit(x_train_s, y_train)\n",
    "    pred_tr, pred_val = model.predict(x_train_s), model.predict(x_val_s)\n",
    "    result_train.append(accuracy_score(y_train, pred_tr))\n",
    "    result_val.append(accuracy_score(y_val, pred_val))\n",
    "    \n",
    "result_train = [] # train setì„ ê°€ì§€ê³  ì˜ˆì¸¡í•œ ê²°ê³¼\n",
    "result_val = [] # val setì„ ê°€ì§€ê³  ì˜ˆì¸¡í•œ ê²°ê³¼\n",
    "depth = list(range(1,21))\n",
    "\n",
    "# Decision Tree\n",
    "for d in depth :\n",
    "    model = DecisionTreeClassifier(max_depth = d)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred_tr, pred_val = model.predict(x_train), model.predict(x_val)\n",
    "    result_train.append(accuracy_score(y_train, pred_tr))\n",
    "    result_val.append(accuracy_score(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b42a9-2736-410b-9789-40287fd91b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(k_values, result_train, label = 'train_acc', marker = 'o')\n",
    "plt.plot(k_values, result_val, label = 'val_acc', marker = 'o')\n",
    "\n",
    "plt.xlabel('Complexity')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beeb07e-8f9e-450f-a0c8-592fffca7cff",
   "metadata": {},
   "source": [
    "## Decision Tree[ ë³€ìˆ˜ì¤‘ìš”ë„ ê·¸ë˜í”„ ] ì‹¤ì „ì—ì„œ ë§ì´ ì”€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979c9b5-e881-45d8-91b7-1159b6e0615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ ì´ë¦„ì„ ì´ìš©í•˜ì—¬ ì‹œê°í™”\n",
    "plt.figure(figsize = (20,8)) # ê·¸ë¦¼ ì‚¬ì´ì¦ˆ ì¡°ì ˆ\n",
    "plot_tree(m3.best_estimator_, feature_names = x_train.columns, \n",
    "               class_names= ['Bad', 'Good'], filled = True, fontsize = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484790ba-8b17-43e3-bd6a-852f81a151fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names):\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    fi_df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x='feature_importance', y='feature_names', data = fi_df)\n",
    "\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    plt.grid()\n",
    "\n",
    "    return fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59b9a5-05b1-4e0a-9404-6a1de506990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(model.feature_importances_, list(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19d05d-637d-4055-8820-180621d28edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(m3.best_estimator_.feature_importances_, list(x_train)) # íŠœë‹í–ˆê¸° ë•Œë¬¸ì—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26fdad3-eb3d-4e64-bca5-4d3429b744a8",
   "metadata": {},
   "source": [
    "## Regessor ì°¨íŠ¸ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672f86a-faa5-4385-85d5-70ad9462e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠœë‹ ê³¼ì • ë¡œê·¸ë¥¼ dfë¡œ ì €ì¥ í•©ì‹œë‹¤.\n",
    "result = pd.DataFrame(m1_gs.cv_results_)\n",
    "\n",
    "# íŠœë‹ ê²°ê³¼ë¥¼ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë´…ì‹œë‹¤.\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.lineplot(x='param_max_depth', y='mean_test_score', data = result)  # plt.plot\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620285a-44ce-4fcc-8f12-eec866a79908",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR(Regressor)\n",
    "# ì´ë¥¼ ì°¨íŠ¸ë¡œ ê·¸ë ¤ë´…ì‹œë‹¤.\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.lineplot(x = 'param_C', y = 'mean_test_score', data = result, hue = 'param_gamma')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4d163-b6ec-4ec9-b50e-b91a5054114b",
   "metadata": {},
   "source": [
    "## XGB ë³€ìˆ˜ì¤‘ìš”ë„ / ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79b9a7-8b55-47a7-86c0-ad406137af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ìœ„ì—êº¼ plot_feature_importance í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cfedd-07e6-484e-b631-9e5fc4a9fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbì˜ ë³€ìˆ˜ ì¤‘ìš”ë„\n",
    "weight : ëª¨ë¸ ì „ì²´ì—ì„œ í•´ë‹¹ featureê°€ splitë  ë•Œ ì‚¬ìš©ëœ íšŸìˆ˜ì˜ í•©(plot_tree ì—ì„œì˜ ê¸°ë³¸ê°’)\n",
    "gain : featureë³„ í‰ê·  imformation gain.(model.feature_importances_ ì˜ ê¸°ë³¸ê°’)\n",
    "cover : featureê°€ split í• ë•Œì˜ ìƒ˜í”Œ ìˆ˜ì˜ í‰ê· ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf69414-2d92-4b9e-b32d-1d520116b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, plot_tree, plot_importance\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c8e9e-0bb5-4b42-a041-af290eb0af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(model.feature_importances_, list(x),6) #x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f47772-a1b8-44b5-b798-32b0f78cb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”(Treeí•˜ë‚˜ì”© ì—´ì–´ë³¼ ìˆ˜ ìˆìŒ)\n",
    "plt.rcParams['figure.figsize'] = 20,20  # íŒŒì¼ì „ì²´ì— ì˜í–¥ì„ ë¯¸ì¹¨ !!!!\n",
    "plot_tree(model, num_trees = 0) \n",
    "plt.show()\n",
    "\n",
    "# xgboost ìì²´ plot_tree í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "# plot_tree(model, num_trees = 0)\n",
    "# num_trees : ì „ì²´ íŠ¸ë¦¬ 5ê°œì§œë¦¬ ëª¨ë¸ì´ë¯€ë¡œ ê°ê° 0~4ê¹Œì§€ ì¸ë±ìŠ¤ë¡œ ì¡°íšŒí•´ ë³¼ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f2c63-94d3-4652-982d-d4bbf308f063",
   "metadata": {},
   "source": [
    "## ì„±ëŠ¥ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7fa2d-6358-4b95-b3d1-d030c05b573e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE, MAE, MAPE = [],[],[]\n",
    "model_desc = ['lr_selected', 'lr_all','knn','dt','rf','xgb','svm']\n",
    "pred = [p1, p2, p3, p4, p5, p6,p7]\n",
    "\n",
    "for i, p in enumerate(pred) :\n",
    "    RMSE.append(mean_squared_error(y_val, p, squared=False))\n",
    "    MAE.append(mean_absolute_error(y_val, p))\n",
    "    MAPE.append(mean_absolute_percentage_error(y_val, p))\n",
    "\n",
    "result = pd.DataFrame({'model_desc':model_desc,'RMSE':RMSE,'MAE':MAE,'MAPE':MAPE})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543c4d3-d6f5-415f-abb8-251ab9fec147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_val, pred1))\n",
    "print(classification_report(y_val, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921def8-9b58-4f63-94d5-5fd1579763dd",
   "metadata": {},
   "source": [
    "## Decision Tree ì‹œê°í™” ë° ë³€ìˆ˜ì¤‘ìš”ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74512328-ac56-4f62-8165-a1b739bd2c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10)) # ê·¸ë¦¼ ì‚¬ì´ì¦ˆ ì¡°ì ˆ\n",
    "plot_tree(m1, feature_names = list(x_train), \n",
    "               class_names= ['Stay', 'Leave'], filled = True, fontsize = 10);  # class_names = [targetì˜ ë‚´ìš©]\n",
    "plt.show()\n",
    "print('-'*88)\n",
    "# ë³€ìˆ˜ ì¤‘ìš”ë„\n",
    "print(list(x_train))\n",
    "print(m1.feature_importances_)\n",
    "print('-'*88)\n",
    "print(classification_report(y_val, p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eaf2ba-8169-49c1-ab4e-c2503d7049fe",
   "metadata": {},
   "source": [
    "## ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ìœ„í•œ ì „ì§„ì„ íƒë²• í•¨ìˆ˜ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f321f-66db-420b-80f0-047e9d7bad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "\n",
    "def forward_stepwise_linear(x_train, y_train):\n",
    "\n",
    "    # ë³€ìˆ˜ëª©ë¡, ì„ íƒëœ ë³€ìˆ˜ ëª©ë¡, ë‹¨ê³„ë³„ ëª¨ë¸ê³¼ AIC ì €ì¥ì†Œ ì •ì˜\n",
    "    features = list(x_train)\n",
    "    selected = []\n",
    "    step_df = pd.DataFrame({ 'step':[], 'feature':[],'aic':[]})\n",
    "\n",
    "    # \n",
    "    for s in range(0, len(features)) :\n",
    "        result =  { 'step':[], 'feature':[],'aic':[]}\n",
    "\n",
    "        # ë³€ìˆ˜ ëª©ë¡ì—ì„œ ë³€ìˆ˜ í•œê°œì”© ë½‘ì•„ì„œ ëª¨ë¸ì— ì¶”ê°€\n",
    "        for f in features :\n",
    "            vars = selected + [f]\n",
    "            x_tr = x_train[vars]\n",
    "            model = OLS(y_train, add_constant(x_tr)).fit(disp=False)\n",
    "            result['step'].append(s+1)\n",
    "            result['feature'].append(vars)\n",
    "            result['aic'].append(model.aic)\n",
    "        \n",
    "        # ëª¨ë¸ë³„ aic ì§‘ê³„\n",
    "        temp = pd.DataFrame(result).sort_values('aic').reset_index(drop = True)\n",
    "\n",
    "        # ë§Œì•½ ì´ì „ aicë³´ë‹¤ ìƒˆë¡œìš´ aic ê°€ í¬ë‹¤ë©´ ë©ˆì¶”ê¸°\n",
    "        if step_df['aic'].min() < temp['aic'].min() :\n",
    "            break\n",
    "        step_df = pd.concat([step_df, temp], axis = 0).reset_index(drop = True)\n",
    "\n",
    "        # ì„ íƒëœ ë³€ìˆ˜ ì œê±°\n",
    "        v = temp.loc[0,'feature'][s]\n",
    "        features.remove(v)\n",
    "\n",
    "        selected.append(v)\n",
    "    \n",
    "    # ì„ íƒëœ ë³€ìˆ˜ì™€ step_df ê²°ê³¼ ë°˜í™˜\n",
    "    return selected, step_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64df06-f8e2-4d8a-b2ef-97d362534801",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars, result = forward_stepwise_logistic(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0df5b-343a-4271-9877-0ac0cef5ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ íƒëœ ë³€ìˆ˜\n",
    "lr_m1 = LinearRegression()\n",
    "lr_m1.fit(x_train[vars], y_train)\n",
    "p1 = lr_m1.predict(x_val[vars])\n",
    "\n",
    "print('RMSE : ', mean_squared_error(y_val, p1, squared=False))\n",
    "print('MAE  : ', mean_absolute_error(y_val, p1))\n",
    "print('MAPE : ', mean_absolute_percentage_error(y_val, p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf20d7b-664d-4370-8e00-55b8e409fb21",
   "metadata": {},
   "source": [
    "## cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c24999-fa58-4b07-b323-450de6a1323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# train + validation setì„ ì´ìš©í•˜ì—¬ í•™ìŠµ, ì˜ˆì¸¡, í‰ê°€ë¥¼ í•œë²ˆì—. (ì—¬ê¸°ì„œëŠ” .fit ì´ ì•„ë‹˜!)\n",
    "dt_result = cross_val_score(model, x, y, cv=10)\n",
    "print(dt_result)\n",
    "print(dt_result.mean(), dt_result.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0876d-960f-44ea-b0a5-8a2acb251549",
   "metadata": {},
   "source": [
    "## Permutation Feature Importance(ê·¸ ì™¸ ë³€ìˆ˜ì¤‘ìš”ë„ ê·¸ë˜í”„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd55a3-cfe5-4fcb-ace0-1b399f315a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d30d2c-6d7c-4780-9492-1a021fc4c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfi1 = permutation_importance(model4, x_val_s, y_val, n_repeats=10, scoring = 'r2', random_state=2022)\n",
    "# scoring = 'accuracy' default[ë¶„ë¥˜ ëª¨ë¸]\n",
    "# deep learning ëª¨ë¸ì— ëŒ€í•´ì„œëŠ” ëª…ì‹œì ìœ¼ë¡œ scoring = 'r2'ì„ ì§€ì •í•´ í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58147e8f-a372-4b2c-a951-7df3e66ce309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureë³„ Score ë¶„í¬\n",
    "plt.figure(figsize = (10,8))\n",
    "for i,vars in enumerate(list(x)) :\n",
    "    sns.kdeplot(pfi1.importances[i], label = vars)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820c5a2-0ff6-4c62-b698-2feac8aa0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = pfi1.importances_mean.argsort()\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.boxplot(pfi1.importances[sorted_idx].T, vert=False, labels=x.columns[sorted_idx])\n",
    "plt.axvline(0, color = 'r')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d3e93-fd33-4813-b864-ad186951fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê· ê°’ìœ¼ë¡œ ë³€ìˆ˜ì¤‘ìš”ë„ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
    "pfi1 = permutation_importance(model1, x_val_s, y_val, n_repeats=10, scoring = 'r2', random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc70a2-80be-4adf-a371-f3b0cd35c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ìˆ˜ ì¤‘ìš”ë„ plot(ê°€ì ¸ì˜¤ê¸°)\n",
    "result = plot_feature_importance(pfi1.importances_mean, list(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa99e68-a6f0-4011-b165-60185b89f33d",
   "metadata": {},
   "source": [
    "## Partial Dependence Plot(ê°œë³„ ë³€ìˆ˜ë³„ ê´€ê³„)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25612daa-29b7-4292-a14c-4f611064b304",
   "metadata": {},
   "source": [
    "* ë³€ìˆ˜ ì¤‘ìš”ë„,PDP : train ë°ì´í„°ë¡œ ì‚´í´ë³´ëŠ” ê²ƒì´ ê¸°ë³¸ì´ë‹¤. ê·¸ë¦¬ê³  ê²°ê³¼ê°€ ìœ ì‚¬í•´ì•¼ í•œë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524504e-98c0-4b99-85f4-ddc30f355d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence, partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b994514-5ba4-44e8-8c6f-d3514006025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë³„ ë³€ìˆ˜ ë¶„ì„\n",
    "var = 'MonthlyIncome'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "plot_partial_dependence(model, features = [var], X = x_val)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac85a3e-a9a0-407d-9b5a-5b6c28609b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ë°ì´í„°ë¡œ í™•ì¸\n",
    "var = 'MonthlyIncome'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12, 8\n",
    "plot_partial_dependence(model, features = [var], X = x_val, kind = 'both') #kind = 'average'\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35f900-19bf-48d5-b435-3be786601d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘ê°œ ë³€ìˆ˜ ë¹„êµ\n",
    "plot_partial_dependence(model, features = ['rm','lstat'], X = x_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9cea2-ca6a-4260-8783-c65510ac347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘ê°œ ë³€ìˆ˜ ë¹„êµ\n",
    "plot_partial_dependence(model2, features = [('CreditAmount','Age')], X = x_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13acb0-6d39-4e2f-a7ad-b98442f5d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤ì¼€ì¼ë§í•œê±° ë°ì´í„° í”„ë ˆì„ì— ë„£ì–´ì„œ ë½‘ì•„ì•¼í•¨\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = list(x))  # ì¹¼ëŸ¼ì´ë¦„ ì§€ì • í•„ìš”!!\n",
    "x_val_s = pd.DataFrame(x_val_s, columns = list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd92fd6-e143-48c7-839e-96ab575b40ff",
   "metadata": {},
   "source": [
    "## SHAP ê°’ìœ¼ë¡œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„¤ëª…í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bd8b4-529c-4568-a7e7-b8167cbef6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ í˜•íšŒê·€ëŠ” íšŒê·€ê³„ìˆ˜ë¡œ ë³€ìˆ˜ ê¸°ì—¬ë„ í•´ì„í•´ë„ ë¬´ë°©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd050132-df09-4291-bc29-658ad30df832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (íšŒê·€ëª¨ë¸)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer1.shap_values(x_train)\n",
    "\n",
    "# (ë¶„ë¥˜ëª¨ë¸)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777c0f6-5481-49e9-a1d9-5dcce0d4076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„œëŠ” ì…ë ¥ë°ì´í„°(x)ê°€ 2ì°¨ì›ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "pred = model1.predict(x_train.iloc[0:1,:])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361de6de-deb7-4cf6-8ce8-6f1a3a522cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainì˜ í‰ê· (íšŒê·€)\n",
    "explainer1.expected_value\n",
    "\n",
    "# trainì˜ í‰ê· (ë¶„ë¥˜)\n",
    "explainer1.expected_value[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9a1ae-2275-452e-b6c6-567d2b419c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ë±ìŠ¤ë³„ ë°ì´í„°\n",
    "shap.initjs() # javascript ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ --> colabì—ì„œëŠ” ëª¨ë“  ì…€ì— í¬í•¨ì‹œì¼œì•¼ í•¨.-> ì•„ë‚˜ì½˜ë‹¤ì—ì„œëŠ” í•œë²ˆë§Œ !\n",
    "index=371\n",
    "# force_plot(ì „ì²´í‰ê· , shapley_values, input)\n",
    "shap.force_plot(explainer1.expected_value, shap_values1[index,:], x.iloc[index,:])\n",
    "\n",
    "# ë¶„ë¥˜ëª¨ë¸\n",
    "shap.initjs() # javascript ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ --> colabì—ì„œëŠ” ëª¨ë“  ì…€ì— í¬í•¨ì‹œì¼œì•¼ í•¨.-> ì•„ë‚˜ì½˜ë‹¤ì—ì„œëŠ” í•œë²ˆë§Œ !\n",
    "index=932\n",
    "# force_plot(ì „ì²´í‰ê· , shapley_values, input)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][index,:], x.iloc[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a1d2a-6bf7-46e5-86da-61fda96261e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ë°ì´í„°\n",
    "shap.initjs() # javascript ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ --> colabì—ì„œëŠ” ëª¨ë“  ì…€ì— í¬í•¨ì‹œì¼œì•¼ í•¨.-> ì•„ë‚˜ì½˜ë‹¤ì—ì„œëŠ” í•œë²ˆë§Œ !\n",
    "\n",
    "# force_plot(ì „ì²´í‰ê· , shapley_values, input)\n",
    "shap.force_plot(explainer1.expected_value, shap_values1[0, :], x_train.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf225d-cdd8-4e25-a11e-d96ef4fadca5",
   "metadata": {},
   "source": [
    "## class balanceë¥¼ ë§ì¶”ê¸° ìœ„í•œ resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f098a68-04d1-45a1-9473-e893b5fca852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3a8f7-42da-4cb1-a3b2-a0d0644bf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a0459-dca1-4b10-9c53-79827e1a9fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ë¹„ì§€ë„ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b59d6-b431-4063-9d80-7500cf3a167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1,50)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(mobile_x)\n",
    "    inertias.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bcac3-b88c-456d-b8d6-846b97a4e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34af48-e397-48a1-aaa7-c27279a6a29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ë§[KNN]\n",
    "model = KMeans(n_clusters=5)\n",
    "model.fit(mobile_x)\n",
    "pred = model.predict(mobile_x)\n",
    "pred = pd.DataFrame(pred, columns = ['predict'])\n",
    "# ê²°ê³¼ ë³´ê¸°\n",
    "mobile_y.reset_index(inplace=True, drop=True)\n",
    "result = pd.concat([mobile_x, mobile_y, pred], axis =1)\n",
    "result.CHURN = result.CHURN.astype('int')\n",
    "# í´ëŸ¬ìŠ¤í„° ë³„ ê³ ê°ì´íƒˆìœ¨\n",
    "result.groupby('predict')['CHURN'].mean()\n",
    "# ì „ì²´ í‰ê· \n",
    "result['CHURN'].value_counts() / result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e88bc6-48aa-43a0-bf61-6195f7628f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN ëª¨ë¸ì„ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.\n",
    "model = DBSCAN(eps=0.1, min_samples=3)\n",
    "model.fit(x)\n",
    "# fittingí•œ í›„ì— ëª¨ë¸ì˜ labels_ ê°’ì´ ì°¾ì•„ë‚¸ êµ°ì§‘ ì¢…ë¥˜ì…ë‹ˆë‹¤.\n",
    "clusters = model.labels_\n",
    "# êµ°ì§‘ ë²ˆí˜¸ ì¤‘ -1ì€ ì´ìƒì¹˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.(ì–´ëŠ êµ°ì§‘ì—ë„ í¬í•¨ ì•ˆë˜ëŠ” ê°’ë“¤!)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126cc2cd-68ba-4e0c-b45f-2cf050a208b6",
   "metadata": {},
   "source": [
    "## ì‹œê³„ì—´ ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359fee4-1fa7-45ce-94c0-0b540f19c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1b49b-b28b-4008-b77d-f1ef70702d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target ì‹œê³„ì—´ë¡œ í™•ì¸ \n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(data['sales'])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "temp = data[-100:]\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(temp['sales'], marker ='o')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa23b2-c179-4c13-a838-d655a9e750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì”ì°¨ ë¶„ì„\n",
    "def residual_diag(residuals, lags = 20) :\n",
    "\n",
    "    print('* ì •ê·œì„± ê²€ì •(> 0.05) : ', round(spst.shapiro(residuals)[1],5))\n",
    "    print('* ì •ìƒì„± ê²€ì •(< 0.05) : ', round(sm.tsa.stattools.adfuller(residuals)[1],5))\n",
    "    print('* ìê¸°ìƒê´€ì„± í™•ì¸(ACF, PACF)')\n",
    "    fig,ax = plt.subplots(1,2, figsize = (15,5))\n",
    "    plot_acf(residuals, lags = lags, ax = ax[0])\n",
    "    plot_pacf(residuals, lags = lags, ax = ax[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733fa1d-5bec-493d-98c1-78d906b7dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚ ì§œ íƒ€ì…ìœ¼ë¡œ ë³€ê²½\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "# ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜\n",
    "data['DT'] = data['date']\n",
    "data.set_index('DT', inplace=True)\n",
    "data.head()\n",
    "## ë‚ ì§œë‹¨ìœ„ ì§€ì •í•˜ê¸° : freq / ì¸ë±ìŠ¤ ì¡°íšŒì‹œ, ë§ˆì§€ë§‰ì— ìˆëŠ” freq ì˜µì…˜\n",
    "# ì¼ë‹¨ìœ„\n",
    "data.asfreq('D').head()\n",
    "# ì›”(ë§)ë‹¨ìœ„\n",
    "data.asfreq('M').head()\n",
    "# ì›”ì´ˆ ë‹¨ìœ„\n",
    "data.asfreq('MS').head()\n",
    "#(ì¶”ê°€) ë¹ ì§„ê°’ ì°¾ê¸°\n",
    "temp = data.asfreq('D')\n",
    "temp.isna().sum()\n",
    "# ì±„ìš°ê¸°\n",
    "data.asfreq('D', method = 'ffill')\n",
    "df = data.asfreq('D') # ì¼ë‹¨ìœ„ ë°ì´í„°ì´ë¯€ë¡œ ì´ê±¸ë¡œ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c782bfe-33b8-4ed8-ba1e-14cd98bc0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y ë§Œë“¤ê¸°\n",
    "df['y'] = df['sales'].shift(-1)\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "# ì œì¼ ë§ˆì§€ë§‰ í–‰ì€ ì‚­ì œ\n",
    "df.dropna(axis = 0, inplace = True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077b5ee-bae1-4267-9902-c3c237830513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„í• \n",
    "# 1) x, y ë‚˜ëˆ„ê¸°\n",
    "# .values(ë„˜íŒŒì´ ì–´ë ˆì´)ë¡œ ë³€í™˜í•´ì„œ ì €ì¥í•˜ëŠ” ì´ìœ  â¡ ë°ì´í„° ìŠ¤í”Œë¦¿ indexë¥¼ ì ìš©í•´ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ì„œ\n",
    "target = 'y'\n",
    "\n",
    "x = df.drop([target, 'date'], axis = 1)\n",
    "y = df.loc[:, target]\n",
    "\n",
    "# ì‹œê³„ì—´ ë°ì´í„° ë¶„í• \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "x.shape\n",
    "# validation set size\n",
    "val_size = 30\n",
    "nfold = 3\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = nfold, test_size = val_size)\n",
    "tscv\n",
    "\n",
    "#ì°¸ì¡°\n",
    "# .splitì„ ì´ìš©í•˜ì—¬ fold í•˜ë‚˜ì”© ì¸ë±ìŠ¤ë“¤ì„ ë½‘ì•„ ë‚¼ ìˆ˜ ìˆìŒ.\n",
    "for train_index, val_index in tscv.split(x):\n",
    "    print(\"Train:\", train_index, \"Val:\", val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7509d9-02fa-4c4d-9963-d83d88be275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ë§\n",
    "# loop ëŒë©° ëª¨ë¸ë§(cross-validation) ìˆ˜í–‰\n",
    "rmse, mae, mape = [],[],[]\n",
    "residuals = []\n",
    "pred = []\n",
    "model = LinearRegression()\n",
    "\n",
    "for train_index, val_index in tscv.split(x):\n",
    "\n",
    "    # ì¸ë±ìŠ¤ë¡œ ë°ì´í„° ë¶„í• \n",
    "    x_train, y_train = x.iloc[train_index], y.iloc[train_index]\n",
    "    x_val, y_val = x.iloc[val_index], y.iloc[val_index]\n",
    "\n",
    "    # í•™ìŠµ\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # ì˜ˆì¸¡\n",
    "    pr = model.predict(x_val)\n",
    "    pred += list(pr)\n",
    "\n",
    "    # í‰ê°€\n",
    "    rmse.append(mean_squared_error(y_val, pr, squared = False))\n",
    "    mae.append(mean_absolute_error(y_val, pr))\n",
    "    mape.append(mean_absolute_percentage_error(y_val, pr))\n",
    "\n",
    "    # ì”ì°¨ : ê° foldì˜ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€\n",
    "    residuals += list(y_val - pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969db4bd-ac0c-4fbb-adb9-1e023faaf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€\n",
    "print('RMSE : ',round(np.mean(rmse),4))\n",
    "print('MAE  : ',round(np.mean(mae),4))\n",
    "print('MAPE : ',round(np.mean(mape),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ccda9-2ee3-442d-aa60-215ffc227846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ë¹„êµ\n",
    "n = val_size * nfold\n",
    "pred = pd.Series(pred, index = y[-n:].index)\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(y[:-n], label = 'train')\n",
    "plt.plot(y[-n:], label = 'val')\n",
    "plt.plot(pred, label = 'predicted')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(y[-n:], label = 'val')\n",
    "plt.plot(pred, label = 'predicted')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6b063-297d-4b19-90ca-b535597d6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€: ì”ì°¨ë¶„ì„\n",
    "## ì‹œê°í™”\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, color = 'r', ls = '--')\n",
    "plt.axhline(np.mean(residuals), color = 'g', ls = '--')\n",
    "plt.show()\n",
    "\n",
    "## ACF, PACF(ìê¸°ìƒê´€ì„± ì—¬ë¶€ í™•ì¸)\n",
    "lags = 20\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize = (15,5))\n",
    "plot_acf(residuals, lags = lags, ax = ax[0])\n",
    "plot_pacf(residuals, lags = lags, ax = ax[1])\n",
    "plt.show()\n",
    "\n",
    "## ê²€ì •\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "stats.shapiro(residuals)[1]  # ì •ê·œì„± ê²€ì • : Shapiro-Wilk ê²€ì •\n",
    "sm.tsa.stattools.adfuller(residuals)[1]  # ì •ìƒì„± ê²€ì • : ADF ê²€ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21e45a-b164-4278-96bb-e2922bb8410f",
   "metadata": {},
   "source": [
    "## ì‹œê³„ì—´ ëª¨ë¸ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a079f9-4e0d-49d0-b774-c97f26ab228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "def plot_model_result(y_train, y_val, pred) :\n",
    "    pred = pd.Series(pred, index = y_val.index)\n",
    "\n",
    "    # ì „ì²´ ì‹œê°í™”\n",
    "    plt.figure(figsize = (20,12))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(y_train, label = 'train')\n",
    "    plt.plot(y_val, label = 'val')\n",
    "    plt.plot(pred, label = 'pred')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(y_val, label = 'val')\n",
    "    plt.plot(pred, label = 'pred')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9739f4e-d804-4514-9beb-94847e7120d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yê°’ ì‚´í´ë³´ê¸°\n",
    "residual_diag(y_train, lags = 30)\n",
    "\n",
    "# ARIMA ëª¨ë¸ë§\n",
    "m1_1 = sm.tsa.SARIMAX(y_train, order=(1,0,1)).fit() # ARMA\n",
    "m1_2 = sm.tsa.SARIMAX(y_train, order=(1,1,1)).fit() # ARIMA\n",
    "\n",
    "# SARIMA ëª¨ë¸ë§ : P, D, Q, m = 1,1,1,7 ë¡œ ëª¨ë¸ì„ ìƒì„±í•©ì‹œë‹¤.\n",
    "m2_1 = sm.tsa.SARIMAX(y_train, order=(5,1,4), seasonal_order=(1,1,1,7)).fit()\n",
    "\n",
    "m3_1 = sm.tsa.SARIMAX(y_train, order=(5,1,4), seasonal_order=(1,1,1,7), exog=x_train).fit()\n",
    "\n",
    "# í‰ê°€[ì”ì°¨ ì§„ë‹¨]\n",
    "residuals = m1_1.resid  # y_trainê³¼ ì˜ˆì¸¡ê°’ ì°¨ì´\n",
    "residual_diag(residuals)\n",
    "# í‰ê°€[AIC] ->ì„ í˜• ëª¨ë¸ì—ì„œì˜ ì í•©ë„ì™€, featureê°€ ê³¼ë„í•˜ê²Œ ëŠ˜ì–´ë‚˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ë„ë¡ ì„¤ê³„ëœ í†µê³„ëŸ‰ì´ AIC ì…ë‹ˆë‹¤.\n",
    "# ê°’ì´ ì‘ì„ ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸\n",
    "# ê³µì‹ : ğ´ğ¼ğ¶=âˆ’2 lnâ¡(ğ¿)+2ğ‘˜ â¡ - ëª¨ë¸ì˜ ì í•©ë„ + ë³€ìˆ˜ì˜ ê°¯ìˆ˜\n",
    "print('model1 AIC :', m1_1.aic)\n",
    "# í‰ê°€[Validation]\n",
    "pred = m1_1.forecast(30)   # SARIMAX ëª¨ë¸ì„ ìƒì„±í•˜ê³ , ì˜ˆì¸¡í•  ë•ŒëŠ” exog=x_val ì˜µì…˜ì´ ë“¤ì–´ê°€ì•¼ í•¨. \n",
    "print('MAE :', mean_absolute_error(y_val, pred))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_val, pred))\n",
    "# í‰ê°€[ê²°ê³¼ ì‹œê°í™”]\n",
    "plot_model_result(y_train, y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc011a5-ea27-4a08-bce6-dd151e82c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "# í•™ìŠµ\n",
    "from itertools import product\n",
    "# product í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ê°’ì˜ ì¡°í•©ì„ êµ¬ì„±\n",
    "p = [1,2,3,4,5]\n",
    "q = [1,2,3,4,5]\n",
    "d = [1]\n",
    "iter = list(product(p,d,q))\n",
    "iter\n",
    "\n",
    "# íŠœë‹ \n",
    "mae, aic = [],[]\n",
    "for i in iter :\n",
    "    model_fit = sm.tsa.SARIMAX(y_train, order=(i[0],i[1],i[2])).fit()\n",
    "    pred = model_fit.forecast(30)\n",
    "    mae.append( mean_absolute_error(y_val, pred))\n",
    "    aic.append(model_fit.aic)\n",
    "    print(i)\n",
    "    \n",
    "result = pd.DataFrame({'params(p,d,q)' : iter, 'mae' : mae, 'aic':aic})\n",
    "\n",
    "display(result.loc[result['mae'] == result.mae.min()])\n",
    "display(result.loc[result['aic'] == result.aic.min()])\n",
    "\n",
    "# ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ p, d, q ê°’ìœ¼ë¡œ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "m1_3 = sm.tsa.SARIMAX(y_train, order=(5,1,4)).fit()\n",
    "\n",
    "# í‰ê°€[ì”ì°¨ì§„ë‹¨]\n",
    "residuals = m1_3.resid\n",
    "residual_diag(residuals) # seasonallity \n",
    "# í‰ê°€[AIC]\n",
    "print('model2 AIC :', m1_3.aic)\n",
    "# í‰ê°€[validation]\n",
    "p1 = m1_3.forecast(30)\n",
    "print('MAE :', mean_absolute_error(y_val, p1))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_val, p1))\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "plot_model_result(y_train, y_val, p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841415ba-a113-49b3-a213-0f2df244b0af",
   "metadata": {},
   "source": [
    "## ë”¥ëŸ¬ë‹[keras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63aa4c-1211-43fd-a84b-c6ffb57254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ad5b2-0eec-4277-8908-5af216a9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape , y.shape  # í™•ì¸í•´ë³¼ê²ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9d68f-a6f4-4763-8fef-6d406055849b",
   "metadata": {},
   "source": [
    "* Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56367fdb-b8cf-4b4b-b174-7834b14485f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Linear Regression]\n",
    "# í˜¹ì‹œ ì´ë¯¸ ê·¸ë ¤ë‘” ê·¸ë˜í”„ê°€ ìˆë‹¤ë©´ ë‚ ë ¤ì¤˜!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# ë ˆì´ì–´ë“¤ì„ ì‚¬ìŠ¬ë¡œ ì—°ê²°í•˜ ë“¯ì´ ì—°ê²°!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "# ëª¨ë¸ì˜ ì‹œì‘ê³¼ ëì„ ì§€ì •\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(model.predict(x).reshape(-1,) )\n",
    "\n",
    "@ [Logistic Regression]\n",
    "keras.backend.clear_session()\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(input_layer)\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb0919-cb10-4b52-b673-e043cccdd6c2",
   "metadata": {},
   "source": [
    "* Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67fd5e0-82fb-42c9-a314-9715ab7552b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Linear Regression]\n",
    "# 1ë²ˆ ì²­ì†Œ : ì´ë¯¸ ë§Œë“¤ì–´ì§„ ëª¨ë¸ì´ ìˆë‹¤ë©´ ê·¸ ëª¨ë¸ì„ ì—†ì• ì¤˜\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 2ë²ˆ ëª¨ë¸ ì„ ì–¸\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# 3ë²ˆ ëª¨ë¸ ë¸”ë¡ ì¡°ë¦½\n",
    "model.add( keras.layers.Input(shape=(1,)) )\n",
    "model.add( keras.layers.Dense(1) )\n",
    "\n",
    "## ì˜¤ë¦¬ì§€ë„ Sequential API\n",
    "# model.add( keras.layers.Dense(1, input_shape=(1,)) )\n",
    "\n",
    "# 4ë²ˆ ì»´íŒŒì¼ \n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(x[:15], y[:15], epochs=10, verbose=1)\n",
    "print(y[15:])\n",
    "print(model.predict(x[15:]))\n",
    "\n",
    "@ [Logistic Regression]\n",
    "# í˜¹ì‹œ ì´ë¯¸ ê·¸ë ¤ë‘” ê·¸ë˜í”„ê°€ ìˆë‹¤ë©´ ë‚ ë ¤ì¤˜!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# modelì— ìˆœì°¨ì ìœ¼ë¡œ ë ˆì´ì–´ë¥¼ ìŒ“ì•„ê°€ê² ë‹¤ëŠ” ì˜ë„!\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# modelì— ì¸í’‹ ê°’ì„ ë°›ëŠ” ë ˆì´ì–´ë¥¼ ë„£ìŒ\n",
    "model.add( keras.layers.Input(shape=(1,)) )\n",
    "# modelì— Dense ë ˆì´ì–´ë¥¼ ë„£ì„ê±°ì•¼ (ìµœì´ˆì˜ ë ˆì´ì–´) : weightë¥¼ ê³±í•˜ê³ , biasë¥¼ ë”í•´ì£¼ëŠ” ê³¼ì •\n",
    "model.add( keras.layers.Dense(1, activation='sigmoid') )\n",
    "\n",
    "# ì˜¤ë¦¬ì§€ë„ Sequential API\n",
    "# model.add( keras.layers.Dense(1, input_shape=(1,), activation='sigmoid') )\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "# keras.losses.binary_crossentropy ì´ê±¸ë¡œë„ ê°€ëŠ¥\n",
    "\n",
    "model.fit(x[:15], y[:15], epochs=10, verbose=1)\n",
    "print(y[15:])\n",
    "print(model.predict(x[15:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91289ec3-9fbe-42a4-bb08-76d33084e753",
   "metadata": {},
   "source": [
    "* ë©€í‹°í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60420175-9abb-4a4d-aa65-a20f60569a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¯¸ë˜ ë°ì´í„°ë¥¼ ë¨¼ì œ ë–¼ì–´ë‚´ì•¼í•˜ê¸° ë•Œë¬¸ì— ë¨¼ì € ë¶„ë¦¬í•´ì¤€ë‹¤.(ë¯¸ë˜ë°ì´í„°ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠëŠ”ë‹¤)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.2, random_state=2022)\n",
    "x_train.shape, y_train.shape\n",
    "# One-Hot Encoding  (get_dummies= xì—ë§Œ ì ìš©)\n",
    "class_n = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, class_n)\n",
    "y_test = to_categorical(y_test, class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e62134-a6df-4a34-bd32-92d177f7835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ y í™•ì¸í•˜ê¸°\n",
    "iris.target_names\n",
    "\n",
    "# One-Hot Encoding  (get_dummies= xì—ë§Œ ì ìš©)\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "y = to_categorical(y, 3) # ë°˜ë³µ ì‹¤í–‰ ì£¼ì˜!!(ê³„ì† ìƒì„±ë¨)\n",
    "x.shape, y.shape\n",
    "\n",
    "@ [Sequential]\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(4,)))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,verbose=1)\n",
    "model.predict(x_test).reshape(-1)\n",
    "y.argmax(axis=1)\n",
    "\n",
    "@ [Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(4,))\n",
    "ol = keras.layers.Dense(3,activation='softmax')(il)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "model.fit(x_train,y_train,epochs=10, verbose=1)\n",
    "pred = model.predict(x_test)\n",
    "pred[:5] # í•©ì¹˜ë©´ í™•ë¥ ê°’ =1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b4936-56b0-4659-a35c-f24f016b555f",
   "metadata": {},
   "source": [
    "* Hidden layer ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab5d1f-3c3d-4be5-80ae-f6c1a261c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Sequential API]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(13,)))\n",
    "model.add(keras.layers.Dense(32,activation='relu'))\n",
    "model.add(keras.layers.Dense(32,activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "@ [Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(30,))\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden1')(il)\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden2')(hl)\n",
    "ol = keras.layers.Dense(1,activation='sigmoid')(hl)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "@ [multi-Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(4,))\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden1')(il)\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden2')(hl)  # ë³€ìˆ˜ëª… ê°™ì•„ë„ ìƒê´€ì—†ìŒ\n",
    "ol = keras.layers.Dense(3,activation='softmax')(hl)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " # optimizer=keras.optimizers.Adam(0.01)-> eta\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066a064-fb8b-457c-93af-792304ffbdb9",
   "metadata": {},
   "source": [
    "## ë”¥ëŸ¬ë‹[ANN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6361238-7234-4dd4-937c-62c28c1ad4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì°¸ì¡°ì½”ë“œ\n",
    "'''\n",
    "matplolib inline ëª…ë ¹ì–´ë¥¼ í†µí•´ì„œ\n",
    "matplotìœ¼ë¡œ ê·¸ë¦¬ëŠ” í”Œë¡¯ë“¤ì„ ì£¼í”¼í„° ë…¸íŠ¸ë¶ ë‚´ì—ì„œ ë³¼ ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤.\n",
    "í¬ë§·ì„ retinaë¡œ ë°”ê¾¸ë©´ ê·¸ë˜í”„ì˜ í™”ì§ˆì´ í›¨ì”¬ ì¢‹ì•„ì§„ë‹¤.\n",
    "'''\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20445e-b94f-47b6-b20a-c81a42dedc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) ì „ì²˜ë¦¬\n",
    "x = wine.data\n",
    "y = wine.target\n",
    "x.shape, y.shape\n",
    "data.target_names\n",
    "\n",
    "## reshape -> flattení•˜ë©´ í•„ìš”ì—†ìŒ\n",
    "train_x.shape\n",
    "train_x = train_x.reshape([train_x.shape[0],-1])\n",
    "test_x = test_x.reshape([test_x.shape[0],-1])\n",
    "train_x.shape # 28*28\n",
    "## min-max scaling\n",
    "max_n, min_n = train_x.max(), train_x.min()\n",
    "max_n, min_n\n",
    "train_x = (train_x - min_n) / (max_n - min_n)\n",
    "test_x = (test_x - min_n) / (max_n - min_n)\n",
    "print(f'max : {train_x.max()} / min : {train_x.min()}')\n",
    "## target feature : One-hot Encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "len_y = len(set(train_y))\n",
    "train_y = to_categorical(train_y, len_y)\n",
    "test_y = to_categorical(test_y, len_y)\n",
    "\n",
    "2) ëª¨ë¸ë§\n",
    "train_x.shape, train_y.shape\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(train_x.shape[1]))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.01),metrics='accuracy')\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss',  # ë¬´ì–¼ ê´€ì°°í• ì§€(ê´€ì¸¡ëŒ€ìƒ)\n",
    "                   min_delta=0,         # ìµœì†Œí•œ ë‚˜ë¹ ì§€ì§€ ì•Šìœ¼ë©´ ê´œì°®ì•„\n",
    "                   patience=5,          # ì¤‘ìš”! ëª‡ë²ˆì´ë‚˜ ì°¸ì„ì§€(ê±°ê¸°ê¹Œì§€ ê°œì„  ì•ˆë˜ë©´ ë©ˆì¶œê±°ì•¼)\n",
    "                   verbose=1,            \n",
    "                   restore_best_weights=True)  # (ë°˜ë“œì‹œ ì‚¬ìš©)í•™ìŠµì´ ë©ˆì·„ì„ ë•Œ, ìµœì ì˜ ê°€ì¤‘ì¹˜ë¡œ ì „í™˜í•´ì¤Œ\n",
    "model.fit(train_x, train_y, \n",
    "          validation_split=0.2,  # Train dataì˜ 20%ë¥¼ Validation dataë¡œ!\n",
    "          callbacks=[es],        # Early Stopping ì ìš©\n",
    "          verbose=1, epochs=50)\n",
    "\n",
    "3) ì˜ˆì¸¡\n",
    "pred_train = model.predict(train_x)\n",
    "pred_test = model.predict(test_x)\n",
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_test = pred_test.argmax(axis=1)\n",
    "logi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\n",
    "logi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n",
    "print('íŠ¸ë ˆì´ë‹ ì •í™•ë„ : {:.2f}%'.format(logi_train_accuracy*100))\n",
    "print('í…ŒìŠ¤íŠ¸ ì •í™•ë„ : {:.2f}%'.format(logi_test_accuracy*100))\n",
    "\n",
    "4) í™•ì¸\n",
    "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "for i, index in enumerate(np.random.choice(test_x.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(test_x[index].reshape([28,-1])), cmap='gray' )\n",
    "    \n",
    "    predict_index = pred_test[index].argmax(axis=0)\n",
    "    true_index = test_y[index].argmax(axis=0)\n",
    "    # Set the title for each image\n",
    "    ax.set_title(f\"{mnist_labels[predict_index]} ({mnist_labels[true_index]})\",\n",
    "                 color=(\"green\" if predict_index == true_index else \"red\"))\n",
    "    \n",
    "5) ì˜¤ë‹µí™•ì¸\n",
    "true_false = (test_y.argmax(axis=1) == single_pred_test)\n",
    "f_id = np.where(true_false == False)[0]\n",
    "f_n = len(f_id)\n",
    "id = f_id[rd.randrange(0,f_n)]\n",
    "print(f'id = {id}' )\n",
    "print(f'ë‹¤ìŒ ê·¸ë¦¼ì€ ìˆ«ì {test_y.argmax(axis=1)[id]} ì…ë‹ˆë‹¤.')\n",
    "print(f'ëª¨ë¸ì˜ ì˜ˆì¸¡ : {single_pred_test[id]}')\n",
    "print(f'ëª¨ë¸ì˜ ì¹´í…Œê³ ë¦¬ë³„ í™•ë¥  : {np.floor(pred_test[id]*100)}')\n",
    "if test_y.argmax(axis=1)[id] == single_pred_test[id] :\n",
    "    print('===============')\n",
    "    print('ì •ë‹µì…ë‹ˆë‹¤')\n",
    "    print('===============')\n",
    "else : \n",
    "    print('===============')\n",
    "    print('í‹€ë ¸ì–´ìš”')\n",
    "    print('===============')\n",
    "plt.imshow(test_x[id].reshape([28,-1]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "6) í‰ê°€\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe819b5d-4d0f-4b45-af16-e768a4fb3bff",
   "metadata": {},
   "source": [
    "## Modeling : multi-input & Concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7af6d6-ab4f-49b4-b2fa-3bf9e6b15d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "print(data.DESCR) \n",
    "df_x = pd.DataFrame(x, columns=iris.feature_names)\n",
    "# nullê°’ í™•ì¸ í•„ìš”\n",
    "iris.target_names\n",
    "\n",
    "2) train set, test set êµ¬ë¶„í•˜ê¸°\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_x, y, test_size=0.1, random_state=2022)\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape\n",
    "\n",
    "ì¶”ê°€) Scaling (ë°ì´í„° ìˆ˜ì¹˜->ë„ˆë¬´ í¸ì°¨ê°€ ì»¤ì„œ(min_max í•„ìš”))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "train_x = mm_scaler.fit_transform(train_x)\n",
    "test_x = mm_scaler.transform(test_x)\n",
    "pd.DataFrame(train_x, columns=iris.feature_names).describe()\n",
    "train_x = pd.DataFrame(train_x, columns=iris.feature_names)\n",
    "test_x = pd.DataFrame(test_x, columns=iris.feature_names)\n",
    "\n",
    "3) lengthë¼ë¦¬, widthë¼ë¦¬\n",
    "print(df_x.columns)\n",
    "tr_x_l = train_x.loc[:, ['sepal length (cm)', 'petal length (cm)'] ]\n",
    "tr_x_w = train_x.loc[:, ['sepal width (cm)', 'petal width (cm)'] ]\n",
    "tr_x_l.shape, tr_x_w.shape\n",
    "te_x_l = test_x.loc[:, ['sepal length (cm)', 'petal length (cm)'] ]\n",
    "te_x_w = test_x.loc[:, ['sepal width (cm)', 'petal width (cm)'] ]\n",
    "\n",
    "4) One-hot Encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_y = to_categorical(train_y, 3)\n",
    "test_y = to_categorical(test_y, 3)\n",
    "train_y.shape\n",
    "\n",
    "5-1) Modeling : multi-input & Concatenate layer\n",
    "@ Functional APIë§Œ ê°€ëŠ¥!!!!\n",
    "# 1. ì„¸ì…˜ í´ë¦¬ì–´\n",
    "clear_session()\n",
    "# 2. ë ˆì´ì–´ ì‚¬ìŠ¬ì²˜ëŸ¼ ì—®ê¸° : input 2ê°œ!\n",
    "il_l = Input( shape=(2,) )\n",
    "hl_l = Dense(2, activation=relu)(il_l)\n",
    "il_w = Input( shape=(2,) )\n",
    "hl_w = Dense(2, activation=relu)(il_w)\n",
    "cl = Concatenate()([hl_l, hl_w])\n",
    "ol = Dense(3, activation=softmax)(cl)\n",
    "# 3. ëª¨ë¸ ì‹œì‘ê³¼ ë ì§€ì •\n",
    "model = Model([il_l, il_w], ol)\n",
    "# 4. ëª¨ë¸ ì»´íŒŒì¼\n",
    "model.compile(loss=categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=Adam())\n",
    "model.summary()\n",
    "\n",
    "5-2) Modeling : multi-input & Add layer\n",
    "tr_x_p.shape, train_y.shape\n",
    "keras.backend.clear_session()\n",
    "il_s = keras.layers.Input(shape=(2,))\n",
    "hl_s = keras.layers.Dense(6,activation='swish')(il_s)\n",
    "il_p = keras.layers.Input(shape=(2,))\n",
    "hl_p = keras.layers.Dense(6,activation='swish')(il_p)\n",
    "add_l = keras.layers.Add()([hl_s, hl_p])\n",
    "ol = keras.layers.Dense(3,activation='softmax')(add_l)\n",
    "model = keras.models.Model([il_s,il_p],ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "6) ëª¨ë¸ ì‹œê°í™”\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "7) í•™ìŠµ\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "model.fit([tr_x_l, tr_x_w], train_y, validation_split=0.1, epochs=1000, verbose=1, callbacks=[es])\n",
    "        # ëª¨ë¸ì— ë¶“ëŠ” ìˆœì„œ ì§€ì¼œì•¼ë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c88908-5b03-4c91-a051-dc4506ec43ed",
   "metadata": {},
   "source": [
    "## ì‹œê°ì§€ëŠ¥ ë”¥ëŸ¬ë‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddd25f-c347-485b-ab54-d37c107c3a0c",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bd33f-550a-4886-a70d-99e29451d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.loadmat(\"notMNIST_small.mat\")\n",
    "\n",
    "# transform data\n",
    "X = data['images']\n",
    "y = data['labels']\n",
    "resolution = 28\n",
    "classes = 10\n",
    "\n",
    "X = np.transpose(X, (2, 0, 1))\n",
    "\n",
    "y = y.astype('int32')\n",
    "X = X.astype('float32') #/ 255.\n",
    "\n",
    "# shape: (sample, x, y, channel)\n",
    "X = X.reshape((-1, resolution, resolution, 1))\n",
    "\n",
    "# looking at data; some fonts are strange\n",
    "i = np.random.randint(0, 18723)\n",
    "print(i)\n",
    "plt.imshow( X[i,:,:,0] )\n",
    "plt.title( \"ABCDEFGHIJ\"[y[i]] )\n",
    "\n",
    "# random letters\n",
    "rows = 6\n",
    "fig, axs = plt.subplots(rows, classes, figsize=(classes, rows))\n",
    "\n",
    "for letter_id in range(10):\n",
    "    letters = X[y == letter_id]\n",
    "    for i in range(rows):\n",
    "        ax = axs[i, letter_id]\n",
    "        ax.imshow(letters[np.random.randint(len(letters)),:,:,0],\n",
    "                  cmap='Greys', interpolation='none')\n",
    "        ax.axis('off')\n",
    "        \n",
    "# splitting data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2022)\n",
    "\n",
    "x_train.shape, y_train.shape\n",
    "\n",
    "max_n, min_n = x_train.max(),x_train.min()\n",
    "\n",
    "x_train = (x_train - min_n)/ (max_n - min_n)\n",
    "x_test = (x_test - min_n)/ (max_n - min_n)\n",
    "\n",
    "len(np.unique(y_train))\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324770b9-89db-4637-81b7-f9369f2567ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(28,28,1,))\n",
    "hl = keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu',)(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu')(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "\n",
    "hl = keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "\n",
    "hl = keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.Dropout(.25)(ml)\n",
    "\n",
    "hl = keras.layers.Flatten()(hl)\n",
    "hl = keras.layers.Dense(512,)(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl) \n",
    "ol = keras.layers.Dense(10, activation='softmax')(hl)\n",
    "\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4a828-c809-4b9f-9b7e-409f10f1c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(28,28,1))\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(il)\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Flatten()(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "ol = keras.layers.Dense(10, activation='softmax')(hl)\n",
    "\n",
    "model = keras.models.Model(il ,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3af6c7-0138-4488-acee-7d699c10745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, restore_best_weights=True)\n",
    "model.fit(x_train, y_train, validation_split=.2, batch_size=1024, epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e329d13-50dd-461f-8122-7937a58416e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "pred_array = np.zeros(shape=(y_pred.shape[0], y_pred.shape[1]))\n",
    "idx = 0\n",
    "\n",
    "for arr_val in y_pred :\n",
    "    # print(arr_val)\n",
    "    pred_array[idx][arr_val.argmax()] = 1\n",
    "    idx += 1\n",
    "    \n",
    "pred_array.shape\n",
    "\n",
    "@ ì„±ëŠ¥í‰ê°€\n",
    "from sklearn.metrics import accuracy_score\n",
    "print( f'{accuracy_score(y_test, pred_array):.4f}' )\n",
    "\n",
    "@ ë¬¸ì ì´ë¯¸ì§€ ì‹œê°í™”\n",
    "import random as rd\n",
    "character = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J'}\n",
    "\n",
    "rand_n = rd.randrange(0, 3744)\n",
    "\n",
    "print(f'id = {rand_n}')\n",
    "print(f'ì‹¤ì œ ë¬¸ì : {character[y_test[rand_n].argmax()]}')\n",
    "print(f'ëª¨ë¸ì˜ ë¬¸ì ì˜ˆì¸¡ : {character[y_pred[rand_n].argmax()]}' )\n",
    "print(f'ëª¨ë¸ì˜ ë¬¸ìë³„ ì˜ˆì¸¡ í™•ë¥  : {np.round(y_pred[rand_n]*100)}')\n",
    "# print(f'ëª¨ë¸ì˜ ë¬¸ìë“¤ ì´ í™•ë¥  : {sum(np.round(y_pred[rand_n]*100))}')\n",
    "\n",
    "print('====================================================')\n",
    "\n",
    "if y_test[rand_n].argmax() == y_pred[rand_n].argmax() :\n",
    "    print('ì •ë‹µ')\n",
    "else :\n",
    "    print('ì˜¤ë‹µ')\n",
    "\n",
    "print('====================================================')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_test[rand_n].reshape(28, 28), cmap='gray')\n",
    "plt.title(\"ABCDEFGHIJ\"[y_test[rand_n].argmax()] )\n",
    "plt.show()\n",
    "\n",
    "# í‹€ë¦° ë¬¸ìë§Œ í™•ì¸\n",
    "t_f = ( y_test.argmax(axis=1) == y_pred.argmax(axis=1) )\n",
    "false_id = np.where(t_f==False)[0]\n",
    "false_n = len(false_id)\n",
    "\n",
    "id = false_id[rd.randrange(0, false_n)]\n",
    "\n",
    "print(f'id = {id}')\n",
    "print(f'ì‹¤ì œ ë¬¸ì : {character[y_test[id].argmax()]}')\n",
    "print(f'ëª¨ë¸ì˜ ë¬¸ì ì˜ˆì¸¡ : {character[y_pred[id].argmax()]}' )\n",
    "print(f'ëª¨ë¸ì˜ ë¬¸ìë³„ ì˜ˆì¸¡ í™•ë¥  : {np.round(y_pred[id]*100)}')\n",
    "# print(f'ëª¨ë¸ì˜ ë¬¸ìë“¤ ì´ í™•ë¥  : {sum(np.round(y_pred[rand_n]*100))}')\n",
    "\n",
    "print('====================================================')\n",
    "\n",
    "if y_test[id].argmax() == y_pred[id].argmax() :\n",
    "    print('ì •ë‹µ')\n",
    "else :\n",
    "    print('ì˜¤ë‹µ')\n",
    "\n",
    "print('====================================================')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_test[id].reshape(28, 28), cmap='gray')\n",
    "plt.title(\"ABCDEFGHIJ\"[y_pred[id].argmax()] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b244a83-691d-4558-9251-8e9552c8c508",
   "metadata": {},
   "source": [
    "### UltraLytics YOLO v3 Image Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d32db-9414-4d3c-bbfc-1086f5e495d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) UltraLytics gitì—ì„œ ë³µì‚¬í•˜ê¸°\n",
    "!git clone https://github.com/ultralytics/yolov3.git\n",
    "\n",
    "2) yolov3 í´ë” ì´ë™ ë° requirements.txt ë‚´ë¶€ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!cd yolov3; pip install -r /content/yolov3/requirements.txt\n",
    "\n",
    "3) Image Detection\n",
    "3-1) ì˜ˆì œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ => !wget -O [ì €ì¥í•  íŒŒì¼ëª…] [íŒŒì¼ ì£¼ì†Œ]\n",
    "!wget -O /content/yolov3/data/images/14th_street.jpg\\\n",
    "https://raw.githubusercontent.com/DrKAI/image/main/14th_Street_2005.jpg\n",
    "\n",
    "3-2) COCO Dataset(ì„±ëŠ¥ì§€í‘œ)ìœ¼ë¡œ pretrained ëœ weights ë‹¤ìš´ë¡œë“œ [weightsê°€ ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œ] \n",
    "=> !mkdir [ê²½ë¡œ/ë””ë ‰í† ë¦¬ ëª…]\n",
    "=> pretrained weights ë‹¤ìš´ë¡œë“œ\n",
    "!mkdir /content/yolov3/pretrained\n",
    "!wget -O /content/yolov3/pretrained/yolov3-tiny.pt\\\n",
    "https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3-tiny.pt\n",
    "\n",
    "3-3) detect.pyë¥¼ pythonìœ¼ë¡œ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ìˆ˜í–‰ => ëª…ë ¹ì–´ ë„ì›€ë§ : !cd yolo3; python detect.py -h\n",
    "!cd yolov3; python detect.py -h\n",
    "!cd yolov3; python detect.py \\\n",
    "    --weights '/content/yolov3/pretrained/yolov3.pt' \\\n",
    "    --source '/content/yolov3/data/images' \\\n",
    "    --project '/content/yolov3/detected' \\\n",
    "    --name 'images' \\\n",
    "    --img 640 \\\n",
    "    --conf-thres 0.1 \\\n",
    "    --iou-thres 0.4 \\\n",
    "    --line-thickness 2 \\\n",
    "    --exist-ok \\# ë®ì–´ì“°ê¸°\n",
    "    --device CPU\n",
    "\n",
    "@ Detect Image ì‚´í´ë³´ê¸°\n",
    "from IPython.display import Image\n",
    "from google.colab import files\n",
    "\n",
    "# Image(filename=[íŒŒì¼ ê²½ë¡œ])\n",
    "Image(filename='/content/yolov3/detected/images/14th_street.jpg', width=850)\n",
    "\n",
    "# files.download(filename=[íŒŒì¼ ê²½ë¡œ])\n",
    "files.download(filename='/content/yolov3/detected/images/14th_street.jpg')\n",
    "\n",
    "# zip\n",
    "!zip -r /content/detected_image.zip /content/yolov3/detected/images2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b633ee0-0881-4d27-b266-086b66b5e510",
   "metadata": {},
   "source": [
    "### UltraLytics_YOLOv3_VideoDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5675720-bd1b-4f39-83fa-f24b59aae4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov3.git\n",
    "\n",
    "!cd yolov3; pip install -r /content/yolov3/requirements.txt\n",
    "\n",
    "!mkdir /content/yolov3/data/videos\n",
    "!wget -O /content/yolov3/data/videos/noway.mp4\\\n",
    "https://github.com/DrKAI/image/raw/main/No_Way_This_Happened.mp4\n",
    "\n",
    "!mkdir /content/yolov3/pretrained\n",
    "!wget -O /content/yolov3/pretrained/yolov3.pt\\\n",
    "https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt\n",
    "\n",
    "# !cd yolov3; python detect.py -h\n",
    "!cd yolov3; python detect.py \\\n",
    "    --weights '/content/yolov3/pretrained/yolov3.pt' \\\n",
    "    --source '/content/yolov3/data/videos/' \\\n",
    "    --project '/content/yolov3/detected' \\\n",
    "    --name 'videos' \\\n",
    "    --img 640 \\\n",
    "    --conf-thres 0.5 \\\n",
    "    --iou-thres 0.4 \\\n",
    "    --line-thickness 2 \\\n",
    "    --exist-ok\n",
    "    # --device CPU\n",
    "    \n",
    "from google.colab import files\n",
    "## colabì€ ë©€í‹° ë‹¤ìš´ë¡œë“œ ì§€ì›X\n",
    "## í´ë” ì••ì¶•í•˜ì—¬ íŒŒì¼ í•˜ë‚˜ë¡œ ë§Œë“¤ê³  ë‹¤ìš´ë¡œë“œ\n",
    "!zip -r /content/detected_videos.zip /content/yolov3/detected/videos/\n",
    "\n",
    "files.download(filename='/content/yolov3/detected/videos/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f69e8-44c7-408a-b75b-1453c5f2fb68",
   "metadata": {},
   "source": [
    "### UltraLytics_YOLOv5_CustomData_ImageDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d2333-3ea6-476f-9ec0-068da8150e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "    \n",
    "!cd yolov5; pip install -r requirements.txt\n",
    "\n",
    "@ Image Detection\n",
    "1) ì‚¬ì „ ì‘ì—…ëœ CustomData yaml ë‹¤ìš´ë¡œë“œ\n",
    "!wget -O /content/yolov5/data/street.yaml\\\n",
    "https://raw.githubusercontent.com/DrKAI/CV/main/street_example.yaml\n",
    "\n",
    "2) pretrained ëœ weights ë‹¤ìš´ë¡œë“œ => weightsê°€ ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œ\n",
    "!mkdir /content/yolov5/pretrained\n",
    "!wget -O /content/yolov5/pretrained/yolov5s.pt\\\n",
    "https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt\n",
    "\n",
    "3) trainìš© ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "!mkdir /content/datasets; mkdir /content/datasets/street\n",
    "!mkdir /content/datasets/street/images; mkdir /content/datasets/street/images/train\n",
    "!mkdir /content/datasets/street/labels; mkdir /content/datasets/street/labels/train\n",
    "\n",
    "!wget -O /content/street_images1.zip https://github.com/DrKAI/CV/raw/main/street_images1.zip\n",
    "!wget -O /content/street_images2.zip https://github.com/DrKAI/CV/raw/main/street_images2.zip\n",
    "!wget -O /content/street_images3.zip https://github.com/DrKAI/CV/raw/main/street_images3.zip\n",
    "\n",
    "!wget -O /content/street_labels1.zip https://github.com/DrKAI/CV/raw/main/street_labels1.zip\n",
    "!wget -O /content/street_labels2.zip https://github.com/DrKAI/CV/raw/main/street_labels2.zip\n",
    "!wget -O /content/street_labels3.zip https://github.com/DrKAI/CV/raw/main/street_labels3.zip\n",
    "    \n",
    "!unzip /content/street_images1.zip -d /content/datasets/street/images/train\n",
    "!unzip /content/street_images2.zip -d /content/datasets/street/images/train\n",
    "!unzip /content/street_images3.zip -d /content/datasets/street/images/train\n",
    "\n",
    "!unzip /content/street_labels1.zip -d /content/datasets/street/labels/train\n",
    "!unzip /content/street_labels2.zip -d /content/datasets/street/labels/train\n",
    "!unzip /content/street_labels3.zip -d /content/datasets/street/labels/train\n",
    "\n",
    "4) train.py ì‹¤í–‰\n",
    "!cd yolov5; python train.py -h\n",
    "!cd yolov5; python train.py \\\n",
    "    --data '/content/yolov5/data/street.yaml' \\\n",
    "    --cfg '/content/yolov5/models/yolov5s.yaml' \\\n",
    "    --weights '/content/yolov5/pretrained/yolov5s.pt' \\\n",
    "    --epochs 1000 \\\n",
    "    --patience 7 \\\n",
    "    --img 640 \\\n",
    "    --project 'trained' \\\n",
    "    --name 'train_street' \\\n",
    "    --exist-ok\n",
    "    # --device cpu\n",
    "\n",
    "5) detectìš© ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "!wget -O /content/yolov5/data/images/street01.jpeg https://github.com/DrKAI/image/raw/main/001.jpeg\n",
    "!wget -O /content/yolov5/data/images/street02.jpg https://github.com/DrKAI/image/raw/main/14th_Street_2005.jpg\n",
    "!wget -O /content/yolov5/data/images/street03.jpg https://github.com/DrKAI/image/raw/main/street02.jpg\n",
    "!wget -O /content/yolov5/data/images/street04.jpg https://github.com/DrKAI/image/raw/main/street03.jpg\n",
    "!wget -O /content/yolov5/data/images/street05.jpg https://github.com/DrKAI/image/raw/main/street04.jpg\n",
    "!wget -O /content/yolov5/data/images/street06.jpg https://github.com/DrKAI/image/raw/main/street05.jpg\n",
    "\n",
    "\n",
    "6) detect.py ì‹¤í–‰\n",
    "!cd yolov5; python detect.py -h\n",
    "\n",
    "!cd yolov5; python detect.py \\\n",
    "    --weights '/content/yolov5/trained/train_street/weights/best.pt' \\\n",
    "    --source '/content/yolov5/data/images/' \\\n",
    "    --project '/content/yolov5/detected' \\\n",
    "    --name 'images' \\\n",
    "    --img 640 \\\n",
    "    --conf-thres 0.25 \\\n",
    "    --iou-thres 0.5 \\\n",
    "    --line-thickness 2 \\\n",
    "    --exist-ok \n",
    "    # --device CPU\n",
    "\n",
    "7) Detect Image ì‚´í´ë³´ê¸°\n",
    "from IPython.display import Image\n",
    "from google.colab import files\n",
    "\n",
    "Image(filename='/content/yolov5/detected/images/street01.jpeg', width=640)\n",
    "\n",
    "## colabì€ ë©€í‹° ë‹¤ìš´ë¡œë“œë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤\n",
    "## í´ë”ë¥¼ ì••ì¶•í•˜ì—¬ íŒŒì¼ í•˜ë‚˜ë¡œ ë§Œë“¤ê³  ë‹¤ìš´ë¡œë“œ í•œë‹¤\n",
    "\n",
    "!zip -r /content/detected_images.zip /content/yolov5/detected/images\n",
    "\n",
    "files.download(filename='/content/detected_images.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706d8f3-326a-4946-891b-a470b77cfac7",
   "metadata": {},
   "source": [
    "## í¬ë¡¤ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57fddd-9cc4-40fe-b90a-47dd69c00c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests ì´ìš©\n",
    "ë°›ì•„ì˜¤ëŠ” ë¬¸ìì—´ì— ë”°ë¼ ë‘ê°€ì§€ ë°©ë²•ìœ¼ë¡œ êµ¬ë¶„\n",
    "json ë¬¸ìì—´ë¡œ ë°›ì•„ì„œ íŒŒì‹±í•˜ëŠ” ë°©ë²• : ì£¼ë¡œ ë™ì  í˜ì´ì§€ í¬ë¡¤ë§í• ë•Œ ì‚¬ìš©\n",
    "html ë¬¸ìì—´ë¡œ ë°›ì•„ì„œ íŒŒì‹±í•˜ëŠ” ë°©ë²• : ì£¼ë¡œ ì •ì  í˜ì´ì§€ í¬ë¡¤ë§í• ë•Œ ì‚¬ìš©\n",
    "selenium ì´ìš©\n",
    "ë¸Œë¼ìš°ì ¸ë¥¼ ì§ì ‘ ì—´ì–´ì„œ ë°ì´í„°ë¥¼ ë°›ëŠ” ë°©ë²•\n",
    "í¬ë¡¤ë§ ë°©ë²•ì— ë”°ë¥¸ ì†ë„\n",
    "requests json > requests html > selenium\n",
    "# summary\n",
    "# web : server-client : url\n",
    "# request, response : get,post\n",
    "# ì›¹ì„œë¹„ìŠ¤ì˜ êµ¬ì¡°\n",
    "# ì›¹í˜ì´ì§€ì˜ ì¢…ë¥˜\n",
    "# - ë™ì í˜ì´ì§€ : URL ë³€ê²½ X > ë°ì´í„° ìˆ˜ì • : JSON : API\n",
    "# - ì •ì í˜ì´ì§€ : URL ë³€ê²½ O > ë°ì´í„° ìˆ˜ì • : HTML : css selector > BeautifulSoup : select(), select_one()\n",
    "\n",
    "\n",
    "# html : ì›¹í˜ì´ì§€ì—ì„œ ë ˆì´ì•„ì›ƒ, í…ìŠ¤íŠ¸ ë“±ì˜ ë°ì´í„°ë¥¼ ì‘ì„±\n",
    "# êµ¬ì„±ìš”ì†Œ: document, element, tag, attr, text\n",
    "# element ê³„ì¸µì  êµ¬ì¡°\n",
    "# tag ì¢…ë¥˜ : p, span, ul, li, table, a, img, iframe, div\n",
    "\n",
    "# css selector : htmlì˜ elementì— styleì„ ì ìš©ì‹œí‚¬ë•Œ elementë¥¼ ì„ íƒí•˜ëŠ” ë°©ë²•\n",
    "# element ì„ íƒ : tag(span), class(.), id(#), attr([value=\"no1\"])\n",
    "# në²ˆì§¸ element ì„ íƒ : .py:nth-child(2) : 2ë²ˆì§¸ ì—˜ë¦¬ë¨¼íŠ¸ì¤‘ì— í´ë˜ìŠ¤ê°€ pyì¸ ì—˜ë¦¬ë¨¼íŠ¸\n",
    "# ê³„ì¸µì  element ì„ íƒ : ëª¨ë“  í•˜ìœ„ ì—˜ë¦¬ë¨¼íŠ¸ ì„ íƒ(.wrap p), í•œë‹¨ê³„ í•˜ìœ„ ì—˜ë¦¬ë¨¼íŠ¸ ì„ íƒ(.wrap > p), ì—¬ëŸ¬ê°œ ì„ íƒ(.no1, .no2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49620ab6-88c5-4ddc-8858-69529f3ea12a",
   "metadata": {},
   "source": [
    "### Selenium\n",
    "- ë¸Œë¼ìš°ì ¸ì˜ ìë™í™” ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ë‹¤ì–‘í•œ ë¸Œë¼ìš°ì ¸ì™€ ì–¸ì–´ë¥¼ ì§€ì›í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "- ë¸Œë¼ìš°ì ¸ë¥¼ íŒŒì´ì¬ ì½”ë“œë¡œ ì»¨íŠ¸ë¡¤ í•´ì„œ ë¸Œë¼ìš°ì ¸ì— ìˆëŠ” ë°ì´í„°ë¥¼ ìˆ˜ì§‘\n",
    "\n",
    "#### í¬ë¡¤ë§ ë°©ë²•\n",
    "- 1. requests : json : ì›¹í˜ì´ì§€ì˜ API íŠ¸ë˜í”½ì„ ë¶„ì„í•´ì„œ ë°ì´í„° ìˆ˜ì§‘ : naver stock\n",
    "- 2. requests : json : ê³µì‹ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” APIë¥¼ application key ë°›ì•„ì„œ ë°ì´í„° ìˆ˜ì§‘ : naver api(papago, trend)\n",
    "- 3. requests : html, BeautifulSoup(css selector) : ì›¹í˜ì´ì§€ì˜ html ì½”ë“œ ë°›ì•„ì„œ ë°ì´í„° ìˆ˜ì§‘ : gmarket\n",
    "- 4. selenium : browser - python : ë¸Œë¼ìš°ì ¸ë¥¼ íŒŒì´ì¬ ì½”ë“œë¡œ ì»¨íŠ¸ë¡¤ í•´ì„œ ë°ì´í„° ìˆ˜ì§‘ : ted\n",
    "- í¬ë¡¤ë§í• ë•Œ ì¢‹ì€ ìˆœì„œ : 2 > 1 > 3 > 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6973869f-8ad4-408b-86f5-05fb2098994b",
   "metadata": {},
   "source": [
    "### ë™ì í˜ì´ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0ee8b-075f-48c3-b624-7f1eb7f9f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë™ì  í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤\n",
    "# 1. ì›¹ì„œë¹„ìŠ¤ ë¶„ì„(ê°œë°œìë„êµ¬) : URL\n",
    "# 2. request(url, params, header) > response(json) : JSON(str)\n",
    "# 3. JSON(str) > list, dict > DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0f089-4c10-41a8-8129-205f475a03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "1) pc ì›¹í˜ì´ì§€ê°€ ë³µì¡í•˜ë©´ mobile ì›¹í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘\n",
    "2) ì„œë²„ì— ë°ì´í„° ìš”ì²­ : request(url) > response : json(str)\n",
    "- responseì˜ status codeê°€ 200ì´ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸\n",
    "- 403ì´ë‚˜ 500ì´ ë‚˜ì˜¤ë©´ requestê°€ ì˜ëª»ë˜ê±°ë‚˜ web serverì—ì„œ ìˆ˜ì§‘ì´ ì•ˆë˜ë„ë¡ ì„¤ì •ì´ ëœê²ƒì„\n",
    "  -> header ì„¤ì • ë˜ëŠ” selenium ì‚¬ìš©\n",
    "- 200ì´ ë‚˜ì˜¤ë”ë¼ë„ response ì•ˆì— ìˆëŠ” ë‚´ìš©ì„ í™•ì¸ > í™•ì¸í•˜ëŠ” ë°©ë²• : response.text[:200]\n",
    "3) ì„œë²„ì—ì„œ ë°›ì€ ë°ì´í„° íŒŒì‹±(ë°ì´í„° í˜•íƒœë¥¼ ë³€ê²½) : json(str) > list, dict > DataFrame\n",
    "4) í•¨ìˆ˜ë¡œ ë§Œë“¤ê¸°\n",
    "\n",
    "def stock_price(pagesize, page, code=\"KOSPI\"):\n",
    "    \"\"\"This function is crawling stock price form naver webpage.\n",
    "    Params\n",
    "    ------\n",
    "    pagesize : int : one page size\n",
    "    page : int : page number\n",
    "    code : str : KOSPI or KOSDAQ\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    type : DataFrame : display date, price columns\n",
    "    \"\"\"\n",
    "    url = f\"https://m.stock.naver.com/api/index/{code}/price?pageSize={pagesize}&page={page}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return pd.DataFrame(data)[[\"localTradedAt\",\"closePrice\"]]\n",
    "\n",
    "kospi = stock_price(60,1,\"KOSPI\")\n",
    "kosdaq = stock_price(60,1,\"KOSDAQ\")\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "df = kospi.copy()\n",
    "df[\"kosdaq\"]=kosdaq[\"closePrice\"]\n",
    "df[\"usd\"] = usd['closePrice']\n",
    "df = df.rename(columns={\"closePrice\":\"kospi\"})\n",
    "df\n",
    "\n",
    "# docstring[\"\"\"\"\"\"] : í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë¬¸ìì—´ë¡œ ì‘ì„± \n",
    "#help()ì´ìš©, Shift + tab\n",
    "help(stock_price)\n",
    "\n",
    "df = pd.DataFrame([{'age': 23},{'age': 36},{'age': 27}])  # ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸°\n",
    "df\n",
    "\n",
    "@ ì‹œê°í™”\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ë°ì´í„° ìˆ˜ì§‘\n",
    "page_size = 60\n",
    "kospi_df = stock_price(\"KOSPI\", page_size=page_size)\n",
    "kosdaq_df = stock_price(\"KOSDAQ\", page_size=page_size)\n",
    "usd_df = exchage_rate(\"FX_USDKRW\", page_size=page_size)\n",
    "eur_df = exchage_rate(\"FX_EURKRW\", page_size=page_size)\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ 1 : ë°ì´í„° íƒ€ì… ë³€ê²½\n",
    "print(kospi_df.dtypes)\n",
    "kospi_df[\"kospi\"] = kospi_df[\"closePrice\"].apply(lambda data: float(data.replace(\",\", \"\")))\n",
    "kospi_df = kospi_df.drop(columns=[\"closePrice\"])\n",
    "print(kospi_df.dtypes)\n",
    "\n",
    "kosdaq_df[\"kosdaq\"] = kosdaq_df[\"closePrice\"].apply(lambda data: float(data.replace(\",\", \"\")))\n",
    "usd_df[\"usd\"] = usd_df[\"closePrice\"].apply(lambda data: float(data.replace(\",\", \"\")))\n",
    "eur_df[\"eur\"] = eur_df[\"closePrice\"].apply(lambda data: float(data.replace(\",\", \"\")))\n",
    "\n",
    "kosdaq_df = kosdaq_df.drop(columns=[\"closePrice\"])\n",
    "usd_df = usd_df.drop(columns=[\"closePrice\"])\n",
    "eur_df = eur_df.drop(columns=[\"closePrice\"])\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ 2 : ë‚ ì§œ ë°ì´í„° ë§ì¶”ê¸° : merge\n",
    "merge_df_1 = pd.merge(kospi_df, kosdaq_df, on=\"localTradedAt\")\n",
    "merge_df_2 = pd.merge(merge_df_1, usd_df, on=\"localTradedAt\")\n",
    "merge_df_3 = pd.merge(merge_df_2, eur_df, on=\"localTradedAt\")\n",
    "merge_df = merge_df_3.copy()\n",
    "merge_df.tail(2)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(20, 5))\n",
    "columns = merge_df.columns[1:]\n",
    "for column in columns:\n",
    "    plt.plot(merge_df[\"localTradedAt\"], merge_df[column], label=column)\n",
    "\n",
    "xticks_count = 11\n",
    "plt.xticks(merge_df[\"localTradedAt\"][::int(len(merge_df) // xticks_count) + 1])\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "corr_df = merge_df[merge_df.columns[1:]].corr()\n",
    "corr_df\n",
    "\n",
    "# ê²°ì •ê³„ìˆ˜ : r-squared \n",
    "# 1ê³¼ ê°€ê¹Œìš¸ìˆ˜ë¡ ê°•í•œ ê´€ê³„, 0ê³¼ ê°€ê¹Œìš¸ìˆ˜ë¡ ì•½í•œ ê´€ê³„\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.heatmap(corr_df**2, cmap=\"YlGnBu\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92a181-e776-4208-91a2-032e56cf19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì… ë³€ê²½ : str > float\n",
    "# df[column].apply() : ëª¨ë“  ë°ì´í„°ë¥¼ í•¨ìˆ˜ì— ëŒ€ì…í•œ ê²°ê³¼ë¥¼ ì¶œë ¥\n",
    "# apply(func) : ëª¨ë“  ë°ì´í„°ë¥¼ funcì„ ì ìš©ì‹œí‚¨ ê²°ê³¼ ì¶œë ¥\n",
    "df.dtypes\n",
    "\n",
    "# í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ : df.corr()\n",
    "# 1ê³¼ ê°€ê¹Œìš¸ìˆ˜ë¡ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ë¥¼ ê°–ëŠ”ë‹¤.\n",
    "# -1ê³¼ ê°€ê¹Œìš¸ìˆ˜ë¡ ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„ë¥¼ ê°–ëŠ”ë‹¤.\n",
    "# 0ê³¼ ê°€ê¹Œìš¸ìˆ˜ë¡ ê´€ê³„ê°€ ì—†ë‹¤.\n",
    "df[['kospi','kosdaq','usd']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58329ff-519b-4c70-bfbd-262752375141",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b48f4b-7dc6-485e-82b1-45e3e360447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "application programing interface\n",
    "api ë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ”ê²ƒì€ ì„œë¹„ìŠ¤ì— ë°ì´í„°ë¥¼ ì œê³µí•œëŠ” ê³µì‹ì ì¸ ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1f72e-7afc-42ce-a3ec-d487dbdb901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APIë¥¼ ì´ìš©í•œ ë°ì´í„° ìˆ˜ì§‘\n",
    "# 1. APP ë“±ë¡ : application key \n",
    "# 2. API ë¬¸ì„œ : URL\n",
    "# 3. request(url, params, header(application key)) > response(json) : JSON(str)\n",
    "# 4. JSON(str) > list, dict > DataFrame or Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c258821c-0a5d-4f7f-88f2-523a3a5139de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68d416-17b4-40ce-9268-a47074cd698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID, CLIENT_SECRET = \"KE2M4YcO4Sv9P7HrFXJ1\", \"9X0zM51ZRf\"\n",
    "\n",
    "# json.dumps() : ì¸í„°ë„· íŠ¸ë˜í”½ì—ì„œëŠ” ì˜ë¬¸, ìˆ«ì, íŠ¹ìˆ˜ë¬¸ìë§Œ ì‚¬ìš©ê°€ëŠ¥\n",
    "# í•œê¸€ê³¼ ê°™ì€ ë¬¸ìë¥¼ ì¸ì½”ë”©(ì˜ë¬¸,ìˆ«ì,íŠ¹ìˆ˜ë¬¸ì)\n",
    "txt= \"íŒŒì´ì¬ì€ ì¬ë¯¸ìˆìŠµë‹ˆë‹¤.\"\n",
    "url = \"https://openapi.naver.com/v1/papago/n2mt\" \n",
    "params = {\"source\": \"ko\", \"target\": \"en\", \"text\": txt}\n",
    "headers = {\"Content-Type\": \"application/json\", \n",
    "           \"X-Naver-Client-Id\": CLIENT_ID,\n",
    "           \"X-Naver-Client-Secret\": CLIENT_SECRET}\n",
    "\n",
    "response = requests.post(url, json.dumps(params),headers=headers)\n",
    "response\n",
    "\n",
    "response.text\n",
    "\n",
    "txt_en = response.json()[\"message\"][\"result\"][\"translatedText\"]\n",
    "txt_en\n",
    "\n",
    "# ì´ë ‡ê²Œ ê°€ì ¸ì˜¬ìˆ˜ ìˆë‹¤[ë‹¤ìŒ í™˜ìœ¨]\n",
    "datas = response.json()[\"data\"]\n",
    "df = pd.DataFrame(datas)\n",
    "df.head(1)\n",
    "\n",
    "def translate(txt):\n",
    "    CLIENT_ID, CLIENT_SECRET = \"KE2M4YcO4Sv9P7HrFXJ1\",\"9X0zM51ZRf\" \n",
    "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
    "    params = {\"source\": \"ko\", \"target\": \"en\", \"text\": txt}\n",
    "    headers = {\"Content-Type\": \"application/json\", \n",
    "           \"X-Naver-Client-Id\": CLIENT_ID,\n",
    "           \"X-Naver-Client-Secret\": CLIENT_SECRET}\n",
    "    response = requests.post(url, json.dumps(params), headers=headers)\n",
    "    txt_en = response.json()[\"message\"][\"result\"][\"translatedText\"]\n",
    "    return txt_en\n",
    "\n",
    "txt= \"ì›¹í¬ë¡¤ë§ì€ ì¬ë¯¸ìˆìŠµë‹ˆë‹¤.\"\n",
    "txt_en = translate(txt)\n",
    "txt_en\n",
    "\n",
    "@ í•œê¸€ excel íŒŒì¼ì„ ì˜ë¬¸ excel íŒŒì¼ë¡œ ë³€ê²½\n",
    "\n",
    "%ls\n",
    "\n",
    "covid = pd.read_excel(\"covid.xlsx\")[[\"category\",\"title\"]]\n",
    "covid.tail(2)\n",
    "\n",
    "covid_en = covid[\"title\"].apply(translate)\n",
    "\n",
    "covid[\"title_en\"] = covid_en\n",
    "covid\n",
    "\n",
    "# utf-8-sig : excelì—ì„œ ì‚¬ìš©í•˜ëŠ” ì¸ì½”ë”© ë°©ì‹ê³¼ í˜¸í™˜ì´ ë˜ëŠ” utf-8ì¸ ì¸ì½”ë”© ë°©ì‹ \n",
    "covid.to_excel(\"covid_en.xlsx\", index = False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d8888-7d77-4ea1-9b61-173c3796e550",
   "metadata": {},
   "source": [
    "### í†µí•©ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ee8a0-4758-428d-a301-f2dbe2437d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. URL\n",
    "url = \"https://openapi.naver.com/v1/datalab/search\"\n",
    "\n",
    "# 2. request > response\n",
    "params = {\n",
    "    \"startDate\": \"2018-01-01\",\n",
    "    \"endDate\": \"2022-01-31\",\n",
    "    \"timeUnit\": \"month\",\n",
    "    \"keywordGroups\": [\n",
    "        {\"groupName\": \"íŠ¸ìœ„í„°\", \"keywords\": [\"íŠ¸ìœ„í„°\", \"íŠ¸ìœ—\"]},\n",
    "        {\"groupName\": \"í˜ì´ìŠ¤ë¶\", \"keywords\": [\"í˜ì´ìŠ¤ë¶\", \"í˜ë¶\"]},\n",
    "        {\"groupName\": \"ì¸ìŠ¤íƒ€ê·¸ë¨\", \"keywords\": [\"ì¸ìŠ¤íƒ€ê·¸ë¨\", \"ì¸ìŠ¤íƒ€\"]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-Naver-Client-Id\": CLIENT_ID,\n",
    "    \"X-Naver-Client-Secret\": CLIENT_SECRET,    \n",
    "}\n",
    "\n",
    "response = requests.post(url, data=json.dumps(params), headers=headers)\n",
    "response\n",
    "\n",
    "# 3. parsing\n",
    "datas = response.json()[\"results\"]\n",
    "\n",
    "# 4. preprocessing\n",
    "result_df = pd.concat(dfs, ignore_index=True)\n",
    "result_df.tail(2)\n",
    "\n",
    "pivot_df = result_df.pivot(\"period\", \"title\", \"ratio\")\n",
    "pivot_df.columns = [\"instagram\", \"twitter\", \"facebook\"]\n",
    "pivot_df.tail(2)\n",
    "\n",
    "# 5. visualization\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot_df.plot(figsize=(20, 5))\n",
    "plt.legend(loc=0)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8271533-a62e-415f-9a5b-7ac6fd1aa285",
   "metadata": {},
   "source": [
    "### ìœ„ë„ ê²½ë„ë¡œ ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a584b0-0446-4bd9-a872-034d0a336b16",
   "metadata": {},
   "source": [
    "- ì ˆì°¨\n",
    "    - ë™ì´ë¦„ìœ¼ë¡œ ìœ„ë„ ê²½ë„ êµ¬í•˜ê¸°\n",
    "    - ìœ„ë„ ê²½ë„ë¡œ geohash ì•Œì•„ë‚´ê¸°\n",
    "    - geohashë¡œ ë§¤ë¬¼ ì•„ì´ë”” ê°€ì ¸ì˜¤ê¸°\n",
    "    - ë§¤ë¬¼ ì•„ì´ë””ë¡œ ë§¤ë¬¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bbc48-ffad-4cfd-9dd9-94e3a2c8a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ë™ì´ë¦„ìœ¼ë¡œ ìœ„ë„ ê²½ë„ êµ¬í•˜ê¸°\n",
    "addr = \"ë§ì›ë™\"\n",
    "url = f\"https://apis.zigbang.com/v2/search?leaseYn=N&q={addr}&serviceType=ì›ë£¸\"\n",
    "response = requests.get(url)\n",
    "data = response.json()[\"items\"][0]\n",
    "lat, lng = data[\"lat\"], data[\"lng\"]\n",
    "lat, lng\n",
    "\n",
    "# 2. ìœ„ë„ ê²½ë„ë¡œ geohash ì•Œì•„ë‚´ê¸°\n",
    "# install geohash2\n",
    "# !pip install geohash2\n",
    "import geohash2\n",
    "\n",
    "# precisionì´ ì»¤ì§ˆìˆ˜ë¡ ì˜ì—­ì´ ì‘ì•„ì§\n",
    "geohash = geohash2.encode(lat, lng, precision=5)\n",
    "geohash\n",
    "\n",
    "# 3. geohashë¡œ ë§¤ë¬¼ ì•„ì´ë”” ê°€ì ¸ì˜¤ê¸°\n",
    "url = f\"https://apis.zigbang.com/v2/items?deposit_gteq=0&domain=zigbang\\\n",
    "&geohash={geohash}&needHasNoFiltered=true&rent_gteq=0&sales_type_in=ì „ì„¸|ì›”ì„¸\\\n",
    "&service_type_eq=ì›ë£¸\"\n",
    "response = requests.get(url)\n",
    "datas = response.json()[\"items\"]\n",
    "# len(datas), datas[0]\n",
    "ids = [data[\"item_id\"] for data in datas]\n",
    "len(ids), ids[:5]\n",
    "\n",
    "# 4. ë§¤ë¬¼ ì•„ì´ë””ë¡œ ë§¤ë¬¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "# 1000ê°œ ë„˜ì–´ê°€ë©´ ë‚˜ëˆ ì„œ ìˆ˜ì§‘í•´ì•¼ í•¨\n",
    "url = \"https://apis.zigbang.com/v2/items/list\"\n",
    "params = {\n",
    "    \"domain\": \"zigbang\",\n",
    "    \"withCoalition\": \"true\",\n",
    "    \"item_ids\": ids\n",
    "}\n",
    "response = requests.post(url, params)\n",
    "response\n",
    "\n",
    "datas = response.json()[\"items\"]\n",
    "df = pd.DataFrame(datas)\n",
    "df.tail(2)\n",
    "\n",
    "# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ í•„í„°ë§\n",
    "columns = [\"item_id\", \"sales_type\", \"deposit\", \"rent\", \"size_m2\", \"floor\", \"building_floor\",\n",
    "           \"address1\", \"manage_cost\"]\n",
    "filtered_column_df = df[columns]\n",
    "filtered_column_df.tail(2)\n",
    "\n",
    "# ì£¼ì†Œì— ë§ì›ë™ì´ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§\n",
    "result_df = filtered_column_df[filtered_column_df[\"address1\"].str.contains(\"ë§ì›ë™\")]\n",
    "result_df = result_df.reset_index(drop=True)\n",
    "result_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f877474-7e76-4bf1-aa09-127db92a7c4b",
   "metadata": {},
   "source": [
    "### ì´ë¯¸ì§€ í¬ë¡¤ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b357db-f6fb-4011-adf9-5c7f01eb8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, os\n",
    "\n",
    "# 1. ë””ë ‰í† ë¦¬ ìƒì„± : data\n",
    "path = \"data\"\n",
    "if not os.path.exists(\"data\"): # ë””ë ‰í† ë¦¬ ì¡´ì¬ ìœ ë¬´ í™•ì¸\n",
    "    os.makedirs(path)\n",
    "    \n",
    "%ls\n",
    "# 2. csv íŒŒì¼ì„ ë¡œë“œ : image link\n",
    "df = pd.read_csv(\"gmarket.csv\")\n",
    "df.tail(2)\n",
    "\n",
    "img_link = df.loc[0, 'img']\n",
    "img_link\n",
    "\n",
    "# 3. download images : requests\n",
    "response = requests.get(img_link)\n",
    "response\n",
    "\n",
    "with open(f'{path}/test.png', \"wb\") as file: # íŒŒì¼ì €ì¥ wb, ì½ê¸°ëŠ” rd\n",
    "    file.write(response.content)\n",
    "    \n",
    "%ls data\n",
    "\n",
    "# 4. display image : pillow\n",
    "from PIL import Image as pil\n",
    "pil.open(f'{path}/test.png') \n",
    "\n",
    "# 5. ì—¬ëŸ¬ê°œì˜ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "df[:3]\n",
    "for idx, data in df[:5].iterrows():\n",
    "    filename = '0' * (3 - len(str(idx))) + str(idx) + '.png'\n",
    "    print(idx, filename, data['img'])\n",
    "    response = requests.get(data['img'])\n",
    "    with open(f'{path}/{filename}', \"wb\") as file: # íŒŒì¼ì €ì¥ wb, ì½ê¸°ëŠ” rd\n",
    "        file.write(response.content)\n",
    "\n",
    "pil.open(f'{path}/004.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5772e5b-415e-4e75-8425-b9a8407e0bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af21c7-3a20-4620-9aed-2ec046660fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f23eb8-7d2a-4838-9529-e3894a6db0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74dd4d7-a4a9-45b4-bc67-27d3d69c4531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12574e-2655-46fa-99f8-66c8f0241808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
