{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#PyTorch 튜토리얼 \n","\n","Tensor(텐서)는 Numpy의 다차원 행렬 자료구조인 ndarray와 유사하나 CPU 뿐만 아니라 GPU에서 실행될 수 있다는 차이점이 있습니다.\n","\n","PyTorch는 GPU와 CPU를 사용하는 딥러닝을 위한 최적화된 텐서 라이브러리입니다.\n","\n","본 코드에서 PyTorch를 사용하여 CNN, RNN 모델을 구현할 때 알아야할 기본적인 사항을 소개합니다. \n","\n","코드 출처: https://tutorials.pytorch.kr/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n","\n","PyTorch Documents: https://pytorch.org/docs/stable/index.html"],"metadata":{"id":"weHATskkbZV_"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"eu1VDs46bHzN","executionInfo":{"status":"ok","timestamp":1664910261940,"user_tz":-540,"elapsed":525,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"outputs":[],"source":["# The torch package contains data structures for multi-dimensional tensors and \n","# defines mathematical operations over these tensors. \n","import torch\n","import numpy as np"]},{"cell_type":"markdown","source":["텐서 초기화하기"],"metadata":{"id":"MsQ8xnmtS1sO"}},{"cell_type":"code","source":["# 2차원 리스트 데이터로부터 텐서 생성\n","data = [[1, 2], [3, 4]]\n","# 텐서 생성\n","x_data = torch.tensor(data)\n","print(x_data)\n","print(x_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKydbeNnbXTY","outputId":"fd46c20f-ead9-4be4-8eaf-d428f113a3ca","executionInfo":{"status":"ok","timestamp":1664910264402,"user_tz":-540,"elapsed":10,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]])\n","torch.Size([2, 2])\n"]}]},{"cell_type":"code","source":["# 랜덤값으로 텐서 생성. 정수값으로 텐서의 차원을 전달\n","# 랜덤값으로 채워진 (3, 4) 차원의 텐서를 생성 \n","tensor = torch.rand(3, 4)   \n","print (\"tensor :\", tensor)\n","print(f\"Shape of tensor: {tensor.shape}\")     \n","print(f\"Datatype of tensor: {tensor.dtype}\") \n","print(f\"Device tensor is stored on: {tensor.device}\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr4iKqvkxrmu","outputId":"4b58aa09-f1e9-44de-993d-a20f6845cc82","executionInfo":{"status":"ok","timestamp":1664910265836,"user_tz":-540,"elapsed":2,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor : tensor([[0.5855, 0.8775, 0.0503, 0.5365],\n","        [0.4936, 0.0427, 0.9056, 0.7863],\n","        [0.9528, 0.9667, 0.9390, 0.5331]])\n","Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}]},{"cell_type":"code","source":["# Returns a tensor filled with the scalar value 1,with the shape defined by the argument size.\n","tensor = torch.ones(4, 4)\n","print(tensor)\n","# 모든 행에 대해서 1번열에 0값을 대입\n","tensor[:,1] = 0\n","print(tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5E-stBHEyp9L","outputId":"d8607299-8ab6-4084-832e-ce4cb73af768","executionInfo":{"status":"ok","timestamp":1664910269262,"user_tz":-540,"elapsed":634,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.]])\n","tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}]},{"cell_type":"code","source":["# Concatenate : 텐서를 연결하기\n","# 딥러닝에서는 모델의 입력 또는 중간 연산 단계에서 두 개의 텐서를 연결하는 경우가 있습니다.\n","# 두 텐서를 연결해서 입력으로 사용하는 것은 두 텐서에 담긴 정보를 모두 사용한다는 의미입니다. \n","# dim : 텐서를 연결하여 어느 차원을 늘릴 것인지를 표시\n","t1 = torch.cat([tensor, tensor], dim=0) # 두 텐서를 연결하여 0번째 차원을 늘리라는 의미\n","print(\"tensor shape:\", tensor.shape)\n","print(\"->\", t1)\n","print(\"t1 shape:\", t1.shape) # 0번째 dimension이 늘어난 것을 확인\n","print(\"----------------------------\")\n","t2 = torch.cat([tensor, tensor], dim=1) # 두 텐서를 연결하여 1번째 차원을 늘리라는 의미\n","print(\"tensor shape:\", tensor.shape)\n","print(\"->\", t2)\n","print(\"t2 shape:\", t2.shape) # 1번째 dimension이 늘어난 것을 확인"],"metadata":{"id":"mlRH8Fzryt-3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664910271225,"user_tz":-540,"elapsed":16,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"ab4dedba-8541-4e25-e1ee-3829279d445a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor shape: torch.Size([4, 4])\n","-> tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n","t1 shape: torch.Size([8, 4])\n","----------------------------\n","tensor shape: torch.Size([4, 4])\n","-> tensor([[1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1.]])\n","t2 shape: torch.Size([4, 8])\n"]}]},{"cell_type":"markdown","source":["#신경망 모델 생성하기\n","\n","모든 신경망 클래스는 torch.nn 패키지를 통해서 생성합니다.\n","\n","torch.nn.Module은 PyTorch의 모든 신경망의 Base Class이며 새로운 신경망 모델은 torch.nn.Module 클래스를 상속하여 정의해야 합니다.\n","\n","새로운 클래스 내에서 \\__init()__함수와 forward()함수를 반드시 override 해야 합니다.\n","\n","\\__init()__함수에서는 모델에서 사용될 module(nn.Linear, nn.Conv2d), activation function(ReLU 등)를 정의합니다. \n","\n","forward()에서는 모델에서 실행되어야 하는 연산을 정의합니다.\n","\n","backward 연산은 backward() 함수를 호출하면 PyTorch가 자동으로 수행하므로 forward()만 정의합니다.\n","\n","forward()에서는 input 데이터에 대해 어떤 연산을 진행하여 output이 나올지를 정의해 주는 것입니다. "],"metadata":{"id":"MFaz5onfc3V9"}},{"cell_type":"code","source":["import torch.nn as nn           # 신경망 구현을 위한 데이터 구조, 신경망 레이어 등이 정의되어 있음 \n","import torch.nn.functional as F # Convolution, Pooling, Activation, Linear 함수 등이 정의되어 있음"],"metadata":{"id":"6Qwmr5Lxcurf","executionInfo":{"status":"ok","timestamp":1664910276380,"user_tz":-540,"elapsed":506,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# torch.nn.Module은 PyTorch의 모든 신경망의 Base Class\n","# __init()__과 forward()를 반드시 override 해야 한다.\n","class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    # 입력 이미지 채널 1개, 출력 채널 6개, 5x5의 정사각 컨볼루션 행렬\n","    # 컨볼루션 커널 정의\n","    # nn.Conv2d(in_channels, out_channels, kernel_size, stride=1)\n","    self.conv1 = nn.Conv2d(1, 6, 5)   # 입력 채널 크기, 출력 채널 크기, 커널 크기\n","    self.conv2 = nn.Conv2d(6, 16, 5)  # 입력 채널 크기, 출력 채널 크기, 커널 크기\n","    \n","    # Fully Connected Layer: y = Wx + b\n","    self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5은 이미지 차원에 해당\n","    self.fc2 = nn.Linear(120, 60)\n","    self.fc3 = nn.Linear(60, 10)\n","\n","  def forward(self, x):\n","    # convolution을 거치게 되면 이미지의 크기는 kernel - 1만큼 감소함\n","    # 현재 입력되는 이미지의 크기가 32 X 32\n","    # conv1을 통해 출력되는 이미지의 크기는 (32 - 5 + 1) X (32 - 5 + 1) = 28 X 28\n","    # (2, 2) 크기 윈도우에 대해 맥스 풀링 -> 이미지의 크기는 2분의 1이 되므로 -> 최종 출력 이미지 크기는 14 X 14\n","    # torch.nn.functional.max_pool2d(input, kernel_size)\n","    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # [batch size, 채널 크기, 이미지 가로 크기, 이미지 세로 크기] == [1, 6, 14, 14] \n","\n","    # conv2을 통해 출력되는 이미지의 크기는 (14 - 5 + 1) X (14 - 5 + 1) = 10 X 10\n","    # (2, 2) 크기 윈도우에 대해 맥스 풀링 -> 이미지의 크기는 2분의 1이 되므로 -> 최종 출력 이미지 크기는 5 X 5\n","    # 크기가 제곱수라면, 하나의 숫자만을 특정(specify)\n","    x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2)) # [1, 16, 5, 5]\n","    # torch.flatten(input, start_dim, end_dim) : flattens input by reshaping it into a one-dimensional tensor. \n","    x = torch.flatten(x, 1) # batch 차원을 제외한 모든 차원을 하나로 평탄화(flatten) [1, 16 * 5 * 5]\n","    x = F.relu(self.fc1(x)) # [1, 120]\n","    x = F.relu(self.fc2(x)) # [1, 60]\n","    x = self.fc3(x) # [1, 10]\n","    return x"],"metadata":{"id":"Jr5g3dg0c9nv","executionInfo":{"status":"ok","timestamp":1664910278357,"user_tz":-540,"elapsed":8,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["net = Net()\n","print(net)"],"metadata":{"id":"OS3iirUStWXR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ea00318-03ab-4100-e832-7180932ad3b4","executionInfo":{"status":"ok","timestamp":1664910283244,"user_tz":-540,"elapsed":518,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=60, bias=True)\n","  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["input = torch.randn(1, 1, 32, 32) # [batch size, 입력 채널 크기, 가로 길이, 세로 길이]\n","out = net(input)\n","print(\"out shape:\", out.shape)\n","print(out)  # out shape: (1, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Rt3x6jpdHw5","outputId":"f15dae37-7e2b-4458-f3c6-d80329efeaf2","executionInfo":{"status":"ok","timestamp":1664910637607,"user_tz":-540,"elapsed":485,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["out shape: torch.Size([1, 10])\n","tensor([[ 0.6728,  0.2974,  0.3051,  0.1006, -0.1383, -0.0678,  0.3153, -0.4468,\n","         -0.7662, -0.0346]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["# view 함수 : reshape 함수. 텐서의 형태(Shape)를 변경함. 변경 전과 후에 원소의 갯수는 유지되어야 한다.\n","# view(1, -1) : 첫번째 차원은 1이 되도록 하되,-1로 표시된 2번째 차원은 파이토치가 알아서 계산하라는 의미\n","output = net(input)               # 입력 데이터를 신경망 모델에 전달하여 예측값을 얻음 shape: (1, 10)\n","print(\"output shape:\", output.shape)\n","target = torch.randn(10)          # 임의의 텐서를 생성하여 정답값으로 가정\n","print (\"target shape:\", target.shape)\n","target = target.view(1, -1)       # 모델의 출력 텐서와 동일한 shape로 변경 : (1, 10)\n","print (\"after reshape(view) -> target shape:\", target.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nH6NhU2EdZ39","outputId":"acf2cf6b-194c-4275-cc55-e668b5b659b8","executionInfo":{"status":"ok","timestamp":1664910305205,"user_tz":-540,"elapsed":558,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["output shape: torch.Size([1, 10])\n","target shape: torch.Size([10])\n","after reshape(view) -> target shape: torch.Size([1, 10])\n"]}]},{"cell_type":"markdown","source":["손실함수 (Loss Function) 설정"],"metadata":{"id":"D1M56m1Joo4p"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# 어떤 텐서가 학습에 필요한 텐서라면 backpropagation을 통하여 gradient를 구해야 합니다.\n","# 텐서의 옵션 requireds_grad를 True로 설정하면 텐서에 실행되는 모든 연산들을 트랙킹하여 자동으로 gradient를 계산합니다.\n","input = torch.randn(3, 5, requires_grad=True) \n","target = torch.randn(3, 5)\n"," # 손실함수로 MSE(Mean Squared Error)를 설정\n"," # 평균제곱오차(MSE)는 오차를 제곱한 값의 평균. 오차란 모델이 예측한 값과 실제 정답과의 차이\n","criterion = nn.MSELoss()          \n","output = criterion(input, target) # Loss 계산\n","output.backward()\n","print('input: ', input)\n","print('target: ', target)\n","print('output: ', output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OF9WEhcIoidP","executionInfo":{"status":"ok","timestamp":1664910308809,"user_tz":-540,"elapsed":669,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"a2fed3ab-58bb-49b0-c06c-da72190b4fd9"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["input:  tensor([[-1.4363,  0.8023, -0.9195,  0.5463, -0.9097],\n","        [ 0.2874,  0.2714,  0.1318, -0.9672, -0.8942],\n","        [-1.2598, -0.4339,  0.3449,  0.8279,  0.5581]], requires_grad=True)\n","target:  tensor([[ 1.5264, -1.4867,  0.5545,  1.6647,  0.5131],\n","        [ 0.3143, -0.0900, -0.4292, -0.1733,  0.4779],\n","        [-0.0040,  0.9531,  0.0668,  0.9897,  0.5251]])\n","output:  tensor(1.7352, grad_fn=<MseLossBackward0>)\n"]}]},{"cell_type":"markdown","source":["옵티마이저 설정"],"metadata":{"id":"1el6Hg6D5_xN"}},{"cell_type":"code","source":["# torch.optim : 신경망 학습을 위한 파라미터 최적화 알고리즘이 구현되어 있는 클래스\n","import torch.optim as optim\n","# Adam Optimizer 객체 생성\n","optimizer = optim.Adam(net.parameters(), lr=0.01)\n","\n","# 학습 과정(training loop)\n","# Pytorch에서는 gradients 값들을 backward를 할 때 계속 누적하기 때문에 \n","# 학습을 시작하기 전에 gradients 버퍼를 zero로 reset해야 한다.\n","optimizer.zero_grad()\n","\n","input = torch.randn(1, 1, 32, 32)\n","output = net(input)\n","target = torch.randn(10)          # 예시를 위한 임의의 정답\n","target = target.view(1, -1)       # 출력과 같은 shape로 만듬\n","loss = criterion(output, target)  # Loss 계산\n","print(loss)\n","\n","loss.backward()         # 역전파 함수 실행을 통해 gradient 계산\n","optimizer.step()        # gradient를 기반으로 실제 파라미터 업데이트를 실행"],"metadata":{"id":"dNH1E4BbeFP3","executionInfo":{"status":"ok","timestamp":1664910323724,"user_tz":-540,"elapsed":485,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc83f5df-5b06-4efc-db0a-5cb4ca28e92b"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.0392, grad_fn=<MseLossBackward0>)\n"]}]},{"cell_type":"code","source":["# torch.optim : 신경망 학습을 위한 파라미터 최적화 알고리즘들이 구현되어 있는 팩키지\n","import torch.optim as optim\n","# Optimizer 객체를 생성하고 모델의 파라미터를 전달, learning rate 설정\n","optimizer = optim.Adam(net.parameters(), lr=0.01) \n","\n","# 학습 과정(training loop)\n","# Pytorch에서는 gradients 값들을 backward를 할 때 계속 누적하기 때문에 \n","# 학습을 시작하기 전에 gradients 버퍼를 zero로 reset해야 한다.\n","optimizer.zero_grad()\n","\n","input = torch.randn(1, 1, 32, 32)\n","output = net(input)\n","target = torch.randn(10)          # 예시를 위한 임의의 정답\n","target = target.view(1, -1)       # 출력과 같은 shape로 만듬\n","loss = criterion(output, target)  # Loss 계산\n","print(loss)\n","\n","loss.backward()         # 역전파 함수 실행을 통해 gradient 계산\n","optimizer.step()        # 파라미터 업데이트를 실행"],"metadata":{"executionInfo":{"status":"ok","timestamp":1664909852609,"user_tz":-540,"elapsed":657,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6491be8-4f0b-40f5-f247-577e31521d40","id":"2lZ1-34tX2yW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.4354, grad_fn=<MseLossBackward0>)\n"]}]},{"cell_type":"markdown","source":["GPU 가속 이용하기"],"metadata":{"id":"kHymma7IcdaH"}},{"cell_type":"code","source":["# 현재 개발환경에서 GPU 가속이 가능한지 확인\n","print(torch.cuda.is_available())"],"metadata":{"id":"_rNJ7nfhcfbS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664903397116,"user_tz":-540,"elapsed":11,"user":{"displayName":"김나리","userId":"01119342099285995005"}},"outputId":"1047a079-660c-496a-80f6-f7742ea1647c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["# GPU 사용이 가능하면 cuda로 연산하도록 device를 설정 그렇지 않으면 cpu로 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RuZAiUbhcnk6","outputId":"a10ee28b-d0fe-47eb-850c-848df80902aa","executionInfo":{"status":"ok","timestamp":1664903403456,"user_tz":-540,"elapsed":4009,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=60, bias=True)\n","  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["PyTorch TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","데이터셋을 샘플링하고, 학습 루프를 편리하게 구현하기 위한 함수"],"metadata":{"id":"ZMNF4FcTgHX4"}},{"cell_type":"code","source":["# 랜덤한 학습 데이터 생성\n","train_inputs = torch.randn(100, 32, 128) # [전체 데이터 개수, 데이터의 최대 길이, 히든 벡터 크기]\n","train_labels = torch.randn(100, 3) # [전체 데이터 개수, 예측할 클래스 개수]\n"],"metadata":{"id":"0hQGB9FQgFmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset에 필요한 패키지 임포트\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"],"metadata":{"id":"dTqLJd41gZ8g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 12 # 매 학습 Step 마다 샘플링할 데이터 개수\n","\n","train_data = TensorDataset(train_inputs, train_labels) # 학습데이터와 레이블을 하나의 TensorDataset으로 결합 가능\n","train_sampler = RandomSampler(train_data) # 데이터를 샘플링 할 함수(순차적으로 뽑아올지, 랜덤하게 뽑아올지)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) # 미니배치 단위로 데이터를 자동 로딩"],"metadata":{"id":"izHGZVsmgXda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataloader를 통해서 학습 루프 생성\n","for step, batch in enumerate(train_dataloader): # enumerate : 인덱스(index)와 데이터값에 동시에 접근\n","  x_data, x_label = batch\n","  # 데이터 로딩 step \n","  print(step, x_data.shape, x_label.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"so6pZGaEg5qI","outputId":"91b1eeb9-3187-462a-d484-9ca15088a395","executionInfo":{"status":"ok","timestamp":1664903412264,"user_tz":-540,"elapsed":6,"user":{"displayName":"김나리","userId":"01119342099285995005"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 torch.Size([12, 32, 128]) torch.Size([12, 3])\n","1 torch.Size([12, 32, 128]) torch.Size([12, 3])\n","2 torch.Size([12, 32, 128]) torch.Size([12, 3])\n","3 torch.Size([12, 32, 128]) torch.Size([12, 3])\n","4 torch.Size([12, 32, 128]) torch.Size([12, 3])\n","5 torch.Size([12, 32, 128]) torch.Size([12, 3])\n","6 torch.Size([12, 32, 128]) torch.Size([12, 3])\n","7 torch.Size([12, 32, 128]) torch.Size([12, 3])\n","8 torch.Size([4, 32, 128]) torch.Size([4, 3])\n"]}]}]}