{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e892ca-4061-4bfa-91e3-d55de043b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "회귀문제, 텍스트 다중분류문제, 이미지 이진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64232e73-99cf-4db2-9d6d-a7c936e652ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('raw_data/onenavi_train.csv', sep='|')\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "df_total = pd.concat([df, df2])\n",
    "\n",
    "df_total.shape\n",
    "\n",
    "df_total = pd.merge(df3, df_total, on='RID')\n",
    "df_total = pd.merge(df4, df_total, on='RID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f75e79-ae97-4fd1-bb38-5814120d49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 한글폰트 설정\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font=\"NanumGothicCoding\", \n",
    "        rc={\"axes.unicode_minus\":False}, # 마이너스 부호 깨짐 현상 해결\n",
    "        style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebbcd0-13e8-4873-8c2e-2017c748f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "sns.countplot(data=df_total, x='level1_pnu')\n",
    "\n",
    "sns.distplot(df_total['ET'])\n",
    "\n",
    "sns.boxenplot(data=df_total, x='level1_pnu', y='ET')\n",
    "\n",
    "sns.pairplot(df_total)\n",
    "\n",
    "df_cor = df_total.corr()\n",
    "sns.heatmap(df_cor,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168dd171-0bf4-495d-9ee0-17a10e8a1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리\n",
    "df_total.isnull().sum()\n",
    "\n",
    "sample = sample.fillna(method='ffill') # bfill\n",
    "\n",
    "# 이상치 처리\n",
    "sns.scatterplot(x='A_DISTANCE', y='ET', data=df_total)\n",
    "\n",
    "df_total = df_total[df_total['ET']<15000] # (15,000초 이하 데이터만 남기기)\n",
    "\n",
    "# 변수 생성\n",
    "df_total['PerHour'] = (df_total['A_DISTANCE']/1000) / (df_total['ET']/3600) # 평균 시속 변수\n",
    "\n",
    "PerHour.max()\n",
    "\n",
    "df_total = df_total[df_total['PerHour']<=130] # 130km/h 초과의 수치는 제거\n",
    "\n",
    "# 추가 변수\n",
    "# 추가 변수 데이터 로딩\n",
    "df_pnu = pd.read_csv('raw_data/onenavi_pnu.csv',sep=\"|\")\n",
    "df_signal = pd.read_csv('raw_data/onenavi_signal.csv',sep=\"|\")\n",
    "\n",
    "# 데이터 합치기\n",
    "df_total = pd.merge(df_total,df_pnu, on = 'RID')\n",
    "df_total = pd.merge(df_total,df_signal, on = 'RID')\n",
    "\n",
    "df_total.values\n",
    "\n",
    "# 'level1_pnu' 변수를 기준, 제거\n",
    "df_total = df_total[df_total['level1_pnu'].isin(['경기도', '서울특별시', '인천광역시'])]\n",
    "df_total['level1_pnu'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbddf81-35b7-4e0a-8c96-738f37fbb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 요일, 시간, 날짜 변수를 'TIME_DEPARTUREDATE'에서 분리하고 변수를 만드는 소스코드\n",
    "from dateutil.parser import parse\n",
    "from tqdm import tqdm\n",
    "\n",
    "weekday_list=[]\n",
    "hour_list=[]\n",
    "day_list=[]\n",
    "\n",
    "for w in tqdm(df_total['TIME_DEPARTUREDATE']):\n",
    "    parse_data_w=parse(w)\n",
    "    weekday_list.append(parse_data_w.weekday())\n",
    "    hour_list.append(parse_data_w.hour)\n",
    "    day_list.append(parse_data_w.day)\n",
    "00\n",
    "df_total['WEEKDAY'] = weekday_list\n",
    "df_total['HOUR'] = hour_list\n",
    "df_total['DAY'] = day_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d54dc-1d5f-4072-aa84-42eb18b5133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더미 변수\n",
    "df_total = pd.get_dummies(df_total, columns=['WEEKDAY', 'HOUR', 'level1_pnu', 'level2_pnu'] ,prefix='dummy', drop_first=False)\n",
    "\n",
    "df_total.shape # (행, 열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849969a-f62a-4243-b709-c07cb8f7ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가데이터 별도 저장 : 원본 기준(나중에 활용)\n",
    "import os\n",
    " \n",
    "if not os.path.exists(\"add_data\"):\n",
    "    os.makedirs(\"add_data\")\n",
    "    \n",
    "new_df_eval=df_total[df_total['DAY']>=27][['ET','ETAA']]\n",
    "new_df_eval.to_csv(\"add_data/onenavi_evaluation_et.csv\",sep=\"|\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf8eab1-e325-46cd-b046-71f7f95c7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "data_day = df_total['DAY']\n",
    "scale_data = df_total.drop(['RID', 'TIME_DEPARTUREDATE', 'TIME_ARRIVEDATE', 'ET', 'ETAA', 'PerHour', 'DAY'], axis=1)\n",
    "\n",
    "columnNames = scale_data.columns\n",
    "\n",
    "columnNames = list(columnNames)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "feature = scaler.fit_transform(scale_data)\n",
    "feature = pd.DataFrame(feature)\n",
    "feature.columns = columnNames\n",
    "feature['DAY'] = data_day \n",
    "\n",
    "train_feature = feature.loc[feature['DAY'] <= 24] # (~24일)\n",
    "evaluation_feature = feature.loc[feature['DAY'] >= 27] # (27일~)\n",
    "\n",
    "\n",
    "train_feature = train_feature.drop('DAY', axis = 1)\n",
    "evaluation_feature = evaluation_feature.drop('DAY', axis = 1)\n",
    "\n",
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbfb02-217b-47c0-bb5c-d19bded74cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV로 저장\n",
    "train_feature.to_csv('add_data/onenavi_train_feature.csv',index = False,sep='|')\n",
    "df_total[df_total['DAY']<=24]['ET'].to_csv('add_data/onenavi_train_target.csv',index = False,sep='|')\n",
    "evaluation_feature.to_csv('add_data/onenavi_evaluation_feature.csv',index = False,sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e2aad-7a54-4e20-b76d-ed516384d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_feature, df_target,test_size=.2 ,random_state=42)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a65bed-dbac-46c6-b1a9-db57cc3acef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장을 위해 폴더를 생성하겠습니다.\n",
    "import os\n",
    " \n",
    "if not os.path.exists(\"model\"):\n",
    "    os.makedirs(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79f38f-80e5-481f-b07c-2f974c417a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링(머신러닝)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import *\n",
    "LR = LinearRegression()\n",
    "LR.fit(train_x, train_y)\n",
    "pred = model.predict(test_x)\n",
    "print(mean_squared_error(test_y, pred, squared=False).round(5))\n",
    "print(r2_score(test_y, pred).round(5))\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF = RandomForestRegressor(n_estimators=100,max_depth=5,min_samples_split=30,min_samples_leaf=15,random_state=42)\n",
    "RF.fit(train_x, train_y)\n",
    "pred = model.predict(test_x)\n",
    "print(mean_squared_error(test_y, pred,squared=False).round(5))\n",
    "print(r2_score(test_y,pred).round(5))\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GB = GradientBoostingRegressor(n_estimators=100,learning_rate=0.1,max_depth=5,min_samples_split=30,min_samples_leaf=15,random_state=42 )\n",
    "GB.fit(train_x, train_y)\n",
    "pred = GB.predict(test_x)\n",
    "print(mean_squared_error(pred, test_y,squared=False).round(5))\n",
    "print(r2_score(pred, test_y).round(5))\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "XGB = XGBRegressor(n_estimators=100,gamma=1,eta=0.1,max_depth=5,reg_lambda=5,reg_alpha=5,random_state=42)\n",
    "XGB.fit(train_x, train_y)\n",
    "pred = XGB.predict(test_x)\n",
    "print(mean_squared_error(test_y, pred,squared=False).round(5))\n",
    "print(r2_score(test_y, pred).round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d64b7f-d58e-4327-b4ba-b903b982400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature의 중요도 확인\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d0f47-96aa-4de6-b871-a151c07708d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names):\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    fi_df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    plt.figure(figsize=(10,18))\n",
    "    sns.barplot(x='feature_importance', y='feature_names', data = fi_df)\n",
    "\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    plt.grid()\n",
    "\n",
    "    return fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667431b-ed08-4bd5-9046-919c8b48d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(RF.feature_importances_, list(train_x))\n",
    "\n",
    "result = plot_feature_importance(GB.feature_importances_, list(train_x))\n",
    "\n",
    "result = plot_feature_importance(XGB.feature_importances_, list(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7463601-92f3-4694-9a20-cc08abb58074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl 파일을 저장하는데 도움을 주는 라이브러리\n",
    "import joblib\n",
    "\n",
    "joblib.dump(LR, 'model/model_0.pkl')\n",
    "joblib.dump(RF, 'model/model_1.pkl')\n",
    "joblib.dump(GB, 'model/model_2.pkl')\n",
    "joblib.dump(XGB, 'model/model_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3fc46-1606-4055-86f8-65987b4c1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링 (딥러닝)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# CNN\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(108,)))\n",
    "model.add(keras.layers.Dense(64, activation='relu', name='hidden1'))\n",
    "model.add(keras.layers.Dense(64, activation='relu', name='hidden2'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae','mse'])\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpoint_path='model_ck/cp.ckpt'\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "mc = ModelCheckpoint(filepath=checkpoint_path,monitor='val_loss', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "model.fit(train_x, train_y, verbose=1, epochs=10, callbacks=[es,mc],validation_split=0.2)\n",
    "\n",
    "history = model.predict(test_x)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "print(f1_score(test_y, history))\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "model.save('./model/DeeplearningModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c49aef-79b1-45c0-b4e2-9a9e40d1b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "# 필요한 라이브러리 import\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "# 모델을 담을 빈 리스트 생성\n",
    "model_result = []\n",
    "\n",
    "from keras.models import load_model\n",
    "m1 = load_model('model/DeeplearningModel.h5')\n",
    "model_result.append(m1)\n",
    "\n",
    "m2 = joblib.load('model/model_0.pkl')\n",
    "m3 = joblib.load('model/model_1.pkl')\n",
    "m4 = joblib.load('model/model_2.pkl')\n",
    "m5 = joblib.load('model/model_3.pkl')\n",
    "model_result.append(m2)\n",
    "model_result.append(m3)\n",
    "model_result.append(m4)\n",
    "model_result.append(m5)\n",
    "\n",
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034354df-3b08-4359-9622-bfde86509ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측 결과 비교\n",
    "#'calculation_etaa'함수 정의\n",
    "def calculation_etaa(et, eta):\n",
    "    etaa = (1-(abs(et-eta)/et))*100.0\n",
    "    etaa[(etaa < 0)] = 0\n",
    "    return etaa\n",
    "\n",
    "\n",
    "# 아래에 실습코드를 실행시키세요.\n",
    "e1_list = ['ETA1', 'ETA2', 'ETA3', 'ETA4', 'ETA5']\n",
    "e2_list = ['ETAA1', 'ETAA2', 'ETAA3', 'ETAA4', 'ETAA5']\n",
    "\n",
    "for e1, e2, model in zip(e1_list, e2_list, model_result):\n",
    "    df_evaluation_target[e1] = model.predict(df_evaluation_feature)\n",
    "    etaa_value = calculation_etaa(df_evaluation_target['ET'], df_evaluation_target[e1])\n",
    "    df_evaluation_target[e2] = etaa_value\n",
    "\n",
    "# mean, min, max, std\n",
    "etaa = ['ETAA', 'ETAA1', 'ETAA2', 'ETAA3', 'ETAA4', 'ETAA5']\n",
    "alg = ['DATA', 'ML-LG', 'ML-RFR', 'ML-GBR', 'XBR', 'Deep']\n",
    "\n",
    "print('+-------------------------------------------------------+')\n",
    "print('|   ALG    | Mean(%) |    STD    |  MIN(%)  |  MAX(%)   |')\n",
    "print('+----------+---------+-----------+----------+-----------+')\n",
    "for i, e in zip(range(len(alg)), etaa):\n",
    "    eMean = df_evaluation_target[e].mean()\n",
    "    eStd = df_evaluation_target[e].std()\n",
    "    eMin = df_evaluation_target[e].min()\n",
    "    eMax = df_evaluation_target[e].max()\n",
    "    print('|  {:6s}  |   {:3.1f}  |   {:05.1f}   |   {:4.1f}   |  {:7.1f}  | '.format(alg[i], eMean, eStd, eMin, eMax))\n",
    "print('+----------+---------+-----------+----------+-----------+\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ecb7aa-4548-4e99-a02b-36f80a6f4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ett = calculation_etaa(test_y['ET'], pred_cat)\n",
    "print(np.mean(ett), np.var(ett))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f03780-3737-435f-8896-a6ab61def91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 최적화\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import *\n",
    "xgb = XGBRegressor(n_estimators=123,gamma=1,max_depth=5,reg_lambda=5,\n",
    "                   reg_alpha=5,random_state=42, learning_rate=0.09)\n",
    "xgb.fit(train_x, train_y)\n",
    "pred = xgb.predict(test_x)\n",
    "print('RMSE: ', mean_squared_error(test_y, pred, squared=False))\n",
    "print('R-squared Score: ', r2_score(test_y, pred))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(xgb,'model/4_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab0eb2-64d9-4b43-8424-0b0acf77af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "params= {'learning_rate' : np.linspace(0.01,0.2, 100), 'n_estimators':range(60,200,80), 'max_depth': [6] }\n",
    "xgb = XGBRegressor(random_state =42)\n",
    "xgb_gs = GridSearchCV(xgb, params, cv=5, verbose=2, scoring = 'neg_mean_absolute_error')\n",
    "xgb_gs.fit(train_x, train_y)\n",
    "pred = m.predict(test_x)\n",
    "#grid_param = {'n_estimators':range(1,200,10), \"learning_rate\" : np.linspace(0.001,0.3,20), \"max_depth\" : range(1,13) }\n",
    "# model_xgb = XGBClassifier()\n",
    "# model_xgb_gs = GridSearchCV(model_xgb, grid_param, cv = 3)\n",
    "# model_xgb_gs.fit(train_x, train_y)\n",
    "# joblib.dump(model_xgb_gs, 'model/4_model.pkl')\n",
    "\n",
    "print('RMSE: ', mean_squared_error(test_y, pred, squared=False))\n",
    "print('R-squared Score: ', r2_score(test_y, pred))\n",
    "joblib.dump(xgb_gs,'model/5_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e298588-511e-451c-af43-0a1868be8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "#'calculation_etaa'함수 정의\n",
    "def calculation_etaa(et, eta):\n",
    "    etaa = (1-(abs(et-eta)/et))*100.0\n",
    "    etaa[(etaa < 0)] = 0\n",
    "    return etaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270cfe97-10ea-4f98-afe0-390a181d6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 심화 문제\n",
    "import pandas as pd\n",
    "\n",
    "# 학습/평가 데이터 로딩\n",
    "df = pd.read_csv('raw_data/onenavi_train.csv',sep=\"|\")\n",
    "df_eval = pd.read_csv('raw_data/onenavi_evaluation.csv',sep=\"|\")\n",
    "\n",
    "# 데이터 합치기\n",
    "df_total = pd.concat([df,df_eval])\n",
    "\n",
    "# 학습/평가 데이터 로딩\n",
    "df_feature = pd.read_csv(\"add_data/onenavi_train_feature.csv\",sep=\"|\")\n",
    "df_target = pd.read_csv(\"add_data/onenavi_train_target.csv\",sep=\"|\")\n",
    "\n",
    "# 학습/평가 데이터 로딩\n",
    "df_evaluation_target = pd.read_csv(\"add_data/onenavi_evaluation_et.csv\",sep=\"|\")\n",
    "df_evaluation_feature = pd.read_csv(\"add_data/onenavi_evaluation_feature.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a545c-9428-411e-a6d2-66fbb58ab18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=221, max_features = 19,random_state=42)\n",
    "rf_model.fit(train_x, train_y)\n",
    "\n",
    "# (n_estimators = 122, max_features = 19)\n",
    "y_pred = rf_model.predict(test_x)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "print('RMSE : ', mean_squared_error(test_y, y_pred, squared=False))\n",
    "print('MAE  : ', mean_absolute_error(test_y, y_pred))\n",
    "print('MAPE : ', mean_absolute_percentage_error(test_y, y_pred))\n",
    "print('r2_score : ', r2_score(test_y, y_pred))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(rf_model, 'model/6_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776d3d3-2bae-483c-a6ea-0a2c6e782042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "clear_session()\n",
    "model = Sequential()\n",
    "# 레이어 블록 조립\n",
    "model.add(Input(shape=(108,)))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "# 요약\n",
    "model.summary()\n",
    "import os\n",
    "# 컴파일\n",
    "model.compile(loss='mse', metrics=['mae','mse'],optimizer='adam')\n",
    "\n",
    "checkpoint_path = \"weights/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "ck = ModelCheckpoint(checkpoint_path,save_weights_only=True,save_best_only = True)\n",
    "\n",
    "# early_stopping\n",
    "es = EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                   patience=5,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "model.fit(train_x, train_y,  validation_split=0.2, epochs=10, callbacks=[ck,es])\n",
    "\n",
    "pred = model.predict(test_x)\n",
    "print('RMSE : ', mean_squared_error(test_y, pred, squared=False))\n",
    "print('MAE  : ', mean_absolute_error(test_y, pred))\n",
    "print('MAPE : ', mean_absolute_percentage_error(test_y, pred))\n",
    "print('r2_score : ', r2_score(test_y, pred))\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "model.save('model/DeeplearningModel_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d4287-eb13-49ec-be14-60e10f9ba110",
   "metadata": {},
   "source": [
    "## 추가(전처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64492685-b77a-4114-80f0-5c51f747bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 임포트 하기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9db226-623a-4ef0-b28f-00aa5fba9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 컬럼 \"voc_trt_perd_itg_cd\" 데이터 확인 및 값 분포 확인\n",
    "df['voc_trt_perd_itg_cd'].value_counts()\n",
    "\n",
    "# 첫번째 컬럼 \"voc_trt_perd_itg_cd\" 값 분포 비율 확인\n",
    "df['voc_trt_perd_itg_cd'].value_counts(normalize=True)\n",
    "\n",
    "# 불필요한 칼럼 삭제\n",
    "# '_' 데이터 비율이 54% 차지하는 것으로 확인됨으로 해당 컬럼은 학습 데이터로 적합하지 않음으로 삭제\n",
    "df1 = df.drop(columns=['voc_trt_perd_itg_cd'])\n",
    "\n",
    "# 날짜 관련 칼럼 확인 및 삭제\n",
    "df[['new_date', 'opn_nfl_chg_date', 'cont_fns_pam_date']].head()\n",
    "df.drop(columns=['new_date', 'opn_nfl_chg_date', 'cont_fns_pam_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53760c3f-f271-4c1a-a4ca-fefd8eb021c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입 변경\n",
    "# 숫자형 데이터가 문자형으로 저장된 경우의 사칙연산\n",
    "df['age_itg_cd'][4]+df['age_itg_cd'][5]\n",
    "\n",
    "df=df.astype({'age_itg_cd': int})\n",
    "#\"_\" 항목을 NaN 값으로 치환\n",
    "df['age_itg_cd'] = df['age_itg_cd'].replace(\"_\", np.NaN)\n",
    "\n",
    "# 'age_itg_cd' 컬럼의 \"_\" 값이 Null 값을오 바뀐 것을 확인\n",
    "df['age_itg_cd'].isnull().sum()\n",
    "\n",
    "# 'age_itg_cd' 항목의 type 변경\n",
    "# NaN의 경우 int type을 지원하지 않아 float type으로 변경\n",
    "df=df.astype({'age_itg_cd': float})\n",
    "\n",
    "##### cust_clas_itg_cd 컬럼에 '_' 값 있는지 확인 : 아직도 있습니다.\n",
    "df[df['cust_clas_itg_cd'] == '_']\n",
    "\n",
    "df = df.replace('_',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3fc57-d73c-4f16-a195-79cc65670bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주의!!\n",
    "① 결측치 처리 시 주의사항\n",
    "데이터 결측치 처리시 반드시 원본 데이터를 COPY 해서 사용해야 합니다.\n",
    "\n",
    "df_fix = df.copy()\n",
    "\n",
    "② 결측치 채우기\n",
    "#fillna 함수를 사용해서 특정 숫자나 문자로 결측치를 처리하는 방법\n",
    "df=df.fillna(15)\n",
    "df.head()\n",
    "\n",
    "# 뒤에 있는 data를 사용해서 결측치를 처리하는 방법\n",
    "df=df_fix.copy()\n",
    "df=df.fillna(method='backfill')  # ffill\n",
    "df.head()\n",
    "\n",
    "# 주의!!\n",
    "단, method 파리미터 사용시 첫 Record 또는 마지막 Record가 결측치 인지 확인해야 합니다.\n",
    "\n",
    "df=df_fix.copy()\n",
    "df['age_itg_cd']=df['age_itg_cd'].replace(np.nan, df['age_itg_cd'].median())\n",
    "df.head()\n",
    "\n",
    "③ 결측치 제거하기\n",
    "#listwise 방식으로 제거 하기(record의 항목 중 1개의 값이라도 NA이면 해당 데이터 행 전체 제거)\n",
    "df=df_fix.copy()\n",
    "df=df.dropna()\n",
    "df.info()\n",
    "\n",
    "#pairwise 방식으로 제거하기(모든 항목이 NA인 데이터 행만 제거)\n",
    "df=df_fix.copy()\n",
    "df=df.dropna(how='all')\n",
    "df.info()\n",
    "\n",
    "#임계치를 설정해서 제거하기 (NA의 갯수에 따라)\n",
    "df=df_fix.copy()\n",
    "df=df.dropna(thresh=14)\n",
    "df.info()\n",
    "\n",
    "# 특정열 안에 결측치가 있을 경우 삭제하기|\n",
    "df=df_fix.copy()\n",
    "df=df.dropna(subset=['cust_clas_itg_cd'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380e443-32e4-40bf-8066-9d358b2e2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ 범주형 데이터 ## 이상치 처리하기\n",
    "df['cust_clas_itg_cd'].value_counts()\n",
    "\n",
    "# 이상치 제거하기\n",
    "df_data=df[(df['cust_clas_itg_cd']!='R')]\n",
    "print(df_data['cust_clas_itg_cd'].value_counts())\n",
    "\n",
    "# 이상치 변경하기\n",
    "df_data=df.copy()\n",
    "df_data['cust_clas_itg_cd']=df_data['cust_clas_itg_cd'].replace('R','L')\n",
    "print(df_data['cust_clas_itg_cd'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325effd4-1c36-4c21-b9e8-04aea5a015dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ 수치형 데이터 ## 이상치 처리하기\n",
    "Q1와 Q3에서 IQR 거리의 1.5배가 넘어가는 값을 Outlier 라고 합니다.\n",
    "이 값들은 이상치로써 일반적으로 제거 또는 변경하여 데이터를 분석,학습 합니다.\n",
    "단, 이상치 분석시에는 제거하지 않습니다.\n",
    "\n",
    "Median(중앙값) : 중앙값의 50% 위치\n",
    "Mean(평균값) : 평균값\n",
    "Box(박스) : Q1(25%) ~ Q3(75%) 까지 값들, IQR(Interquartile Range)\n",
    "Whiskers(수염) : Q1, Q3 로 부터 IQR 거리의 1.5배 내에서 가장 멀리 떨어진 데이터 점까지 이어져 있는 구역\n",
    "Outlier(이상치) : Whiskers 보다 바깥 쪽에 데이터가 존재하면, 통계적으로 이상치로 분류\n",
    " \n",
    "# 확인\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(df['age_itg_cd'])\n",
    "plt.show()\n",
    "\n",
    "## 이상치 제거하기\n",
    "#Q1, Q3 구하기\n",
    "q1 = df['age_itg_cd'].quantile(0.25)\n",
    "q3 = df['age_itg_cd'].quantile(0.75)\n",
    "\n",
    "# 1.5 * IQR(Q3 - Q1)\n",
    "iqr = 1.5 * (q3 - q1) \n",
    "\n",
    "# 이상치 제거하기\n",
    "df_data=df[(df['age_itg_cd'] < (q3 + iqr)) & (df['age_itg_cd'] > (q1 - iqr))]\n",
    "\n",
    "df_data.describe()\n",
    "\n",
    "## 이상치 변경하기\n",
    "# 이상치 대체값 설정하기\n",
    "age_min = q1 - iqr\n",
    "age_max = q3 + iqr\n",
    "\n",
    "# 이상치를 변경\n",
    "df[(df['age_itg_cd'] > age_max)]= age_max\n",
    "df[(df['age_itg_cd'] < age_min)]= age_min\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce4562-4f5e-4f59-89d9-f905fb65d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시각화\n",
    "\n",
    "# 'VOC처리소요시간통합코드', '고객체감기준확인소요시간'간의 관꼐를 알아보기 위해 산점도 그리기\n",
    "# Matplotlib\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y='cust_snsry_base_conf_need_time', x='voc_trt_need_time_itg_cd', data=df)\n",
    "plt.show()\n",
    "\n",
    "# 'age_itg_cd'에 대한 빈도를 10개 구간으로 구간으로 그리기\n",
    "plt.figure()\n",
    "plt.hist(df[\"age_itg_cd\"])\n",
    "plt.show()\n",
    "\n",
    "#나이대별 총이용금액 분포를 박스 그래프로 그리기\n",
    "plt.boxplot(df['age_itg_cd'])\n",
    "plt.show()\n",
    "\n",
    "#컬럼별 상과관계를 heatmap 그래프로 그리기\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()\n",
    "\n",
    "# 차트꾸미기\n",
    "#두개선을 가지는 임의의 선그래프를 그리고 범례 추가하기\n",
    "plt.plot([1,2,3], [1,4,9])\n",
    "plt.plot([2,3,4],[5,6,7])\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Game Result')\n",
    "plt.legend(['A team', 'B team'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536bf0f5-a13f-4d24-b480-629dadf94804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Engineering\n",
    "\n",
    "① Binning\n",
    "Binning은 단어 뜻 그대로 자료를 일정한 규격의 통에 넣는것 입니다.\n",
    "만약 관측치가 연속형이면서 범위가 너무 다양할 경우, 적절히 그룹을 지어주면 데이터를 이해하기가 더 쉬워질수 있기에 사용합니다.\n",
    "즉, 연속형 변수를 범주형 변수로 만드는 방법이라고 보시면 됩니다.\n",
    "\n",
    "# 'age_itg_cd'를 활describe 나이대(\"by_age\")  Feature 만들기\n",
    "df['by_age']=df['age_itg_cd']//10*10\n",
    "df=df.astype({'age_itg_cd': int, 'by_age':int})\n",
    "\n",
    "② Encoding\n",
    "기계 학습의 주요 문제 중 하나는 많은 알고리즘이 범주 형 데이터를 입력값으로 수용하지 않는다는 점인데, \n",
    "이를 Encoding을 통해 해결 할 수 있습니다.\n",
    "\n",
    "문자형 카테고리를 숫자형 카테고리 값으로 변환합니다.\n",
    "하지만 레이블 인코딩이 일괄적으로 숫자 값으로 변환이 되면서 몇몇 ML알고리즘에는 이를 적용할 경우 예측 성능이 떨어지는 경우가 발생할 수 있습니다.\n",
    "숫자로 되어 있어 잘못하면 가중치로 인식하여 값에 왜곡이 생기게 됩니다.\n",
    "이러한 특성 때문에 레이블 인코딩은 선형 회귀에는 적용하지 않습니다.\n",
    "\n",
    "# 라이브러리 임포트\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# LabelEncoder() 호출\n",
    "le = LabelEncoder()\n",
    "# LabelEncoding 결과를 새로운 컬럼을 생성하여 저장\n",
    "df['le_cust_clas_itg_cd'] = le.fit_transform(df['cust_clas_itg_cd'])\n",
    "# LabeEncoding 매핑값 확인\n",
    "le.classes_\n",
    "\n",
    "#pandas에서는 get_dummies함수를 사용하면 쉽게 One-Hot Encording이 가능\n",
    "pd.get_dummies(df['cust_clas_itg_cd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c0df0-f0ea-446c-a3de-c6ea97fdc6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Train, Test 데이터셋 분할\n",
    "① Feature / Target 데이터 분리\n",
    "Feature는 X, Target은 y로 분리\n",
    "\n",
    "# Feature는 Target('trm_yn') 제외한 나머지 \n",
    "X = df.drop(columns=['trm_yn']).values\n",
    "# Target은 해지여부('trm_yn')\n",
    "y = df['trm_yn'].values\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "② Train / Test 데이터 Set 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.3, stratify=y, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "4. 데이터 스케일링(표준화, 정규화)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 스케일러 호출\n",
    "scaler = StandardScaler()\n",
    "# 스케일링 (Train, Test)\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "x_test_std = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 스케일러 호출\n",
    "scaler = MinMaxScaler()\n",
    "# 스케일링 (Train, Test)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a736a6-da6a-42cd-a93e-badb3aacf581",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. 머신러닝 모델 구현\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 파라미터 (C: 규제강도, max_iter: 계산에 사용할 작업 수)\n",
    "lr_model = LogisticRegression()\n",
    "# 모델 학습하기\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "@ 모델 성능 평가하기\n",
    "# 오차행렬 (TN  FP, FN  TP)\n",
    "print(\"1.오차 행렬(confusion_matrix)\")\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "\n",
    "# 정확도\n",
    "print(\"\\n2.정확도(acciracy_score)\")\n",
    "print(accuracy_score(y_test, lr_pred) )\n",
    "\n",
    "# 정밀도\n",
    "print(\"\\n3.정밀도(precision_score)\")\n",
    "print(precision_score(y_test, lr_pred) )\n",
    "\n",
    "# 재현율 \n",
    "print(\"\\n3.재현율(recall_score)\")\n",
    "print(recall_score(y_test, lr_pred))  \n",
    "\n",
    "# 정밀도 + 재현율\n",
    "print(\"\\n4.F1 점수\")\n",
    "print(f1_score(y_test, lr_pred) )  \n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942a384-2906-4c5f-8e7a-d08d70035004",
   "metadata": {},
   "source": [
    "## 머신러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a594b-8e00-4179-a3cf-db39d3684013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier(n_estimators=100)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bfb5d-9979-4b6b-844d-9988cb614908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier(n_estimators=3, random_state=42)  \n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfaace7-65c0-43cf-9c4a-5eab1114692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "print(f1_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843a258-006f-4e39-ae65-eb39495e70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "print(accuracy_score(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a4423f-fc22-4a5a-a19a-8c7f2304e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(max_depth=30, n_estimators=5)\n",
    "rfc_model.fit(X_train,y_train)\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d5d44-6b45-42b9-95fb-a1b77bef9170",
   "metadata": {},
   "source": [
    "## 성능비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b402b-f723-40d6-ae14-4c6369de04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 별 accuracy, precission , recall, f1_score를 List 로 저장\n",
    "perfomance_acc = [accuracy_score(y_test, lr_pred), accuracy_score(y_test, knn_pred), accuracy_score(y_test, dt_pred), accuracy_score(y_test, rfc_pred)]\n",
    "perfomance_precission = [precision_score(y_test, lr_pred), precision_score(y_test, knn_pred), precision_score(y_test, dt_pred), precision_score(y_test, rfc_pred)]\n",
    "perfomance_recall = [recall_score(y_test, lr_pred), recall_score(y_test, knn_pred), recall_score(y_test, dt_pred), recall_score(y_test, rfc_pred)]\n",
    "perfomance_f1_score = [f1_score(y_test, lr_pred), f1_score(y_test, knn_pred), f1_score(y_test, dt_pred), f1_score(y_test, rfc_pred)]\n",
    "\n",
    "performance_index = ['accuary', 'precission', 'recall', 'f1_score']\n",
    "performance_columns = ['Logistic', 'KNN', 'Decision', 'RandomForest']\n",
    "\n",
    "# 모델 별 전체 성능을 데이터프레임으로 저장ㅌ\n",
    "performance_total= pd.DataFrame(data=[perfomance_acc, perfomance_precission, perfomance_recall, perfomance_f1_score], index=performance_index, columns=performance_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb797b2b-17bc-4ca9-8f87-f8ec486186c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa5fcc-2b32-444e-ae1b-60b5828881c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Accuracy')\n",
    "sns.barplot(x=perfomance_acc, y=performance_columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ff874-d9ff-4f57-9956-6219bf32735b",
   "metadata": {},
   "source": [
    "모델 Feature 중요도 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ecdb1-b669-4257-8be4-3e06bb39ab73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature = df.drop(columns=['trm_yn'])\n",
    "\n",
    "rfc_importances_values = rfc_model.feature_importances_\n",
    "rfc_importances = pd.Series(rfc_importances_values, index=feature.columns )\n",
    "rfc_top10 = rfc_importances.sort_values(ascending=False)[:10]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Top 10 Feature Importances')\n",
    "sns.barplot(x=rfc_top10, y = rfc_top10.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745a2a0-be20-478e-840c-7e60219495d6",
   "metadata": {},
   "source": [
    "## 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70338648-bc81-4734-8062-ed4e3e493927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a07a24-7850-409c-b88c-bc7dacd407c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(32, activation='relu', input_shape=(80,)))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e90b9-0fb3-42fb-8a7f-d6f92c0ff65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])  # MAE, RMSE(회귀모델 시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ba6e6-ed3c-43c0-a1ef-a4756b04c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(5, activation='relu', input_shape=(80,)))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(4, activation='relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40cf59-4b5e-4aa6-8850-2f349b631a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', \n",
    "              loss='sparse_catesgorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# 원-핫 인코딩이 안되어 있을 경우 다중 분류 모델의 loss는 'sparse_catesgorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584cbcb-cd51-45e7-97c9-442c0bc2e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=20, \n",
    "          batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9cc20b-9789-47b5-b1ff-e97c377bd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 콜백 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f99e64-4165-4345-85e8-4245a05a8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import  EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407872b0-cf09-4741-8a9a-16e800db0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218868d-b753-4eba-81cd-db9fc7918e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('my_checkpoint.h5', monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b924fa-0aeb-49e4-bf03-e12f4b5786ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daba57e-5ae2-46b4-a3cb-99d571419def",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=20, \n",
    "          callbacks=[es, mc],\n",
    "          batch_size=16,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e138751-3c19-4c5b-9853-605f763af1fa",
   "metadata": {},
   "source": [
    "모델 성능 평가(시각화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7459f8-8b9c-4c2b-94fa-0903affc980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(model2.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bf218-373b-42ee-b335-9b9dcbc45acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618da5d-d4ba-4d5a-8b9a-451d3956e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(performance[['loss','val_loss']])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c02e9-c11e-4888-ba72-9e0656128d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(performance[['loss','val_loss', 'accuracy','val_accuracy']])\n",
    "plt.legend(['loss','val_loss', 'accuracy','val_accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab35db2-3cbc-45e6-ba71-8ef4b80382cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc03a5d-bf5d-497c-9e31-6b3de195dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import  EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# input layer 확인 \n",
    "X_train.shape\n",
    "\n",
    "# 모델 선언 (뱐수 : model_q)\n",
    "model_q = Sequential()\n",
    "model_q.add(Dense(32, activation='relu', input_shape=(80,)))\n",
    "model_q.add(Dropout(0.3))\n",
    "model_q.add(Dense(16, activation='relu'))\n",
    "model_q.add(Dropout(0.3))\n",
    "model_q.add(Dense(8, activation='relu'))\n",
    "model_q.add(Dropout(0.3))\n",
    "model_q.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 확인\n",
    "model_q.summary()\n",
    "\n",
    "# 모델 컴파일하기\n",
    "model_q.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# callbacks 함수 설정\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1) # loss일 경우 min으로\n",
    "mc = ModelCheckpoint('model_q/my_checkpoint_q.ckpt', monitor='val_accuracy',save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_q.fit(X_train, y_train, \n",
    "                        validation_data=(X_test, y_test),\n",
    "                        epochs=20, \n",
    "                        callbacks=[es, mc],\n",
    "                        batch_size=32,\n",
    "                        verbose=1)\n",
    "\n",
    "model_q.load_weights(\"model_q/my_checkpoint_q.ckpt\")\n",
    "model_q.save(\"석재민.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb56ca-e925-4682-a328-ff3977d10df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 입력하세요.\n",
    "performance_q = pd.DataFrame(model_q.history.history)\n",
    "\n",
    "plt.plot(performance_q[['accuracy','val_accuracy']])\n",
    "plt.legend(['accuracy','val_accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6262d-6eb6-4402-bd92-236efaed8764",
   "metadata": {},
   "source": [
    "## TEXT_NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb121c-583c-4b80-bc6a-8a43fdf2b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2942f0a-faa9-4121-9a3f-95ded11057b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import rich  # 출력을 예쁘게 꾸며주는 라이브러리\n",
    "from rich.table import Table\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "train_df = pd.read_csv('spam.csv')\n",
    "test_df = pd.read_csv('spam_test_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd3c7d-30a6-4b19-9227-af0212c52dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "train_df.isna().sum()\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.drop(columns={'index'},inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7284e-1ee2-4447-aa3d-d402983942b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "train_df['label'] = train_df['label'].replace(['ham','spam'],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bade92-b486-476c-8b9a-ccbebeda1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipe(model, model_name: str) -> Pipeline:\n",
    "    \"TfidfVectorizer와 모델을 연결한 파이프라인을 반환하는 함수\"\n",
    "    tfidf = TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 3))\n",
    "    pipe = Pipeline([\n",
    "        (\"tfidf\", tfidf),\n",
    "        (model_name, model)\n",
    "    ])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a1488-50a4-44ec-ae7a-473484e44db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_kfold_accuarcy(model, k: int = 5) -> float:\n",
    "    \"모델을 입력받아 KFold 예측 후 accuracy score를 반환하는 함수\"\n",
    "    kfold = StratifiedKFold(k, shuffle=True, random_state=42)\n",
    "    result = []\n",
    "    for train_idx, test_idx in kfold.split(train_df[\"text\"], train_df[\"label\"]):\n",
    "        train, val = train_df.iloc[train_idx], train_df.iloc[test_idx]\n",
    "        model.fit(train[\"text\"], train[\"label\"])\n",
    "        pred = model.predict(val[\"text\"])\n",
    "        acc = accuracy_score(val[\"label\"], pred)\n",
    "        result.append(acc)\n",
    "\n",
    "    return np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a379e-3b3d-4014-9d5e-0be30545999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"naive_bayes\", BernoulliNB()),\n",
    "    (\"SGD\", SGDClassifier(random_state=42, n_jobs=-1)),\n",
    "]\n",
    "\n",
    "model_pipes = [(name, get_pipe(model, name)) for name, model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6fd39-adde-4327-8335-c5af1070cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\n",
    "#     (\"naive_bayes\", BernoulliNB()),\n",
    "#     (\"SGD\", SGDClassifier(random_state=42, n_jobs=-1)),\n",
    "#     (\"rfc\", RandomForestClassifier(random_state=42, n_jobs=-1)),\n",
    "#     (\"SVC\", SVC(random_state=42)),\n",
    "#     (\"ada\", AdaBoostClassifier(random_state=42)),\n",
    "#     (\"lgbm\", LGBMClassifier(random_state=42)),\n",
    "#     (\"lgbm2\", LGBMClassifier(n_estimators=80, random_state=42)),\n",
    "#     (\"xgb\", XGBClassifier(random_state=42)),\n",
    "#     (\"knc1\", KNeighborsClassifier()),\n",
    "#     (\"knc2\", KNeighborsClassifier(n_neighbors=4))\n",
    "# ]\n",
    "\n",
    "# model_pipes = [(name, get_pipe(model, name)) for name, model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd27a5-85ed-4c01-8bce-c6e122510660",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Table(title=\"Model Comparison Table\")\n",
    "table.add_column(\"Model Name\", justify=\"left\", style=\"green\")\n",
    "table.add_column(\"Accuracy\", justify=\"right\")\n",
    "\n",
    "for model_name, model in tqdm(model_pipes, leave=False):\n",
    "    acc = return_kfold_accuarcy(model)\n",
    "    table.add_row(model_name, f\"{acc:0.3f}\")\n",
    "\n",
    "rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4db547-ed33-4b25-b8bc-b31dbcbb9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stack_models = [(name, get_pipe(model, name)) for name, model in models]\n",
    "\n",
    "stacking = StackingClassifier(stack_models)\n",
    "acc = return_kfold_accuarcy(stacking)\n",
    "rich.print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894296cd-a9ae-4205-b4cc-8acac2efd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking.fit(train_df['text'], train_df['label'])\n",
    "submission_pred = stacking.predict(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c09f59-7954-43fc-8900-5f858e3b312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('spam_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6112bf5-e8a5-4b29-8cc0-af7ae1f85cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['label'] = submission_pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb97d5-ff7c-421f-9588-4583e572bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['label']= submission['label'].replace([0,1],['ham','spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f301b-f5b4-4aae-8b6e-a697de64e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"/aihub/data/M1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17252a1-07ee-4f4a-a6f2-c62bd314f3cf",
   "metadata": {},
   "source": [
    "## 스팸분류(river)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e6704-c32a-4825-8a7d-633860b5907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mecab = Mecab()\n",
    "#fm.findSystemFonts()\n",
    "plt.rcParams['font.family']= [\"NanumGothicCoding\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"]=False\n",
    "# GPU 환경 설정하기\n",
    "# assert tf.test.is_gpu_available() == True, 'GPU 설정을 확인하세요.'\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.config.list_logical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c58303-0497-4225-b53d-3b8c27e1fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv(\"spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8368f0-b09c-4986-8738-8f20a11211b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv(\"spam.csv\")\n",
    "spam_data.dropna(axis=0,inplace= True)\n",
    "spam_data.reset_index(drop=True, inplace=True)\n",
    "spam_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109657e3-92b6-44d7-8eb4-dd9ddf2daa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7742161d-b596-4291-82d1-e221952da1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data['label'] = spam_data['label'].replace(['ham','spam'],[0,1])\n",
    "spam_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb89995-fb6f-491c-a49e-c7db1cd9453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = spam_data.drop('label', axis=1, inplace=False)\n",
    "# y = spam_data['label']\n",
    "x = spam_data['text']\n",
    "y = spam_data['label']\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a87ec5-7eb2-4acf-93f2-49caaeff4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.preprocessing import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca14b9-76eb-4920-8cfd-afc91011902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 20000\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "def sequence_vectorize(train_texts, val_texts):\n",
    "\n",
    "\n",
    "   tokenizer = text.Tokenizer(num_words=TOP_K)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "    print(type(tokenizer.word_counts))\n",
    "\n",
    "   x_train = tokenizer.texts_to_sequences(train_texts)\n",
    "    x_val = tokenizer.texts_to_sequences(val_texts)\n",
    "\n",
    "   max_length = len(max(x_train, key=len))\n",
    "    print(max_length)\n",
    "    if max_length > MAX_SEQUENCE_LENGTH:\n",
    "        max_length = MAX_SEQUENCE_LENGTH\n",
    "\n",
    "   x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
    "    x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n",
    "    return x_train, x_val, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4703fb0-d31f-44c1-8c5a-b8cb67f0c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_v, x_val_v, tokenizer_word_index = sequence_vectorize(x_train, x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d1eee-2fab-4237-a45a-73e2f16417e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1d8d7-ac0c-41b7-9033-f947300dea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.layers import Embedding\n",
    "from tensorflow.python.keras.layers import SeparableConv1D\n",
    "from tensorflow.python.keras.layers import MaxPooling1D\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27035487-04fa-4dc5-a0ad-dec099413d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model =  Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=x_train_v.max()+1,\n",
    "                    output_dim=100,\n",
    "                    input_length=110))\n",
    "\n",
    "\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(rate=0.02))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d81bf1-e258-4542-b0f3-c3034c383f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b630d-7c5a-46d7-8594-e9251c097d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp = keras.callbacks.ModelCheckpoint(filepath = 'model.ckpt',monitor = 'val_loss', verbose = 1, save_best_only= True)\n",
    "es = keras.callbacks.EarlyStopping(monitor = 'val_loss', verbose=1, restore_best_weights=True,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99006280-4e78-4609-bd72-5fff1f723f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_v, y_train, epochs = 100, verbose = 1, validation_split = 0.2, callbacks = [es, mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61696b8-4900-45cd-8093-37da09402ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"spam_test_text.csv\")\n",
    "test_data.drop(\"id\", inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01136f-3011-4986-b9c8-303ba263e979",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7328bf-5a03-4a60-b72b-4e8080b310b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "import cv2, os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee23f70-4510-4dea-bec1-4b21780371a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습곡선 함수\n",
    "def dl_history_plot(history):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history['loss'], label='train_err')\n",
    "    plt.plot(history['val_loss'], label='val_err')\n",
    "\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20a622-8462-43cd-8ebc-2bda593de39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path)\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70de1e5-202b-4cdd-886f-a8346aba037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class name 찍어보기\n",
    "import string\n",
    "class_names = list(string.ascii_lowercase)\n",
    "len(class_names), class_names\n",
    "\n",
    "\n",
    "# 데이터 살펴보기\n",
    "# 아래 숫자를 바꿔가며 화면에 그려 봅시다.\n",
    "n = 10\n",
    "sign_fig = data.iloc[n, 1:].values\n",
    "sign_fig = sign_fig.reshape(28, 28)\n",
    "\n",
    "sign = class_names[data.iloc[n,0]]\n",
    "\n",
    "plt.title(sign)\n",
    "plt.imshow(255-sign_fig, cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a86fe-964d-4e09-a668-e09de45b1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "target = 'label'\n",
    "x = data.drop(target, axis = 1)\n",
    "y = data.loc[:, target]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, train_size = 20000, random_state = 2022)\n",
    "\n",
    "x_train.shape, x_val.shape\n",
    "\n",
    "# 모두 넘파이로 변환\n",
    "x_train2, x_val2, y_train2, y_val2 = x_train.values, x_val.values, y_train.values, y_val.values\n",
    "\n",
    "\n",
    "## CNN을 위해 shape 맞추기 n, 28,28,1\n",
    "x_train2 = x_train2.reshape(20000,28,28,1)\n",
    "x_val2 = x_val2.reshape(7455,28,28,1)\n",
    "\n",
    "x_train2.shape, x_val2.shape\n",
    "\n",
    "# min_max scaling\n",
    "x_train2 = x_train2 / 255.\n",
    "x_val2 = x_val2 / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be4878-dd40-49bf-937d-60c00cf2ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b210859-3990-4e43-ad14-6ec9b2e9ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(28,28,1))\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(il)\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Flatten()(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "ol = keras.layers.Dense(26, activation='softmax')(hl)\n",
    "\n",
    "M_cnn = keras.models.Model(il ,ol)\n",
    "M_cnn.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "M_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc7846-daad-406e-ac8c-c28ba548708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "mc = ModelCheckpoint('my_ck.h5', monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f9a831-a7d7-461e-866b-d4f672fa551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = M_cnn.fit(x_train2, y_train2, \n",
    "          validation_data=(x_val2, y_val2),\n",
    "          epochs=20, \n",
    "          callbacks=[es, mc],\n",
    "          batch_size=16,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978cfa8-18f7-4c27-a236-3a1072ab6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_history_plot(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e6a6f-fe20-4146-b599-4345169d3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 & 검증\n",
    "p1 = M_cnn.predict(x_val2)\n",
    "\n",
    "p1_1 = p1.argmax(axis=1)\n",
    "\n",
    "cn = np.array(class_names)\n",
    "\n",
    "print(accuracy_score(y_val,p1_1))\n",
    "print('-'*60)\n",
    "print(confusion_matrix(y_val, p1_1))\n",
    "print('-'*60)\n",
    "print(classification_report(cn[y_val], cn[p1_1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee055ac1-bb0c-48f1-9565-1a273125bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost\n",
    "!pip install category_encoders\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141088d2-4101-47e2-aea4-094014751a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본모델\n",
    "M2_cat= CatBoostClassifier()\n",
    "M2_cat.fit(x_train, y_train)\n",
    "p2 = M2_cat.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94914852-aa9f-4614-99a0-d55986fc735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화\n",
    "M3_CB = CatBoostClassifier(depth=4,bagging_temperature=2.099,learning_rate=0.02091,subsample=0.2325)\n",
    "M3_CB.fit(x_train, y_train)\n",
    "p3 = M3_CB.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81852f7a-38fd-4f88-8215-c0f0e64f3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = np.array(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37701dbb-1f79-4805-adb9-99917620e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본모델(cat)\n",
    "print(accuracy_score(y_val,p2))\n",
    "print('-'*60)\n",
    "print(confusion_matrix(y_val, p2))\n",
    "print('-'*60)\n",
    "print(classification_report(cn[y_val], cn[p2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451c81b-d665-41f9-9fa1-98fc0f8875b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화\n",
    "print(accuracy_score(y_val,p3))\n",
    "print('-'*60)\n",
    "print(confusion_matrix(y_val, p3))\n",
    "print('-'*60)\n",
    "print(classification_report(cn[y_val], cn[p3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20097b73-1236-4b91-83d4-23434532585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장하기(3가지 방식)keras, joblib, pickle\n",
    "import joblib\n",
    "joblib.dump(m1, 'sign_model_rf.pkl')\n",
    "m2.save('sign_model.h5')\n",
    "\n",
    "# 모델 로딩\n",
    "m1_2 = joblib.load('sign_model_rf.pkl')\n",
    "from keras.models import load_model\n",
    "m2_1 = load_model('sign_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642a31a-a063-410b-9160-130f8c09bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프 라인 (Data Pipeline 구성) 함수로 만들기\n",
    "\n",
    "# 파이프라인에서 필요한 라이브러리/함수\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "\n",
    "def sign_pipeline(file) :\n",
    "\n",
    "    # class names 준비\n",
    "    class_names = list(string.ascii_lowercase)\n",
    "    class_names = np.array(class_names)\n",
    "\n",
    "    # 흑백으로 읽기\n",
    "    img = cv2.imread(file , cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # 크기 조정\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "\n",
    "    # input shape 맞추기\n",
    "    test_sign = img.reshape(1,28,28,1)\n",
    "\n",
    "    # 스케일링\n",
    "    test_sign = test_sign / 255.\n",
    "\n",
    "    # 모델 로딩\n",
    "    model = load_model('sign_model.h5')\n",
    "\n",
    "    # 예측\n",
    "    pred = model.predict(test_sign)\n",
    "    pred_1 = pred.argmax(axis=1)\n",
    "\n",
    "    return class_names[pred_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec4ddc-5e02-4c1a-a021-21f864b523c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/content/drive/MyDrive/dataset/test image/v.png'\n",
    "sign_pipeline(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16319d-95cc-4461-a6d5-d1cdd67b68bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
