{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ZexYfzw47W"
   },
   "source": [
    "## 데이터 출처\n",
    "\n",
    "[Naver sentiment movie corpus]: https://github.com/e9t/nsmc/\n",
    "\n",
    "- CNN 모델의 학습을 위해 [Naver sentiment movie corpus] 데이터셋 중 일부를 추출하여 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107486,
     "status": "ok",
     "timestamp": 1664096182485,
     "user": {
      "displayName": "김나리",
      "userId": "01119342099285995005"
     },
     "user_tz": -540
    },
    "id": "4xlnVwtmM_0h",
    "outputId": "eda2f432-c849-411e-f104-f3afec78be25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torchtext==0.10.0\n",
      "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 4.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
      "Installing collected packages: torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu113\n",
      "    Uninstalling torch-1.12.1+cu113:\n",
      "      Successfully uninstalled torch-1.12.1+cu113\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.13.1\n",
      "    Uninstalling torchtext-0.13.1:\n",
      "      Successfully uninstalled torchtext-0.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
      "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
     ]
    }
   ],
   "source": [
    "# torchtext.legacy를 사용할 수 있는 torchtext 버전 설치\n",
    "!pip install -U torchtext==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20396,
     "status": "ok",
     "timestamp": 1664096211274,
     "user": {
      "displayName": "김나리",
      "userId": "01119342099285995005"
     },
     "user_tz": -540
    },
    "id": "ay1ouffYd02L",
    "outputId": "53553beb-1438-413f-bebb-38b09d147597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#colab 을 이용한 실행시\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKiGO6t0dmZx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.nn : 신경망 구현을 위한 데이터 구조, 신경망 레이어, 관련함수들이 구현되어 있는 팩키지\n",
    "# torch.nn.functional: torch.nn 팩키지의 함수들이 정의되어 있음 (손실함수, 활성화함수, 풀링함수 등) \n",
    "# torch. autograd : 미분을 위한 함수들이 정의되어 있음\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#import torchtext.data as data\n",
    "#import torchtext.datasets as datasets\n",
    "#legacy 버전으로 변경\n",
    "\n",
    "# torchtext : text의 preprocessing 파이프라인 정의, \n",
    "# 토크나이징, Vocab 생성, dataset splits, 데이터 로더 등 지원\n",
    "from torchtext.legacy import data\n",
    "import torchtext.datasets as datasets\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfjQ9Ta12O5g"
   },
   "source": [
    "<연습> 3개, 4개, 5개 단어로 된 필터(커널)를 각 100개씩 적용하는 CNN 모델을 정의하여 긍부정 분류를 실행하세요.\n",
    "\n",
    "분류 정확도를 높일 수 있는 방법을 자유롭게 시도해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5M_ahOAzdmZ3"
   },
   "outputs": [],
   "source": [
    "# CNN 모델링\n",
    "class CNN_Text(nn.Module):\n",
    "    # 생성자 : 모델의 구조와 동작을 정의\n",
    "    # 객체가 갖는 속성값을 초기화함. 객체가 생성될 때 자동으로 호출된다.\n",
    "    def __init__(self, embed_num, class_num):\n",
    "        super(CNN_Text, self).__init__() # nn.Module 클래스의 변수들을 상속\n",
    "        # V: 사전의 크기\n",
    "        # D: embed_dim\n",
    "        # C: 분류하고자 하는 클래스의 개수\n",
    "        # Co : 각 커널(필터)의 갯수\n",
    "        V = embed_num\n",
    "        D = 100 \n",
    "        C = class_num\n",
    "        \n",
    "        #--- (연습1) Co에 output channel의 갯수를 지정하세요 ---\n",
    "        # write code here \n",
    "        Co = 100 # output channel 수 (필터의 갯수)\n",
    "\n",
    "        #--- (연습2) Ks에 커널사이즈(단어 갯수)를 지정하세요 ---\n",
    "        # write code here \n",
    "        Ks = [3,4,5]\n",
    "\n",
    "        # 사전에 있는 모든 단어 벡터에 random 초기값\n",
    "        self.embed = nn.Embedding(V, D) \n",
    "        # torch.nn.Conv2d (in_channels, out_channels, kernel_size, stride=1)\n",
    "        # convs1에 컨볼루션 모듈의 리스트가 들어감 (필터(커널) 갯수만큼) \n",
    "        # forward에서 순차적으로 접근 가능\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, 100)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        # nn.Linear : Linear 레이어를 위한 클래스\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "# foward 함수 : 모델이 학습데이터를 입력받아서 forward 연산을 진행\n",
    "# model 객체를 데이터와 함께 호출하면 자동으로 실행된다.\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D) 미니배치, 문장 최대길이, 단어벡터 차원\n",
    "        x = x.unsqueeze(1)  # (N x Ci x W x D) Conv2d를 사용하려면 채널정보 추가해야 함\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks) MaxPool1D는 3D 입력만 받음\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks) max pooling 후에 마지막 차원은 1 -> squeeze\n",
    "        x = torch.cat(x, 1) # torch.cat(tensors, dim=0), dim=1이면 두번째 차원이 늘어나게 concat (첫번째 차원은 N)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co), dropout을 적용\n",
    "        logit = self.fc1(x)  # fully-connected layer 적용\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gM4G8CnWdmZ5"
   },
   "outputs": [],
   "source": [
    "class mydataset(data.Dataset):\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n",
    "        fields = [('text', text_field), ('label', label_field)] # text_field는 text로 호칭하고, label_field 필드는 label로 호칭\n",
    "        if examples is None:\n",
    "            path = self.dirname if path is None else path\n",
    "            examples = []\n",
    "            for i,line in enumerate(open(path,'r',encoding='utf-8')):\n",
    "                if i==0:\n",
    "                    continue\n",
    "                line = line.strip().split('\\t')\n",
    "                txt = line[1].split(' ')               \n",
    "                                  \n",
    "                examples += [ data.Example.fromlist( [ txt, line[2]],fields ) ]\n",
    "        super(mydataset, self).__init__(examples, fields, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1664096644660,
     "user": {
      "displayName": "김나리",
      "userId": "01119342099285995005"
     },
     "user_tz": -540
    },
    "id": "kWexP0_1dmZ8",
    "outputId": "dac7e9a2-2ba7-46ea-d085-0ec68a2905ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21893"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_field, label_field : 전처리 관련된 field 객체를 각각 생성 \n",
    "# batch_first : 미니배치 차원을 맨 앞으로 하여 데이터를 불러올 것인지 여부\n",
    "# fix_length : 하나의 문장 내 max 토큰수 \n",
    "# sequential : 시퀀스데이터 여부\n",
    "text_field = data.Field(batch_first = True, fix_length = 20 )\n",
    "label_field = data.Field(sequential= False, batch_first = True, unk_token = None )\n",
    "\n",
    "train_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_train_tok.txt')\n",
    "\n",
    "test_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_test_tok.txt')\n",
    "#print(test_data.fields.items())\n",
    "\n",
    "# vocab 생성\n",
    "text_field.build_vocab(train_data)\n",
    "label_field.build_vocab(train_data)\n",
    "\n",
    "# Defines an iterator that loads batches of data from a Dataset\n",
    "train_iter, test_iter = data.Iterator.splits(\n",
    "                            (train_data, test_data), \n",
    "                            batch_sizes=(100, 1))#, device= 'cuda')\n",
    "len(text_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664096647792,
     "user": {
      "displayName": "김나리",
      "userId": "01119342099285995005"
     },
     "user_tz": -540
    },
    "id": "0lf4fXqhdmZ_",
    "outputId": "e1e2a7da-9f91-4ee5-f58d-ca1ce3f78674",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Text(\n",
       "  (embed): Embedding(21893, 100)\n",
       "  (convs1): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=300, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN모델 객체를 생성 (embed_num, class_num)\n",
    "cnn = CNN_Text(len(text_field.vocab), 2)\n",
    "\n",
    "# torch.optim : 신경망 학습을 위한 다양한 파라미터 최적화 알고리즘이 구현되어 있는 팩키지\n",
    "# Optimizer를 설정\n",
    "optimizer = torch.optim.Adam(cnn.parameters())\n",
    "cnn.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159795,
     "status": "ok",
     "timestamp": 1664096815244,
     "user": {
      "displayName": "김나리",
      "userId": "01119342099285995005"
     },
     "user_tz": -540
    },
    "id": "lCPi9H_MdmaC",
    "outputId": "5100317f-a253-4eb5-c73c-0930037fe9b7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch\n",
      "loss : 66.115\n",
      "1 epoch\n",
      "loss : 48.978\n",
      "2 epoch\n",
      "loss : 35.182\n",
      "3 epoch\n",
      "loss : 23.822\n",
      "4 epoch\n",
      "loss : 15.326\n",
      "5 epoch\n",
      "loss : 10.197\n",
      "6 epoch\n",
      "loss : 7.642\n",
      "7 epoch\n",
      "loss : 5.491\n",
      "8 epoch\n",
      "loss : 4.464\n",
      "9 epoch\n",
      "loss : 3.311\n",
      "10 epoch\n",
      "loss : 3.003\n",
      "11 epoch\n",
      "loss : 2.460\n",
      "12 epoch\n",
      "loss : 2.233\n",
      "13 epoch\n",
      "loss : 2.145\n",
      "14 epoch\n",
      "loss : 1.845\n",
      "15 epoch\n",
      "loss : 1.716\n",
      "16 epoch\n",
      "loss : 1.508\n",
      "17 epoch\n",
      "loss : 1.462\n",
      "18 epoch\n",
      "loss : 1.619\n",
      "19 epoch\n",
      "loss : 1.341\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    \n",
    "    totalloss = 0\n",
    "    for batch in train_iter:\n",
    "        optimizer.zero_grad() # resets the gradient to 0\n",
    "        \n",
    "        txt = batch.text\n",
    "        label = batch.label\n",
    "                \n",
    "        #print(txt.size()) -> torch.Size([100, 20])\n",
    "        pred = cnn(txt)\n",
    "                \n",
    "        #print(pred.size(), label.size()) -> torch.Size([100, 2]) torch.Size([100])\n",
    "        #print(label)\n",
    "        loss = F.cross_entropy(pred, label)\n",
    "        totalloss += loss.data\n",
    "        \n",
    "        loss.backward() # backward 연산\n",
    "\n",
    "        #--- (연습3) 파라미터를 업데이트 하는 함수를 호출하세요 ---\n",
    "        # write code here\n",
    "        optimizer.step() # optimizer.step()을 호출하여 파라미터를 업데이트한다\n",
    "        \n",
    "        \n",
    "    print(epoch,'epoch')    \n",
    "    print('loss : {:.3f}'.format(totalloss.numpy()))\n",
    "\n",
    "torch.save(cnn,'/content/gdrive/My Drive/Colab Notebooks/aivle/model/cnn_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXYHemZy3m0n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1664096823995,
     "user": {
      "displayName": "김나리",
      "userId": "01119342099285995005"
     },
     "user_tz": -540
    },
    "id": "lUApbakVdmaF",
    "outputId": "66ac2925-a5fb-4df8-b791-01fc52a5e295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct :  82\n",
      "incorrect :  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7963    0.8600    0.8269        50\n",
      "    positive     0.8478    0.7800    0.8125        50\n",
      "\n",
      "    accuracy                         0.8200       100\n",
      "   macro avg     0.8221    0.8200    0.8197       100\n",
      "weighted avg     0.8221    0.8200    0.8197       100\n",
      "\n",
      "CPU times: user 96.2 ms, sys: 0 ns, total: 96.2 ms\n",
      "Wall time: 95.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "cnn.eval()\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "y_test = []\n",
    "prediction = []\n",
    "\n",
    "for batch in test_iter:\n",
    "    txt = batch.text\n",
    "    label = batch.label\n",
    "    y_test.append(label.data[0])\n",
    "\n",
    "    pred = cnn(txt)\n",
    "    _,ans = torch.max(pred,dim=1)\n",
    "    prediction.append(ans.data[0])\n",
    "    \n",
    "    if ans.data[0] == label.data[0]:        \n",
    "        correct += 1    \n",
    "    else:\n",
    "        incorrect += 1\n",
    "    \n",
    "print ('correct : ', correct)\n",
    "print ('incorrect : ', incorrect)\n",
    "print(classification_report(torch.tensor(y_test), \n",
    "                            torch.tensor(prediction), \n",
    "                            digits=4, \n",
    "                            target_names=['negative', 'positive']))\n",
    "\n",
    "# Weighted Avg는 클래스의 수치간의 평균 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i045lkYUdmaH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1mvcMZjzmoye8_J2LND6mpdAib1aJTh_V",
     "timestamp": 1579181395154
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
