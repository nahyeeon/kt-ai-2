{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec11f1-d725-4f69-9547-6169fc46267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현장에서 많이씀(성능이 좋기때문) => RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6586a9b-b735-473d-b739-6811b33bedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params \n",
    "KNN { 'n_neighbors' : range(3,51,2), 'metric' : ['euclidean', 'manhattan']  }\n",
    "DecisionTree { 'max_depth':range(2,11), 'min_samples_leaf':range(10,101,10) }\n",
    "RandomForest { 'n_estimators':[20,50,100], 'max_features':range(1,21) }\n",
    "XGBoost {'learning_rate' : np.linspace(0.01,0.2, 20), 'n_estimators':range(60,200,20), 'max_depth':[3,4,5,6]}\n",
    "SVM { 'C' : np.linspace(0.01, 100, 50), 'gamma':[0.001,0.01,.1,1] }\n",
    "\n",
    "GridSearchCV(m, params, cv=5, scoring = 'neg_mean_absolute_error')\n",
    "XGBRegressor(objective = 'reg:squarederror')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21635a-7ffc-458a-8c3f-1153adb17a03",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b2fbff-8574-435a-8be6-f587fc7a189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리들을 불러오자.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 전처리\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 모델링\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import * \n",
    "\n",
    "# 비지도 학습\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c3a6c-841d-4042-bb6e-c7c3520e15f7",
   "metadata": {},
   "source": [
    "## target 변수 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31aedfe-394b-4ab8-8096-622dad5d30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Creditability'].value_counts())\n",
    "print(data['Creditability'].value_counts()/ data.shape[0])\n",
    "\n",
    "data['Creditability'].value_counts().plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d154d6a-7f80-40dc-aa6e-c437c8391566",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cdeb5-e440-42eb-9823-186597581100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터분할1\n",
    "target = 'Sales'\n",
    "x = data.drop(target, axis=1)\n",
    "y = data.loc[:, target]\n",
    "\n",
    "# 가변수화\n",
    "dumm_cols = ['ShelveLoc','Education','Urban', 'US']\n",
    "x = pd.get_dummies(x, columns = dumm_cols, drop_first = True)\n",
    "\n",
    "# 데이터 분할2\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.2\n",
    "                                                  , random_state = 2022)\n",
    "\n",
    "# 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "x_train_s = scaler.fit_transform(x_train)\n",
    "x_val_s = scaler.transform(x_val)\n",
    "\n",
    "x_train_s = pd.DataFrame(x_train_s, columns=list(x))\n",
    "x_val_s = pd.DataFrame(x_val_s, columns=list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64255320-fd98-4f20-b828-d87efa0f4db4",
   "metadata": {},
   "source": [
    "## Fitting Graph ->Elbow Method [모델과적합]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ec031-30e5-4a94-8c13-8a7602d610b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "* 가장 단순한 모델(평균모델)\n",
    "** knn : k를 최대로 크게하면 평균 모델이 됨.\n",
    "** k의 최대값은 학습 데이터의 행 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe7a64-aa84-4141-8d05-a60747447be9",
   "metadata": {},
   "source": [
    "* Decision Tree\n",
    "** Decision Tree는 나무의 크기가 클 수록 복잡한 모델\n",
    "** 크기를 결정하는 파라미터는 max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff7702-02a6-428e-aca3-0b02b207cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "n = x_train_s.shape[0]\n",
    "model = KNeighborsRegressor(n_neighbors = n) # train set의 행 수\n",
    "model.fit(x_train_s, y_train)\n",
    "pred_train = model.predict(x_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc2d5d-ca76-4a77-aaf1-45bf0b8c5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = [] # train set을 가지고 예측한 결과\n",
    "result_val = [] # val set을 가지고 예측한 결과\n",
    "k_values = list(range(1,101))\n",
    "\n",
    "# KNN\n",
    "for d in k_values :\n",
    "    model = KNeighborsClassifier(n_neighbors= d)\n",
    "    model.fit(x_train_s, y_train)\n",
    "    pred_tr, pred_val = model.predict(x_train_s), model.predict(x_val_s)\n",
    "    result_train.append(accuracy_score(y_train, pred_tr))\n",
    "    result_val.append(accuracy_score(y_val, pred_val))\n",
    "    \n",
    "result_train = [] # train set을 가지고 예측한 결과\n",
    "result_val = [] # val set을 가지고 예측한 결과\n",
    "depth = list(range(1,21))\n",
    "\n",
    "# Decision Tree\n",
    "for d in depth :\n",
    "    model = DecisionTreeClassifier(max_depth = d)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred_tr, pred_val = model.predict(x_train), model.predict(x_val)\n",
    "    result_train.append(accuracy_score(y_train, pred_tr))\n",
    "    result_val.append(accuracy_score(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b42a9-2736-410b-9789-40287fd91b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(k_values, result_train, label = 'train_acc', marker = 'o')\n",
    "plt.plot(k_values, result_val, label = 'val_acc', marker = 'o')\n",
    "\n",
    "plt.xlabel('Complexity')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beeb07e-8f9e-450f-a0c8-592fffca7cff",
   "metadata": {},
   "source": [
    "## Decision Tree[ 변수중요도 그래프 ] 실전에서 많이 씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979c9b5-e881-45d8-91b7-1159b6e0615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 이름을 이용하여 시각화\n",
    "plt.figure(figsize = (20,8)) # 그림 사이즈 조절\n",
    "plot_tree(m3.best_estimator_, feature_names = x_train.columns, \n",
    "               class_names= ['Bad', 'Good'], filled = True, fontsize = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484790ba-8b17-43e3-bd6a-852f81a151fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names):\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    fi_df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x='feature_importance', y='feature_names', data = fi_df)\n",
    "\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    plt.grid()\n",
    "\n",
    "    return fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59b9a5-05b1-4e0a-9404-6a1de506990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(model.feature_importances_, list(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19d05d-637d-4055-8820-180621d28edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(m3.best_estimator_.feature_importances_, list(x_train)) # 튜닝했기 때문에"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26fdad3-eb3d-4e64-bca5-4d3429b744a8",
   "metadata": {},
   "source": [
    "## Regessor 차트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672f86a-faa5-4385-85d5-70ad9462e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝 과정 로그를 df로 저장 합시다.\n",
    "result = pd.DataFrame(m1_gs.cv_results_)\n",
    "\n",
    "# 튜닝 결과를 그래프로 그려봅시다.\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.lineplot(x='param_max_depth', y='mean_test_score', data = result)  # plt.plot\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620285a-44ce-4fcc-8f12-eec866a79908",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR(Regressor)\n",
    "# 이를 차트로 그려봅시다.\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.lineplot(x = 'param_C', y = 'mean_test_score', data = result, hue = 'param_gamma')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4d163-b6ec-4ec9-b50e-b91a5054114b",
   "metadata": {},
   "source": [
    "## XGB 변수중요도 / 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79b9a7-8b55-47a7-86c0-ad406137af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위에꺼 plot_feature_importance 함수 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cfedd-07e6-484e-b631-9e5fc4a9fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb의 변수 중요도\n",
    "weight : 모델 전체에서 해당 feature가 split될 때 사용된 횟수의 합(plot_tree 에서의 기본값)\n",
    "gain : feature별 평균 imformation gain.(model.feature_importances_ 의 기본값)\n",
    "cover : feature가 split 할때의 샘플 수의 평균."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf69414-2d92-4b9e-b32d-1d520116b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, plot_tree, plot_importance\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c8e9e-0bb5-4b42-a041-af290eb0af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(model.feature_importances_, list(x),6) #x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f47772-a1b8-44b5-b798-32b0f78cb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화(Tree하나씩 열어볼 수 있음)\n",
    "plt.rcParams['figure.figsize'] = 20,20  # 파일전체에 영향을 미침 !!!!\n",
    "plot_tree(model, num_trees = 0) \n",
    "plt.show()\n",
    "\n",
    "# xgboost 자체 plot_tree 함수를 제공합니다.\n",
    "# plot_tree(model, num_trees = 0)\n",
    "# num_trees : 전체 트리 5개짜리 모델이므로 각각 0~4까지 인덱스로 조회해 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f2c63-94d3-4652-982d-d4bbf308f063",
   "metadata": {},
   "source": [
    "## 성능비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7fa2d-6358-4b95-b3d1-d030c05b573e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE, MAE, MAPE = [],[],[]\n",
    "model_desc = ['lr_selected', 'lr_all','knn','dt','rf','xgb','svm']\n",
    "pred = [p1, p2, p3, p4, p5, p6,p7]\n",
    "\n",
    "for i, p in enumerate(pred) :\n",
    "    RMSE.append(mean_squared_error(y_val, p, squared=False))\n",
    "    MAE.append(mean_absolute_error(y_val, p))\n",
    "    MAPE.append(mean_absolute_percentage_error(y_val, p))\n",
    "\n",
    "result = pd.DataFrame({'model_desc':model_desc,'RMSE':RMSE,'MAE':MAE,'MAPE':MAPE})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543c4d3-d6f5-415f-abb8-251ab9fec147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_val, pred1))\n",
    "print(classification_report(y_val, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921def8-9b58-4f63-94d5-5fd1579763dd",
   "metadata": {},
   "source": [
    "## Decision Tree 시각화 및 변수중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74512328-ac56-4f62-8165-a1b739bd2c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10)) # 그림 사이즈 조절\n",
    "plot_tree(m1, feature_names = list(x_train), \n",
    "               class_names= ['Stay', 'Leave'], filled = True, fontsize = 10);  # class_names = [target의 내용]\n",
    "plt.show()\n",
    "print('-'*88)\n",
    "# 변수 중요도\n",
    "print(list(x_train))\n",
    "print(m1.feature_importances_)\n",
    "print('-'*88)\n",
    "print(classification_report(y_val, p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eaf2ba-8169-49c1-ab4e-c2503d7049fe",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀를 위한 전진선택법 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f321f-66db-420b-80f0-047e9d7bad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "\n",
    "def forward_stepwise_linear(x_train, y_train):\n",
    "\n",
    "    # 변수목록, 선택된 변수 목록, 단계별 모델과 AIC 저장소 정의\n",
    "    features = list(x_train)\n",
    "    selected = []\n",
    "    step_df = pd.DataFrame({ 'step':[], 'feature':[],'aic':[]})\n",
    "\n",
    "    # \n",
    "    for s in range(0, len(features)) :\n",
    "        result =  { 'step':[], 'feature':[],'aic':[]}\n",
    "\n",
    "        # 변수 목록에서 변수 한개씩 뽑아서 모델에 추가\n",
    "        for f in features :\n",
    "            vars = selected + [f]\n",
    "            x_tr = x_train[vars]\n",
    "            model = OLS(y_train, add_constant(x_tr)).fit(disp=False)\n",
    "            result['step'].append(s+1)\n",
    "            result['feature'].append(vars)\n",
    "            result['aic'].append(model.aic)\n",
    "        \n",
    "        # 모델별 aic 집계\n",
    "        temp = pd.DataFrame(result).sort_values('aic').reset_index(drop = True)\n",
    "\n",
    "        # 만약 이전 aic보다 새로운 aic 가 크다면 멈추기\n",
    "        if step_df['aic'].min() < temp['aic'].min() :\n",
    "            break\n",
    "        step_df = pd.concat([step_df, temp], axis = 0).reset_index(drop = True)\n",
    "\n",
    "        # 선택된 변수 제거\n",
    "        v = temp.loc[0,'feature'][s]\n",
    "        features.remove(v)\n",
    "\n",
    "        selected.append(v)\n",
    "    \n",
    "    # 선택된 변수와 step_df 결과 반환\n",
    "    return selected, step_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64df06-f8e2-4d8a-b2ef-97d362534801",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars, result = forward_stepwise_logistic(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0df5b-343a-4271-9877-0ac0cef5ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 변수\n",
    "lr_m1 = LinearRegression()\n",
    "lr_m1.fit(x_train[vars], y_train)\n",
    "p1 = lr_m1.predict(x_val[vars])\n",
    "\n",
    "print('RMSE : ', mean_squared_error(y_val, p1, squared=False))\n",
    "print('MAE  : ', mean_absolute_error(y_val, p1))\n",
    "print('MAPE : ', mean_absolute_percentage_error(y_val, p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf20d7b-664d-4370-8e00-55b8e409fb21",
   "metadata": {},
   "source": [
    "## cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c24999-fa58-4b07-b323-450de6a1323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# train + validation set을 이용하여 학습, 예측, 평가를 한번에. (여기서는 .fit 이 아님!)\n",
    "dt_result = cross_val_score(model, x, y, cv=10)\n",
    "print(dt_result)\n",
    "print(dt_result.mean(), dt_result.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0876d-960f-44ea-b0a5-8a2acb251549",
   "metadata": {},
   "source": [
    "## Permutation Feature Importance(그 외 변수중요도 그래프)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd55a3-cfe5-4fcb-ace0-1b399f315a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d30d2c-6d7c-4780-9492-1a021fc4c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfi1 = permutation_importance(model4, x_val_s, y_val, n_repeats=10, scoring = 'r2', random_state=2022)\n",
    "# scoring = 'accuracy' default[분류 모델]\n",
    "# deep learning 모델에 대해서는 명시적으로 scoring = 'r2'을 지정해 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58147e8f-a372-4b2c-a951-7df3e66ce309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature별 Score 분포\n",
    "plt.figure(figsize = (10,8))\n",
    "for i,vars in enumerate(list(x)) :\n",
    "    sns.kdeplot(pfi1.importances[i], label = vars)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820c5a2-0ff6-4c62-b698-2feac8aa0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = pfi1.importances_mean.argsort()\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.boxplot(pfi1.importances[sorted_idx].T, vert=False, labels=x.columns[sorted_idx])\n",
    "plt.axvline(0, color = 'r')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d3e93-fd33-4813-b864-ad186951fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균값으로 변수중요도 그래프 그리기\n",
    "pfi1 = permutation_importance(model1, x_val_s, y_val, n_repeats=10, scoring = 'r2', random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc70a2-80be-4adf-a371-f3b0cd35c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 중요도 plot(가져오기)\n",
    "result = plot_feature_importance(pfi1.importances_mean, list(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa99e68-a6f0-4011-b165-60185b89f33d",
   "metadata": {},
   "source": [
    "## Partial Dependence Plot(개별 변수별 관계)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25612daa-29b7-4292-a14c-4f611064b304",
   "metadata": {},
   "source": [
    "* 변수 중요도,PDP : train 데이터로 살펴보는 것이 기본이다. 그리고 결과가 유사해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524504e-98c0-4b99-85f4-ddc30f355d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence, partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b994514-5ba4-44e8-8c6f-d3514006025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 변수 분석\n",
    "var = 'MonthlyIncome'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "plot_partial_dependence(model, features = [var], X = x_val)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac85a3e-a9a0-407d-9b5a-5b6c28609b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터로 확인\n",
    "var = 'MonthlyIncome'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12, 8\n",
    "plot_partial_dependence(model, features = [var], X = x_val, kind = 'both') #kind = 'average'\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35f900-19bf-48d5-b435-3be786601d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개 변수 비교\n",
    "plot_partial_dependence(model, features = ['rm','lstat'], X = x_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9cea2-ca6a-4260-8783-c65510ac347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개 변수 비교\n",
    "plot_partial_dependence(model2, features = [('CreditAmount','Age')], X = x_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13acb0-6d39-4e2f-a7ad-b98442f5d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링한거 데이터 프레임에 넣어서 뽑아야함\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = list(x))  # 칼럼이름 지정 필요!!\n",
    "x_val_s = pd.DataFrame(x_val_s, columns = list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd92fd6-e143-48c7-839e-96ab575b40ff",
   "metadata": {},
   "source": [
    "## SHAP 값으로 모델의 예측 설명하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bd8b4-529c-4568-a7e7-b8167cbef6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀는 회귀계수로 변수 기여도 해석해도 무방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd050132-df09-4291-bc29-658ad30df832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (회귀모델)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer1.shap_values(x_train)\n",
    "\n",
    "# (분류모델)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777c0f6-5481-49e9-a1d9-5dcce0d4076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측하기 위해서는 입력데이터(x)가 2차원이어야 합니다.\n",
    "pred = model1.predict(x_train.iloc[0:1,:])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361de6de-deb7-4cf6-8ce8-6f1a3a522cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train의 평균(회귀)\n",
    "explainer1.expected_value\n",
    "\n",
    "# train의 평균(분류)\n",
    "explainer1.expected_value[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9a1ae-2275-452e-b6c6-567d2b419c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스별 데이터\n",
    "shap.initjs() # javascript 시각화 라이브러리 --> colab에서는 모든 셀에 포함시켜야 함.-> 아나콘다에서는 한번만 !\n",
    "index=371\n",
    "# force_plot(전체평균, shapley_values, input)\n",
    "shap.force_plot(explainer1.expected_value, shap_values1[index,:], x.iloc[index,:])\n",
    "\n",
    "# 분류모델\n",
    "shap.initjs() # javascript 시각화 라이브러리 --> colab에서는 모든 셀에 포함시켜야 함.-> 아나콘다에서는 한번만 !\n",
    "index=932\n",
    "# force_plot(전체평균, shapley_values, input)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][index,:], x.iloc[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a1d2a-6bf7-46e5-86da-61fda96261e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터\n",
    "shap.initjs() # javascript 시각화 라이브러리 --> colab에서는 모든 셀에 포함시켜야 함.-> 아나콘다에서는 한번만 !\n",
    "\n",
    "# force_plot(전체평균, shapley_values, input)\n",
    "shap.force_plot(explainer1.expected_value, shap_values1[0, :], x_train.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf225d-cdd8-4e25-a11e-d96ef4fadca5",
   "metadata": {},
   "source": [
    "## class balance를 맞추기 위한 resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f098a68-04d1-45a1-9473-e893b5fca852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3a8f7-42da-4cb1-a3b2-a0d0644bf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a0459-dca1-4b10-9c53-79827e1a9fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 비지도 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b59d6-b431-4063-9d80-7500cf3a167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1,50)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(mobile_x)\n",
    "    inertias.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bcac3-b88c-456d-b8d6-846b97a4e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34af48-e397-48a1-aaa7-c27279a6a29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델링[KNN]\n",
    "model = KMeans(n_clusters=5)\n",
    "model.fit(mobile_x)\n",
    "pred = model.predict(mobile_x)\n",
    "pred = pd.DataFrame(pred, columns = ['predict'])\n",
    "# 결과 보기\n",
    "mobile_y.reset_index(inplace=True, drop=True)\n",
    "result = pd.concat([mobile_x, mobile_y, pred], axis =1)\n",
    "result.CHURN = result.CHURN.astype('int')\n",
    "# 클러스터 별 고객이탈율\n",
    "result.groupby('predict')['CHURN'].mean()\n",
    "# 전체 평균\n",
    "result['CHURN'].value_counts() / result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e88bc6-48aa-43a0-bf61-6195f7628f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN 모델을 만들어 봅시다.\n",
    "model = DBSCAN(eps=0.1, min_samples=3)\n",
    "model.fit(x)\n",
    "# fitting한 후에 모델의 labels_ 값이 찾아낸 군집 종류입니다.\n",
    "clusters = model.labels_\n",
    "# 군집 번호 중 -1은 이상치를 의미합니다.(어느 군집에도 포함 안되는 값들!)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126cc2cd-68ba-4e0c-b45f-2cf050a208b6",
   "metadata": {},
   "source": [
    "## 시계열 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359fee4-1fa7-45ce-94c0-0b540f19c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1b49b-b28b-4008-b77d-f1ef70702d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 시계열로 확인 \n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(data['sales'])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "temp = data[-100:]\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(temp['sales'], marker ='o')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa23b2-c179-4c13-a838-d655a9e750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잔차 분석\n",
    "def residual_diag(residuals, lags = 20) :\n",
    "\n",
    "    print('* 정규성 검정(> 0.05) : ', round(spst.shapiro(residuals)[1],5))\n",
    "    print('* 정상성 검정(< 0.05) : ', round(sm.tsa.stattools.adfuller(residuals)[1],5))\n",
    "    print('* 자기상관성 확인(ACF, PACF)')\n",
    "    fig,ax = plt.subplots(1,2, figsize = (15,5))\n",
    "    plot_acf(residuals, lags = lags, ax = ax[0])\n",
    "    plot_pacf(residuals, lags = lags, ax = ax[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733fa1d-5bec-493d-98c1-78d906b7dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 타입으로 변경\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "# 날짜를 인덱스로 변환\n",
    "data['DT'] = data['date']\n",
    "data.set_index('DT', inplace=True)\n",
    "data.head()\n",
    "## 날짜단위 지정하기 : freq / 인덱스 조회시, 마지막에 있는 freq 옵션\n",
    "# 일단위\n",
    "data.asfreq('D').head()\n",
    "# 월(말)단위\n",
    "data.asfreq('M').head()\n",
    "# 월초 단위\n",
    "data.asfreq('MS').head()\n",
    "#(추가) 빠진값 찾기\n",
    "temp = data.asfreq('D')\n",
    "temp.isna().sum()\n",
    "# 채우기\n",
    "data.asfreq('D', method = 'ffill')\n",
    "df = data.asfreq('D') # 일단위 데이터이므로 이걸로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c782bfe-33b8-4ed8-ba1e-14cd98bc0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 만들기\n",
    "df['y'] = df['sales'].shift(-1)\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "# 제일 마지막 행은 삭제\n",
    "df.dropna(axis = 0, inplace = True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077b5ee-bae1-4267-9902-c3c237830513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "# 1) x, y 나누기\n",
    "# .values(넘파이 어레이)로 변환해서 저장하는 이유 ➡ 데이터 스플릿 index를 적용해서 데이터를 가져오기 위해서\n",
    "target = 'y'\n",
    "\n",
    "x = df.drop([target, 'date'], axis = 1)\n",
    "y = df.loc[:, target]\n",
    "\n",
    "# 시계열 데이터 분할\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "x.shape\n",
    "# validation set size\n",
    "val_size = 30\n",
    "nfold = 3\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = nfold, test_size = val_size)\n",
    "tscv\n",
    "\n",
    "#참조\n",
    "# .split을 이용하여 fold 하나씩 인덱스들을 뽑아 낼 수 있음.\n",
    "for train_index, val_index in tscv.split(x):\n",
    "    print(\"Train:\", train_index, \"Val:\", val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7509d9-02fa-4c4d-9963-d83d88be275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "# loop 돌며 모델링(cross-validation) 수행\n",
    "rmse, mae, mape = [],[],[]\n",
    "residuals = []\n",
    "pred = []\n",
    "model = LinearRegression()\n",
    "\n",
    "for train_index, val_index in tscv.split(x):\n",
    "\n",
    "    # 인덱스로 데이터 분할\n",
    "    x_train, y_train = x.iloc[train_index], y.iloc[train_index]\n",
    "    x_val, y_val = x.iloc[val_index], y.iloc[val_index]\n",
    "\n",
    "    # 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 예측\n",
    "    pr = model.predict(x_val)\n",
    "    pred += list(pr)\n",
    "\n",
    "    # 평가\n",
    "    rmse.append(mean_squared_error(y_val, pr, squared = False))\n",
    "    mae.append(mean_absolute_error(y_val, pr))\n",
    "    mape.append(mean_absolute_percentage_error(y_val, pr))\n",
    "\n",
    "    # 잔차 : 각 fold의 결과를 리스트로 변환하여 추가\n",
    "    residuals += list(y_val - pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969db4bd-ac0c-4fbb-adb9-1e023faaf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 평가\n",
    "print('RMSE : ',round(np.mean(rmse),4))\n",
    "print('MAE  : ',round(np.mean(mae),4))\n",
    "print('MAPE : ',round(np.mean(mape),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ccda9-2ee3-442d-aa60-215ffc227846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 비교\n",
    "n = val_size * nfold\n",
    "pred = pd.Series(pred, index = y[-n:].index)\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(y[:-n], label = 'train')\n",
    "plt.plot(y[-n:], label = 'val')\n",
    "plt.plot(pred, label = 'predicted')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(y[-n:], label = 'val')\n",
    "plt.plot(pred, label = 'predicted')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6b063-297d-4b19-90ca-b535597d6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가: 잔차분석\n",
    "## 시각화\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, color = 'r', ls = '--')\n",
    "plt.axhline(np.mean(residuals), color = 'g', ls = '--')\n",
    "plt.show()\n",
    "\n",
    "## ACF, PACF(자기상관성 여부 확인)\n",
    "lags = 20\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize = (15,5))\n",
    "plot_acf(residuals, lags = lags, ax = ax[0])\n",
    "plot_pacf(residuals, lags = lags, ax = ax[1])\n",
    "plt.show()\n",
    "\n",
    "## 검정\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "stats.shapiro(residuals)[1]  # 정규성 검정 : Shapiro-Wilk 검정\n",
    "sm.tsa.stattools.adfuller(residuals)[1]  # 정상성 검정 : ADF 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21e45a-b164-4278-96bb-e2922bb8410f",
   "metadata": {},
   "source": [
    "## 시계열 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a079f9-4e0d-49d0-b774-c97f26ab228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "def plot_model_result(y_train, y_val, pred) :\n",
    "    pred = pd.Series(pred, index = y_val.index)\n",
    "\n",
    "    # 전체 시각화\n",
    "    plt.figure(figsize = (20,12))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(y_train, label = 'train')\n",
    "    plt.plot(y_val, label = 'val')\n",
    "    plt.plot(pred, label = 'pred')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(y_val, label = 'val')\n",
    "    plt.plot(pred, label = 'pred')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9739f4e-d804-4514-9beb-94847e7120d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y값 살펴보기\n",
    "residual_diag(y_train, lags = 30)\n",
    "\n",
    "# ARIMA 모델링\n",
    "m1_1 = sm.tsa.SARIMAX(y_train, order=(1,0,1)).fit() # ARMA\n",
    "m1_2 = sm.tsa.SARIMAX(y_train, order=(1,1,1)).fit() # ARIMA\n",
    "\n",
    "# SARIMA 모델링 : P, D, Q, m = 1,1,1,7 로 모델을 생성합시다.\n",
    "m2_1 = sm.tsa.SARIMAX(y_train, order=(5,1,4), seasonal_order=(1,1,1,7)).fit()\n",
    "\n",
    "m3_1 = sm.tsa.SARIMAX(y_train, order=(5,1,4), seasonal_order=(1,1,1,7), exog=x_train).fit()\n",
    "\n",
    "# 평가[잔차 진단]\n",
    "residuals = m1_1.resid  # y_train과 예측값 차이\n",
    "residual_diag(residuals)\n",
    "# 평가[AIC] ->선형 모델에서의 적합도와, feature가 과도하게 늘어나는 것을 방지하도록 설계된 통계량이 AIC 입니다.\n",
    "# 값이 작을 수록 좋은 모델\n",
    "# 공식 : 𝐴𝐼𝐶=−2 ln⁡(𝐿)+2𝑘 ➡ - 모델의 적합도 + 변수의 갯수\n",
    "print('model1 AIC :', m1_1.aic)\n",
    "# 평가[Validation]\n",
    "pred = m1_1.forecast(30)   # SARIMAX 모델을 생성하고, 예측할 때는 exog=x_val 옵션이 들어가야 함. \n",
    "print('MAE :', mean_absolute_error(y_val, pred))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_val, pred))\n",
    "# 평가[결과 시각화]\n",
    "plot_model_result(y_train, y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc011a5-ea27-4a08-bce6-dd151e82c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 튜닝\n",
    "\n",
    "# 학습\n",
    "from itertools import product\n",
    "# product 함수를 이용하여 값의 조합을 구성\n",
    "p = [1,2,3,4,5]\n",
    "q = [1,2,3,4,5]\n",
    "d = [1]\n",
    "iter = list(product(p,d,q))\n",
    "iter\n",
    "\n",
    "# 튜닝 \n",
    "mae, aic = [],[]\n",
    "for i in iter :\n",
    "    model_fit = sm.tsa.SARIMAX(y_train, order=(i[0],i[1],i[2])).fit()\n",
    "    pred = model_fit.forecast(30)\n",
    "    mae.append( mean_absolute_error(y_val, pred))\n",
    "    aic.append(model_fit.aic)\n",
    "    print(i)\n",
    "    \n",
    "result = pd.DataFrame({'params(p,d,q)' : iter, 'mae' : mae, 'aic':aic})\n",
    "\n",
    "display(result.loc[result['mae'] == result.mae.min()])\n",
    "display(result.loc[result['aic'] == result.aic.min()])\n",
    "\n",
    "# 가장 성능이 좋은 p, d, q 값으로 모델을 생성합니다.\n",
    "m1_3 = sm.tsa.SARIMAX(y_train, order=(5,1,4)).fit()\n",
    "\n",
    "# 평가[잔차진단]\n",
    "residuals = m1_3.resid\n",
    "residual_diag(residuals) # seasonallity \n",
    "# 평가[AIC]\n",
    "print('model2 AIC :', m1_3.aic)\n",
    "# 평가[validation]\n",
    "p1 = m1_3.forecast(30)\n",
    "print('MAE :', mean_absolute_error(y_val, p1))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_val, p1))\n",
    "# 결과 시각화\n",
    "plot_model_result(y_train, y_val, p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841415ba-a113-49b3-a213-0f2df244b0af",
   "metadata": {},
   "source": [
    "## 딥러닝[keras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63aa4c-1211-43fd-a84b-c6ffb57254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ad5b2-0eec-4277-8908-5af216a9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape , y.shape  # 확인해볼것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9d68f-a6f4-4763-8fef-6d406055849b",
   "metadata": {},
   "source": [
    "* Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56367fdb-b8cf-4b4b-b174-7834b14485f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Linear Regression]\n",
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "# 결과 출력\n",
    "print(model.predict(x).reshape(-1,) )\n",
    "\n",
    "@ [Logistic Regression]\n",
    "keras.backend.clear_session()\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(input_layer)\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb0919-cb10-4b52-b673-e043cccdd6c2",
   "metadata": {},
   "source": [
    "* Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67fd5e0-82fb-42c9-a314-9715ab7552b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Linear Regression]\n",
    "# 1번 청소 : 이미 만들어진 모델이 있다면 그 모델을 없애줘\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 2번 모델 선언\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# 3번 모델 블록 조립\n",
    "model.add( keras.layers.Input(shape=(1,)) )\n",
    "model.add( keras.layers.Dense(1) )\n",
    "\n",
    "## 오리지널 Sequential API\n",
    "# model.add( keras.layers.Dense(1, input_shape=(1,)) )\n",
    "\n",
    "# 4번 컴파일 \n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(x[:15], y[:15], epochs=10, verbose=1)\n",
    "print(y[15:])\n",
    "print(model.predict(x[15:]))\n",
    "\n",
    "@ [Logistic Regression]\n",
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# model에 순차적으로 레이어를 쌓아가겠다는 의도!\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# model에 인풋 값을 받는 레이어를 넣음\n",
    "model.add( keras.layers.Input(shape=(1,)) )\n",
    "# model에 Dense 레이어를 넣을거야 (최초의 레이어) : weight를 곱하고, bias를 더해주는 과정\n",
    "model.add( keras.layers.Dense(1, activation='sigmoid') )\n",
    "\n",
    "# 오리지널 Sequential API\n",
    "# model.add( keras.layers.Dense(1, input_shape=(1,), activation='sigmoid') )\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "# keras.losses.binary_crossentropy 이걸로도 가능\n",
    "\n",
    "model.fit(x[:15], y[:15], epochs=10, verbose=1)\n",
    "print(y[15:])\n",
    "print(model.predict(x[15:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91289ec3-9fbe-42a4-bb08-76d33084e753",
   "metadata": {},
   "source": [
    "* 멀티클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60420175-9abb-4a4d-aa65-a20f60569a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미래 데이터를 먼제 떼어내야하기 때문에 먼저 분리해준다.(미래데이터는 건드리지 않는다)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.2, random_state=2022)\n",
    "x_train.shape, y_train.shape\n",
    "# One-Hot Encoding  (get_dummies= x에만 적용)\n",
    "class_n = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, class_n)\n",
    "y_test = to_categorical(y_test, class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e62134-a6df-4a34-bd32-92d177f7835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ y 확인하기\n",
    "iris.target_names\n",
    "\n",
    "# One-Hot Encoding  (get_dummies= x에만 적용)\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "y = to_categorical(y, 3) # 반복 실행 주의!!(계속 생성됨)\n",
    "x.shape, y.shape\n",
    "\n",
    "@ [Sequential]\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(4,)))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,verbose=1)\n",
    "model.predict(x_test).reshape(-1)\n",
    "y.argmax(axis=1)\n",
    "\n",
    "@ [Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(4,))\n",
    "ol = keras.layers.Dense(3,activation='softmax')(il)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "model.fit(x_train,y_train,epochs=10, verbose=1)\n",
    "pred = model.predict(x_test)\n",
    "pred[:5] # 합치면 확률값 =1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b4936-56b0-4659-a35c-f24f016b555f",
   "metadata": {},
   "source": [
    "* Hidden layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab5d1f-3c3d-4be5-80ae-f6c1a261c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Sequential API]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(13,)))\n",
    "model.add(keras.layers.Dense(32,activation='relu'))\n",
    "model.add(keras.layers.Dense(32,activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "@ [Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(30,))\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden1')(il)\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden2')(hl)\n",
    "ol = keras.layers.Dense(1,activation='sigmoid')(hl)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "@ [multi-Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(4,))\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden1')(il)\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden2')(hl)  # 변수명 같아도 상관없음\n",
    "ol = keras.layers.Dense(3,activation='softmax')(hl)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " # optimizer=keras.optimizers.Adam(0.01)-> eta\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066a064-fb8b-457c-93af-792304ffbdb9",
   "metadata": {},
   "source": [
    "## 딥러닝[ANN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6361238-7234-4dd4-937c-62c28c1ad4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참조코드\n",
    "'''\n",
    "matplolib inline 명령어를 통해서\n",
    "matplot으로 그리는 플롯들을 주피터 노트북 내에서 볼 수 있게 해준다.\n",
    "포맷을 retina로 바꾸면 그래프의 화질이 훨씬 좋아진다.\n",
    "'''\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20445e-b94f-47b6-b20a-c81a42dedc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) 전처리\n",
    "x = wine.data\n",
    "y = wine.target\n",
    "x.shape, y.shape\n",
    "data.target_names\n",
    "\n",
    "## reshape -> flatten하면 필요없음\n",
    "train_x.shape\n",
    "train_x = train_x.reshape([train_x.shape[0],-1])\n",
    "test_x = test_x.reshape([test_x.shape[0],-1])\n",
    "train_x.shape # 28*28\n",
    "## min-max scaling\n",
    "max_n, min_n = train_x.max(), train_x.min()\n",
    "max_n, min_n\n",
    "train_x = (train_x - min_n) / (max_n - min_n)\n",
    "test_x = (test_x - min_n) / (max_n - min_n)\n",
    "print(f'max : {train_x.max()} / min : {train_x.min()}')\n",
    "## target feature : One-hot Encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "len_y = len(set(train_y))\n",
    "train_y = to_categorical(train_y, len_y)\n",
    "test_y = to_categorical(test_y, len_y)\n",
    "\n",
    "2) 모델링\n",
    "train_x.shape, train_y.shape\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(train_x.shape[1]))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.01),metrics='accuracy')\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss',  # 무얼 관찰할지(관측대상)\n",
    "                   min_delta=0,         # 최소한 나빠지지 않으면 괜찮아\n",
    "                   patience=5,          # 중요! 몇번이나 참을지(거기까지 개선 안되면 멈출거야)\n",
    "                   verbose=1,            \n",
    "                   restore_best_weights=True)  # (반드시 사용)학습이 멈췄을 때, 최적의 가중치로 전환해줌\n",
    "model.fit(train_x, train_y, \n",
    "          validation_split=0.2,  # Train data의 20%를 Validation data로!\n",
    "          callbacks=[es],        # Early Stopping 적용\n",
    "          verbose=1, epochs=50)\n",
    "\n",
    "3) 예측\n",
    "pred_train = model.predict(train_x)\n",
    "pred_test = model.predict(test_x)\n",
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_test = pred_test.argmax(axis=1)\n",
    "logi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\n",
    "logi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n",
    "print('트레이닝 정확도 : {:.2f}%'.format(logi_train_accuracy*100))\n",
    "print('테스트 정확도 : {:.2f}%'.format(logi_test_accuracy*100))\n",
    "\n",
    "4) 확인\n",
    "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "for i, index in enumerate(np.random.choice(test_x.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(test_x[index].reshape([28,-1])), cmap='gray' )\n",
    "    \n",
    "    predict_index = pred_test[index].argmax(axis=0)\n",
    "    true_index = test_y[index].argmax(axis=0)\n",
    "    # Set the title for each image\n",
    "    ax.set_title(f\"{mnist_labels[predict_index]} ({mnist_labels[true_index]})\",\n",
    "                 color=(\"green\" if predict_index == true_index else \"red\"))\n",
    "    \n",
    "5) 오답확인\n",
    "true_false = (test_y.argmax(axis=1) == single_pred_test)\n",
    "f_id = np.where(true_false == False)[0]\n",
    "f_n = len(f_id)\n",
    "id = f_id[rd.randrange(0,f_n)]\n",
    "print(f'id = {id}' )\n",
    "print(f'다음 그림은 숫자 {test_y.argmax(axis=1)[id]} 입니다.')\n",
    "print(f'모델의 예측 : {single_pred_test[id]}')\n",
    "print(f'모델의 카테고리별 확률 : {np.floor(pred_test[id]*100)}')\n",
    "if test_y.argmax(axis=1)[id] == single_pred_test[id] :\n",
    "    print('===============')\n",
    "    print('정답입니다')\n",
    "    print('===============')\n",
    "else : \n",
    "    print('===============')\n",
    "    print('틀렸어요')\n",
    "    print('===============')\n",
    "plt.imshow(test_x[id].reshape([28,-1]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "6) 평가\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe819b5d-4d0f-4b45-af16-e768a4fb3bff",
   "metadata": {},
   "source": [
    "## Modeling : multi-input & Concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7af6d6-ab4f-49b4-b2fa-3bf9e6b15d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) 데이터 불러오기\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "print(data.DESCR) \n",
    "df_x = pd.DataFrame(x, columns=iris.feature_names)\n",
    "# null값 확인 필요\n",
    "iris.target_names\n",
    "\n",
    "2) train set, test set 구분하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_x, y, test_size=0.1, random_state=2022)\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape\n",
    "\n",
    "추가) Scaling (데이터 수치->너무 편차가 커서(min_max 필요))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "train_x = mm_scaler.fit_transform(train_x)\n",
    "test_x = mm_scaler.transform(test_x)\n",
    "pd.DataFrame(train_x, columns=iris.feature_names).describe()\n",
    "train_x = pd.DataFrame(train_x, columns=iris.feature_names)\n",
    "test_x = pd.DataFrame(test_x, columns=iris.feature_names)\n",
    "\n",
    "3) length끼리, width끼리\n",
    "print(df_x.columns)\n",
    "tr_x_l = train_x.loc[:, ['sepal length (cm)', 'petal length (cm)'] ]\n",
    "tr_x_w = train_x.loc[:, ['sepal width (cm)', 'petal width (cm)'] ]\n",
    "tr_x_l.shape, tr_x_w.shape\n",
    "te_x_l = test_x.loc[:, ['sepal length (cm)', 'petal length (cm)'] ]\n",
    "te_x_w = test_x.loc[:, ['sepal width (cm)', 'petal width (cm)'] ]\n",
    "\n",
    "4) One-hot Encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_y = to_categorical(train_y, 3)\n",
    "test_y = to_categorical(test_y, 3)\n",
    "train_y.shape\n",
    "\n",
    "5-1) Modeling : multi-input & Concatenate layer\n",
    "# Functional API만 가능!!!!\n",
    "# 1. 세션 클리어\n",
    "clear_session()\n",
    "# 2. 레이어 사슬처럼 엮기 : input 2개!\n",
    "il_l = Input( shape=(2,) )\n",
    "hl_l = Dense(2, activation=relu)(il_l)\n",
    "il_w = Input( shape=(2,) )\n",
    "hl_w = Dense(2, activation=relu)(il_w)\n",
    "cl = Concatenate()([hl_l, hl_w])\n",
    "ol = Dense(3, activation=softmax)(cl)\n",
    "# 3. 모델 시작과 끝 지정\n",
    "model = Model([il_l, il_w], ol)\n",
    "# 4. 모델 컴파일\n",
    "model.compile(loss=categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=Adam())\n",
    "model.summary()\n",
    "\n",
    "5-2) Modeling : multi-input & Add layer\n",
    "tr_x_p.shape, train_y.shape\n",
    "keras.backend.clear_session()\n",
    "il_s = keras.layers.Input(shape=(2,))\n",
    "hl_s = keras.layers.Dense(6,activation='swish')(il_s)\n",
    "il_p = keras.layers.Input(shape=(2,))\n",
    "hl_p = keras.layers.Dense(6,activation='swish')(il_p)\n",
    "add_l = keras.layers.Add()([hl_s, hl_p])\n",
    "ol = keras.layers.Dense(3,activation='softmax')(add_l)\n",
    "model = keras.models.Model([il_s,il_p],ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "6) 모델 시각화\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "7) 학습\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "model.fit([tr_x_l, tr_x_w], train_y, validation_split=0.1, epochs=1000, verbose=1, callbacks=[es])\n",
    "        # 모델에 붓는 순서 지켜야됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593f273-92a5-4600-8cd1-aa85307168a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324770b9-89db-4637-81b7-f9369f2567ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd2b8d-bc7e-4ab6-9d73-54faa199b194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
