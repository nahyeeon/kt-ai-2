{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec11f1-d725-4f69-9547-6169fc46267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현장에서 많이씀(성능이 좋기때문) => RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6586a9b-b735-473d-b739-6811b33bedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params \n",
    "KNN { 'n_neighbors' : range(3,51,2), 'metric' : ['euclidean', 'manhattan']  }\n",
    "DecisionTree { 'max_depth':range(2,11), 'min_samples_leaf':range(10,101,10) }\n",
    "RandomForest { 'n_estimators':[20,50,100], 'max_features':range(1,21) }\n",
    "XGBoost {'learning_rate' : np.linspace(0.01,0.2, 20), 'n_estimators':range(60,200,20), 'max_depth':[3,4,5,6]}\n",
    "SVM { 'C' : np.linspace(0.01, 100, 50), 'gamma':[0.001,0.01,.1,1] }\n",
    "\n",
    "GridSearchCV(m, params, cv=5, scoring = 'neg_mean_absolute_error')\n",
    "XGBRegressor(objective = 'reg:squarederror')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21635a-7ffc-458a-8c3f-1153adb17a03",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b2fbff-8574-435a-8be6-f587fc7a189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리들을 불러오자.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 전처리\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 모델링\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import * \n",
    "\n",
    "# 비지도 학습\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c3a6c-841d-4042-bb6e-c7c3520e15f7",
   "metadata": {},
   "source": [
    "## target 변수 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31aedfe-394b-4ab8-8096-622dad5d30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Creditability'].value_counts())\n",
    "print(data['Creditability'].value_counts()/ data.shape[0])\n",
    "\n",
    "data['Creditability'].value_counts().plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d154d6a-7f80-40dc-aa6e-c437c8391566",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cdeb5-e440-42eb-9823-186597581100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터분할1\n",
    "target = 'Sales'\n",
    "x = data.drop(target, axis=1)\n",
    "y = data.loc[:, target]\n",
    "\n",
    "# 가변수화\n",
    "dumm_cols = ['ShelveLoc','Education','Urban', 'US']\n",
    "x = pd.get_dummies(x, columns = dumm_cols, drop_first = True)\n",
    "\n",
    "# 데이터 분할2\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.2\n",
    "                                                  , random_state = 2022)\n",
    "\n",
    "# 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "x_train_s = scaler.fit_transform(x_train)\n",
    "x_val_s = scaler.transform(x_val)\n",
    "\n",
    "x_train_s = pd.DataFrame(x_train_s, columns=list(x))\n",
    "x_val_s = pd.DataFrame(x_val_s, columns=list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64255320-fd98-4f20-b828-d87efa0f4db4",
   "metadata": {},
   "source": [
    "## Fitting Graph ->Elbow Method [모델과적합]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ec031-30e5-4a94-8c13-8a7602d610b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "* 가장 단순한 모델(평균모델)\n",
    "** knn : k를 최대로 크게하면 평균 모델이 됨.\n",
    "** k의 최대값은 학습 데이터의 행 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe7a64-aa84-4141-8d05-a60747447be9",
   "metadata": {},
   "source": [
    "* Decision Tree\n",
    "** Decision Tree는 나무의 크기가 클 수록 복잡한 모델\n",
    "** 크기를 결정하는 파라미터는 max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff7702-02a6-428e-aca3-0b02b207cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "n = x_train_s.shape[0]\n",
    "model = KNeighborsRegressor(n_neighbors = n) # train set의 행 수\n",
    "model.fit(x_train_s, y_train)\n",
    "pred_train = model.predict(x_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc2d5d-ca76-4a77-aaf1-45bf0b8c5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = [] # train set을 가지고 예측한 결과\n",
    "result_val = [] # val set을 가지고 예측한 결과\n",
    "k_values = list(range(1,101))\n",
    "\n",
    "# KNN\n",
    "for d in k_values :\n",
    "    model = KNeighborsClassifier(n_neighbors= d)\n",
    "    model.fit(x_train_s, y_train)\n",
    "    pred_tr, pred_val = model.predict(x_train_s), model.predict(x_val_s)\n",
    "    result_train.append(accuracy_score(y_train, pred_tr))\n",
    "    result_val.append(accuracy_score(y_val, pred_val))\n",
    "    \n",
    "result_train = [] # train set을 가지고 예측한 결과\n",
    "result_val = [] # val set을 가지고 예측한 결과\n",
    "depth = list(range(1,21))\n",
    "\n",
    "# Decision Tree\n",
    "for d in depth :\n",
    "    model = DecisionTreeClassifier(max_depth = d)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred_tr, pred_val = model.predict(x_train), model.predict(x_val)\n",
    "    result_train.append(accuracy_score(y_train, pred_tr))\n",
    "    result_val.append(accuracy_score(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b42a9-2736-410b-9789-40287fd91b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(k_values, result_train, label = 'train_acc', marker = 'o')\n",
    "plt.plot(k_values, result_val, label = 'val_acc', marker = 'o')\n",
    "\n",
    "plt.xlabel('Complexity')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beeb07e-8f9e-450f-a0c8-592fffca7cff",
   "metadata": {},
   "source": [
    "## Decision Tree[ 변수중요도 그래프 ] 실전에서 많이 씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979c9b5-e881-45d8-91b7-1159b6e0615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 이름을 이용하여 시각화\n",
    "plt.figure(figsize = (20,8)) # 그림 사이즈 조절\n",
    "plot_tree(m3.best_estimator_, feature_names = x_train.columns, \n",
    "               class_names= ['Bad', 'Good'], filled = True, fontsize = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484790ba-8b17-43e3-bd6a-852f81a151fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names):\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    fi_df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x='feature_importance', y='feature_names', data = fi_df)\n",
    "\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    plt.grid()\n",
    "\n",
    "    return fi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59b9a5-05b1-4e0a-9404-6a1de506990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(model.feature_importances_, list(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19d05d-637d-4055-8820-180621d28edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(m3.best_estimator_.feature_importances_, list(x_train)) # 튜닝했기 때문에"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26fdad3-eb3d-4e64-bca5-4d3429b744a8",
   "metadata": {},
   "source": [
    "## Regessor 차트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672f86a-faa5-4385-85d5-70ad9462e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝 과정 로그를 df로 저장 합시다.\n",
    "result = pd.DataFrame(m1_gs.cv_results_)\n",
    "\n",
    "# 튜닝 결과를 그래프로 그려봅시다.\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.lineplot(x='param_max_depth', y='mean_test_score', data = result)  # plt.plot\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620285a-44ce-4fcc-8f12-eec866a79908",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR(Regressor)\n",
    "# 이를 차트로 그려봅시다.\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.lineplot(x = 'param_C', y = 'mean_test_score', data = result, hue = 'param_gamma')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4d163-b6ec-4ec9-b50e-b91a5054114b",
   "metadata": {},
   "source": [
    "## XGB 변수중요도 / 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79b9a7-8b55-47a7-86c0-ad406137af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위에꺼 plot_feature_importance 함수 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cfedd-07e6-484e-b631-9e5fc4a9fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb의 변수 중요도\n",
    "weight : 모델 전체에서 해당 feature가 split될 때 사용된 횟수의 합(plot_tree 에서의 기본값)\n",
    "gain : feature별 평균 imformation gain.(model.feature_importances_ 의 기본값)\n",
    "cover : feature가 split 할때의 샘플 수의 평균."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf69414-2d92-4b9e-b32d-1d520116b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, plot_tree, plot_importance\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c8e9e-0bb5-4b42-a041-af290eb0af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_feature_importance(model.feature_importances_, list(x),6) #x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f47772-a1b8-44b5-b798-32b0f78cb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화(Tree하나씩 열어볼 수 있음)\n",
    "plt.rcParams['figure.figsize'] = 20,20  # 파일전체에 영향을 미침 !!!!\n",
    "plot_tree(model, num_trees = 0) \n",
    "plt.show()\n",
    "\n",
    "# xgboost 자체 plot_tree 함수를 제공합니다.\n",
    "# plot_tree(model, num_trees = 0)\n",
    "# num_trees : 전체 트리 5개짜리 모델이므로 각각 0~4까지 인덱스로 조회해 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f2c63-94d3-4652-982d-d4bbf308f063",
   "metadata": {},
   "source": [
    "## 성능비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7fa2d-6358-4b95-b3d1-d030c05b573e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE, MAE, MAPE = [],[],[]\n",
    "model_desc = ['lr_selected', 'lr_all','knn','dt','rf','xgb','svm']\n",
    "pred = [p1, p2, p3, p4, p5, p6,p7]\n",
    "\n",
    "for i, p in enumerate(pred) :\n",
    "    RMSE.append(mean_squared_error(y_val, p, squared=False))\n",
    "    MAE.append(mean_absolute_error(y_val, p))\n",
    "    MAPE.append(mean_absolute_percentage_error(y_val, p))\n",
    "\n",
    "result = pd.DataFrame({'model_desc':model_desc,'RMSE':RMSE,'MAE':MAE,'MAPE':MAPE})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543c4d3-d6f5-415f-abb8-251ab9fec147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_val, pred1))\n",
    "print(classification_report(y_val, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921def8-9b58-4f63-94d5-5fd1579763dd",
   "metadata": {},
   "source": [
    "## Decision Tree 시각화 및 변수중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74512328-ac56-4f62-8165-a1b739bd2c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10)) # 그림 사이즈 조절\n",
    "plot_tree(m1, feature_names = list(x_train), \n",
    "               class_names= ['Stay', 'Leave'], filled = True, fontsize = 10);  # class_names = [target의 내용]\n",
    "plt.show()\n",
    "print('-'*88)\n",
    "# 변수 중요도\n",
    "print(list(x_train))\n",
    "print(m1.feature_importances_)\n",
    "print('-'*88)\n",
    "print(classification_report(y_val, p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eaf2ba-8169-49c1-ab4e-c2503d7049fe",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀를 위한 전진선택법 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f321f-66db-420b-80f0-047e9d7bad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "\n",
    "def forward_stepwise_linear(x_train, y_train):\n",
    "\n",
    "    # 변수목록, 선택된 변수 목록, 단계별 모델과 AIC 저장소 정의\n",
    "    features = list(x_train)\n",
    "    selected = []\n",
    "    step_df = pd.DataFrame({ 'step':[], 'feature':[],'aic':[]})\n",
    "\n",
    "    # \n",
    "    for s in range(0, len(features)) :\n",
    "        result =  { 'step':[], 'feature':[],'aic':[]}\n",
    "\n",
    "        # 변수 목록에서 변수 한개씩 뽑아서 모델에 추가\n",
    "        for f in features :\n",
    "            vars = selected + [f]\n",
    "            x_tr = x_train[vars]\n",
    "            model = OLS(y_train, add_constant(x_tr)).fit(disp=False)\n",
    "            result['step'].append(s+1)\n",
    "            result['feature'].append(vars)\n",
    "            result['aic'].append(model.aic)\n",
    "        \n",
    "        # 모델별 aic 집계\n",
    "        temp = pd.DataFrame(result).sort_values('aic').reset_index(drop = True)\n",
    "\n",
    "        # 만약 이전 aic보다 새로운 aic 가 크다면 멈추기\n",
    "        if step_df['aic'].min() < temp['aic'].min() :\n",
    "            break\n",
    "        step_df = pd.concat([step_df, temp], axis = 0).reset_index(drop = True)\n",
    "\n",
    "        # 선택된 변수 제거\n",
    "        v = temp.loc[0,'feature'][s]\n",
    "        features.remove(v)\n",
    "\n",
    "        selected.append(v)\n",
    "    \n",
    "    # 선택된 변수와 step_df 결과 반환\n",
    "    return selected, step_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64df06-f8e2-4d8a-b2ef-97d362534801",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars, result = forward_stepwise_logistic(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0df5b-343a-4271-9877-0ac0cef5ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 변수\n",
    "lr_m1 = LinearRegression()\n",
    "lr_m1.fit(x_train[vars], y_train)\n",
    "p1 = lr_m1.predict(x_val[vars])\n",
    "\n",
    "print('RMSE : ', mean_squared_error(y_val, p1, squared=False))\n",
    "print('MAE  : ', mean_absolute_error(y_val, p1))\n",
    "print('MAPE : ', mean_absolute_percentage_error(y_val, p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf20d7b-664d-4370-8e00-55b8e409fb21",
   "metadata": {},
   "source": [
    "## cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c24999-fa58-4b07-b323-450de6a1323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# train + validation set을 이용하여 학습, 예측, 평가를 한번에. (여기서는 .fit 이 아님!)\n",
    "dt_result = cross_val_score(model, x, y, cv=10)\n",
    "print(dt_result)\n",
    "print(dt_result.mean(), dt_result.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd0876d-960f-44ea-b0a5-8a2acb251549",
   "metadata": {},
   "source": [
    "## Permutation Feature Importance(그 외 변수중요도 그래프)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd55a3-cfe5-4fcb-ace0-1b399f315a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d30d2c-6d7c-4780-9492-1a021fc4c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfi1 = permutation_importance(model4, x_val_s, y_val, n_repeats=10, scoring = 'r2', random_state=2022)\n",
    "# scoring = 'accuracy' default[분류 모델]\n",
    "# deep learning 모델에 대해서는 명시적으로 scoring = 'r2'을 지정해 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58147e8f-a372-4b2c-a951-7df3e66ce309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature별 Score 분포\n",
    "plt.figure(figsize = (10,8))\n",
    "for i,vars in enumerate(list(x)) :\n",
    "    sns.kdeplot(pfi1.importances[i], label = vars)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820c5a2-0ff6-4c62-b698-2feac8aa0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = pfi1.importances_mean.argsort()\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.boxplot(pfi1.importances[sorted_idx].T, vert=False, labels=x.columns[sorted_idx])\n",
    "plt.axvline(0, color = 'r')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d3e93-fd33-4813-b864-ad186951fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균값으로 변수중요도 그래프 그리기\n",
    "pfi1 = permutation_importance(model1, x_val_s, y_val, n_repeats=10, scoring = 'r2', random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc70a2-80be-4adf-a371-f3b0cd35c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 중요도 plot(가져오기)\n",
    "result = plot_feature_importance(pfi1.importances_mean, list(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa99e68-a6f0-4011-b165-60185b89f33d",
   "metadata": {},
   "source": [
    "## Partial Dependence Plot(개별 변수별 관계)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25612daa-29b7-4292-a14c-4f611064b304",
   "metadata": {},
   "source": [
    "* 변수 중요도,PDP : train 데이터로 살펴보는 것이 기본이다. 그리고 결과가 유사해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524504e-98c0-4b99-85f4-ddc30f355d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence, partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b994514-5ba4-44e8-8c6f-d3514006025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 변수 분석\n",
    "var = 'MonthlyIncome'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "plot_partial_dependence(model, features = [var], X = x_val)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac85a3e-a9a0-407d-9b5a-5b6c28609b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터로 확인\n",
    "var = 'MonthlyIncome'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12, 8\n",
    "plot_partial_dependence(model, features = [var], X = x_val, kind = 'both') #kind = 'average'\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35f900-19bf-48d5-b435-3be786601d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개 변수 비교\n",
    "plot_partial_dependence(model, features = ['rm','lstat'], X = x_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9cea2-ca6a-4260-8783-c65510ac347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개 변수 비교\n",
    "plot_partial_dependence(model2, features = [('CreditAmount','Age')], X = x_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13acb0-6d39-4e2f-a7ad-b98442f5d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링한거 데이터 프레임에 넣어서 뽑아야함\n",
    "x_train_s = pd.DataFrame(x_train_s, columns = list(x))  # 칼럼이름 지정 필요!!\n",
    "x_val_s = pd.DataFrame(x_val_s, columns = list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd92fd6-e143-48c7-839e-96ab575b40ff",
   "metadata": {},
   "source": [
    "## SHAP 값으로 모델의 예측 설명하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bd8b4-529c-4568-a7e7-b8167cbef6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀는 회귀계수로 변수 기여도 해석해도 무방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd050132-df09-4291-bc29-658ad30df832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (회귀모델)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer1.shap_values(x_train)\n",
    "\n",
    "# (분류모델)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777c0f6-5481-49e9-a1d9-5dcce0d4076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측하기 위해서는 입력데이터(x)가 2차원이어야 합니다.\n",
    "pred = model1.predict(x_train.iloc[0:1,:])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361de6de-deb7-4cf6-8ce8-6f1a3a522cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train의 평균(회귀)\n",
    "explainer1.expected_value\n",
    "\n",
    "# train의 평균(분류)\n",
    "explainer1.expected_value[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9a1ae-2275-452e-b6c6-567d2b419c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스별 데이터\n",
    "shap.initjs() # javascript 시각화 라이브러리 --> colab에서는 모든 셀에 포함시켜야 함.-> 아나콘다에서는 한번만 !\n",
    "index=371\n",
    "# force_plot(전체평균, shapley_values, input)\n",
    "shap.force_plot(explainer1.expected_value, shap_values1[index,:], x.iloc[index,:])\n",
    "\n",
    "# 분류모델\n",
    "shap.initjs() # javascript 시각화 라이브러리 --> colab에서는 모든 셀에 포함시켜야 함.-> 아나콘다에서는 한번만 !\n",
    "index=932\n",
    "# force_plot(전체평균, shapley_values, input)\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][index,:], x.iloc[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a1d2a-6bf7-46e5-86da-61fda96261e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터\n",
    "shap.initjs() # javascript 시각화 라이브러리 --> colab에서는 모든 셀에 포함시켜야 함.-> 아나콘다에서는 한번만 !\n",
    "\n",
    "# force_plot(전체평균, shapley_values, input)\n",
    "shap.force_plot(explainer1.expected_value, shap_values1[0, :], x_train.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf225d-cdd8-4e25-a11e-d96ef4fadca5",
   "metadata": {},
   "source": [
    "## class balance를 맞추기 위한 resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f098a68-04d1-45a1-9473-e893b5fca852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3a8f7-42da-4cb1-a3b2-a0d0644bf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a0459-dca1-4b10-9c53-79827e1a9fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 비지도 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b59d6-b431-4063-9d80-7500cf3a167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1,50)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(mobile_x)\n",
    "    inertias.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bcac3-b88c-456d-b8d6-846b97a4e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34af48-e397-48a1-aaa7-c27279a6a29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델링[KNN]\n",
    "model = KMeans(n_clusters=5)\n",
    "model.fit(mobile_x)\n",
    "pred = model.predict(mobile_x)\n",
    "pred = pd.DataFrame(pred, columns = ['predict'])\n",
    "# 결과 보기\n",
    "mobile_y.reset_index(inplace=True, drop=True)\n",
    "result = pd.concat([mobile_x, mobile_y, pred], axis =1)\n",
    "result.CHURN = result.CHURN.astype('int')\n",
    "# 클러스터 별 고객이탈율\n",
    "result.groupby('predict')['CHURN'].mean()\n",
    "# 전체 평균\n",
    "result['CHURN'].value_counts() / result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e88bc6-48aa-43a0-bf61-6195f7628f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN 모델을 만들어 봅시다.\n",
    "model = DBSCAN(eps=0.1, min_samples=3)\n",
    "model.fit(x)\n",
    "# fitting한 후에 모델의 labels_ 값이 찾아낸 군집 종류입니다.\n",
    "clusters = model.labels_\n",
    "# 군집 번호 중 -1은 이상치를 의미합니다.(어느 군집에도 포함 안되는 값들!)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126cc2cd-68ba-4e0c-b45f-2cf050a208b6",
   "metadata": {},
   "source": [
    "## 시계열 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359fee4-1fa7-45ce-94c0-0b540f19c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1b49b-b28b-4008-b77d-f1ef70702d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 시계열로 확인 \n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(data['sales'])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "temp = data[-100:]\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(temp['sales'], marker ='o')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa23b2-c179-4c13-a838-d655a9e750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잔차 분석\n",
    "def residual_diag(residuals, lags = 20) :\n",
    "\n",
    "    print('* 정규성 검정(> 0.05) : ', round(spst.shapiro(residuals)[1],5))\n",
    "    print('* 정상성 검정(< 0.05) : ', round(sm.tsa.stattools.adfuller(residuals)[1],5))\n",
    "    print('* 자기상관성 확인(ACF, PACF)')\n",
    "    fig,ax = plt.subplots(1,2, figsize = (15,5))\n",
    "    plot_acf(residuals, lags = lags, ax = ax[0])\n",
    "    plot_pacf(residuals, lags = lags, ax = ax[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733fa1d-5bec-493d-98c1-78d906b7dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 타입으로 변경\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "# 날짜를 인덱스로 변환\n",
    "data['DT'] = data['date']\n",
    "data.set_index('DT', inplace=True)\n",
    "data.head()\n",
    "## 날짜단위 지정하기 : freq / 인덱스 조회시, 마지막에 있는 freq 옵션\n",
    "# 일단위\n",
    "data.asfreq('D').head()\n",
    "# 월(말)단위\n",
    "data.asfreq('M').head()\n",
    "# 월초 단위\n",
    "data.asfreq('MS').head()\n",
    "#(추가) 빠진값 찾기\n",
    "temp = data.asfreq('D')\n",
    "temp.isna().sum()\n",
    "# 채우기\n",
    "data.asfreq('D', method = 'ffill')\n",
    "df = data.asfreq('D') # 일단위 데이터이므로 이걸로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c782bfe-33b8-4ed8-ba1e-14cd98bc0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 만들기\n",
    "df['y'] = df['sales'].shift(-1)\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "# 제일 마지막 행은 삭제\n",
    "df.dropna(axis = 0, inplace = True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077b5ee-bae1-4267-9902-c3c237830513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "# 1) x, y 나누기\n",
    "# .values(넘파이 어레이)로 변환해서 저장하는 이유 ➡ 데이터 스플릿 index를 적용해서 데이터를 가져오기 위해서\n",
    "target = 'y'\n",
    "\n",
    "x = df.drop([target, 'date'], axis = 1)\n",
    "y = df.loc[:, target]\n",
    "\n",
    "# 시계열 데이터 분할\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "x.shape\n",
    "# validation set size\n",
    "val_size = 30\n",
    "nfold = 3\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = nfold, test_size = val_size)\n",
    "tscv\n",
    "\n",
    "#참조\n",
    "# .split을 이용하여 fold 하나씩 인덱스들을 뽑아 낼 수 있음.\n",
    "for train_index, val_index in tscv.split(x):\n",
    "    print(\"Train:\", train_index, \"Val:\", val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7509d9-02fa-4c4d-9963-d83d88be275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "# loop 돌며 모델링(cross-validation) 수행\n",
    "rmse, mae, mape = [],[],[]\n",
    "residuals = []\n",
    "pred = []\n",
    "model = LinearRegression()\n",
    "\n",
    "for train_index, val_index in tscv.split(x):\n",
    "\n",
    "    # 인덱스로 데이터 분할\n",
    "    x_train, y_train = x.iloc[train_index], y.iloc[train_index]\n",
    "    x_val, y_val = x.iloc[val_index], y.iloc[val_index]\n",
    "\n",
    "    # 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 예측\n",
    "    pr = model.predict(x_val)\n",
    "    pred += list(pr)\n",
    "\n",
    "    # 평가\n",
    "    rmse.append(mean_squared_error(y_val, pr, squared = False))\n",
    "    mae.append(mean_absolute_error(y_val, pr))\n",
    "    mape.append(mean_absolute_percentage_error(y_val, pr))\n",
    "\n",
    "    # 잔차 : 각 fold의 결과를 리스트로 변환하여 추가\n",
    "    residuals += list(y_val - pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969db4bd-ac0c-4fbb-adb9-1e023faaf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 평가\n",
    "print('RMSE : ',round(np.mean(rmse),4))\n",
    "print('MAE  : ',round(np.mean(mae),4))\n",
    "print('MAPE : ',round(np.mean(mape),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ccda9-2ee3-442d-aa60-215ffc227846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 비교\n",
    "n = val_size * nfold\n",
    "pred = pd.Series(pred, index = y[-n:].index)\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(y[:-n], label = 'train')\n",
    "plt.plot(y[-n:], label = 'val')\n",
    "plt.plot(pred, label = 'predicted')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.plot(y[-n:], label = 'val')\n",
    "plt.plot(pred, label = 'predicted')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6b063-297d-4b19-90ca-b535597d6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가: 잔차분석\n",
    "## 시각화\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, color = 'r', ls = '--')\n",
    "plt.axhline(np.mean(residuals), color = 'g', ls = '--')\n",
    "plt.show()\n",
    "\n",
    "## ACF, PACF(자기상관성 여부 확인)\n",
    "lags = 20\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize = (15,5))\n",
    "plot_acf(residuals, lags = lags, ax = ax[0])\n",
    "plot_pacf(residuals, lags = lags, ax = ax[1])\n",
    "plt.show()\n",
    "\n",
    "## 검정\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "stats.shapiro(residuals)[1]  # 정규성 검정 : Shapiro-Wilk 검정\n",
    "sm.tsa.stattools.adfuller(residuals)[1]  # 정상성 검정 : ADF 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21e45a-b164-4278-96bb-e2922bb8410f",
   "metadata": {},
   "source": [
    "## 시계열 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a079f9-4e0d-49d0-b774-c97f26ab228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "def plot_model_result(y_train, y_val, pred) :\n",
    "    pred = pd.Series(pred, index = y_val.index)\n",
    "\n",
    "    # 전체 시각화\n",
    "    plt.figure(figsize = (20,12))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(y_train, label = 'train')\n",
    "    plt.plot(y_val, label = 'val')\n",
    "    plt.plot(pred, label = 'pred')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(y_val, label = 'val')\n",
    "    plt.plot(pred, label = 'pred')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9739f4e-d804-4514-9beb-94847e7120d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y값 살펴보기\n",
    "residual_diag(y_train, lags = 30)\n",
    "\n",
    "# ARIMA 모델링\n",
    "m1_1 = sm.tsa.SARIMAX(y_train, order=(1,0,1)).fit() # ARMA\n",
    "m1_2 = sm.tsa.SARIMAX(y_train, order=(1,1,1)).fit() # ARIMA\n",
    "\n",
    "# SARIMA 모델링 : P, D, Q, m = 1,1,1,7 로 모델을 생성합시다.\n",
    "m2_1 = sm.tsa.SARIMAX(y_train, order=(5,1,4), seasonal_order=(1,1,1,7)).fit()\n",
    "\n",
    "m3_1 = sm.tsa.SARIMAX(y_train, order=(5,1,4), seasonal_order=(1,1,1,7), exog=x_train).fit()\n",
    "\n",
    "# 평가[잔차 진단]\n",
    "residuals = m1_1.resid  # y_train과 예측값 차이\n",
    "residual_diag(residuals)\n",
    "# 평가[AIC] ->선형 모델에서의 적합도와, feature가 과도하게 늘어나는 것을 방지하도록 설계된 통계량이 AIC 입니다.\n",
    "# 값이 작을 수록 좋은 모델\n",
    "# 공식 : 𝐴𝐼𝐶=−2 ln⁡(𝐿)+2𝑘 ➡ - 모델의 적합도 + 변수의 갯수\n",
    "print('model1 AIC :', m1_1.aic)\n",
    "# 평가[Validation]\n",
    "pred = m1_1.forecast(30)   # SARIMAX 모델을 생성하고, 예측할 때는 exog=x_val 옵션이 들어가야 함. \n",
    "print('MAE :', mean_absolute_error(y_val, pred))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_val, pred))\n",
    "# 평가[결과 시각화]\n",
    "plot_model_result(y_train, y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc011a5-ea27-4a08-bce6-dd151e82c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 튜닝\n",
    "\n",
    "# 학습\n",
    "from itertools import product\n",
    "# product 함수를 이용하여 값의 조합을 구성\n",
    "p = [1,2,3,4,5]\n",
    "q = [1,2,3,4,5]\n",
    "d = [1]\n",
    "iter = list(product(p,d,q))\n",
    "iter\n",
    "\n",
    "# 튜닝 \n",
    "mae, aic = [],[]\n",
    "for i in iter :\n",
    "    model_fit = sm.tsa.SARIMAX(y_train, order=(i[0],i[1],i[2])).fit()\n",
    "    pred = model_fit.forecast(30)\n",
    "    mae.append( mean_absolute_error(y_val, pred))\n",
    "    aic.append(model_fit.aic)\n",
    "    print(i)\n",
    "    \n",
    "result = pd.DataFrame({'params(p,d,q)' : iter, 'mae' : mae, 'aic':aic})\n",
    "\n",
    "display(result.loc[result['mae'] == result.mae.min()])\n",
    "display(result.loc[result['aic'] == result.aic.min()])\n",
    "\n",
    "# 가장 성능이 좋은 p, d, q 값으로 모델을 생성합니다.\n",
    "m1_3 = sm.tsa.SARIMAX(y_train, order=(5,1,4)).fit()\n",
    "\n",
    "# 평가[잔차진단]\n",
    "residuals = m1_3.resid\n",
    "residual_diag(residuals) # seasonallity \n",
    "# 평가[AIC]\n",
    "print('model2 AIC :', m1_3.aic)\n",
    "# 평가[validation]\n",
    "p1 = m1_3.forecast(30)\n",
    "print('MAE :', mean_absolute_error(y_val, p1))\n",
    "print('MAPE:', mean_absolute_percentage_error(y_val, p1))\n",
    "# 결과 시각화\n",
    "plot_model_result(y_train, y_val, p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841415ba-a113-49b3-a213-0f2df244b0af",
   "metadata": {},
   "source": [
    "## 딥러닝[keras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63aa4c-1211-43fd-a84b-c6ffb57254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ad5b2-0eec-4277-8908-5af216a9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape , y.shape  # 확인해볼것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9d68f-a6f4-4763-8fef-6d406055849b",
   "metadata": {},
   "source": [
    "* Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56367fdb-b8cf-4b4b-b174-7834b14485f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Linear Regression]\n",
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "# 결과 출력\n",
    "print(model.predict(x).reshape(-1,) )\n",
    "\n",
    "@ [Logistic Regression]\n",
    "keras.backend.clear_session()\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(input_layer)\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb0919-cb10-4b52-b673-e043cccdd6c2",
   "metadata": {},
   "source": [
    "* Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67fd5e0-82fb-42c9-a314-9715ab7552b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Linear Regression]\n",
    "# 1번 청소 : 이미 만들어진 모델이 있다면 그 모델을 없애줘\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 2번 모델 선언\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# 3번 모델 블록 조립\n",
    "model.add( keras.layers.Input(shape=(1,)) )\n",
    "model.add( keras.layers.Dense(1) )\n",
    "\n",
    "## 오리지널 Sequential API\n",
    "# model.add( keras.layers.Dense(1, input_shape=(1,)) )\n",
    "\n",
    "# 4번 컴파일 \n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(x[:15], y[:15], epochs=10, verbose=1)\n",
    "print(y[15:])\n",
    "print(model.predict(x[15:]))\n",
    "\n",
    "@ [Logistic Regression]\n",
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# model에 순차적으로 레이어를 쌓아가겠다는 의도!\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# model에 인풋 값을 받는 레이어를 넣음\n",
    "model.add( keras.layers.Input(shape=(1,)) )\n",
    "# model에 Dense 레이어를 넣을거야 (최초의 레이어) : weight를 곱하고, bias를 더해주는 과정\n",
    "model.add( keras.layers.Dense(1, activation='sigmoid') )\n",
    "\n",
    "# 오리지널 Sequential API\n",
    "# model.add( keras.layers.Dense(1, input_shape=(1,), activation='sigmoid') )\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "# keras.losses.binary_crossentropy 이걸로도 가능\n",
    "\n",
    "model.fit(x[:15], y[:15], epochs=10, verbose=1)\n",
    "print(y[15:])\n",
    "print(model.predict(x[15:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91289ec3-9fbe-42a4-bb08-76d33084e753",
   "metadata": {},
   "source": [
    "* 멀티클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60420175-9abb-4a4d-aa65-a20f60569a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미래 데이터를 먼제 떼어내야하기 때문에 먼저 분리해준다.(미래데이터는 건드리지 않는다)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.2, random_state=2022)\n",
    "x_train.shape, y_train.shape\n",
    "# One-Hot Encoding  (get_dummies= x에만 적용)\n",
    "class_n = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, class_n)\n",
    "y_test = to_categorical(y_test, class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e62134-a6df-4a34-bd32-92d177f7835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ y 확인하기\n",
    "iris.target_names\n",
    "\n",
    "# One-Hot Encoding  (get_dummies= x에만 적용)\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "y = to_categorical(y, 3) # 반복 실행 주의!!(계속 생성됨)\n",
    "x.shape, y.shape\n",
    "\n",
    "@ [Sequential]\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(4,)))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,verbose=1)\n",
    "model.predict(x_test).reshape(-1)\n",
    "y.argmax(axis=1)\n",
    "\n",
    "@ [Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(4,))\n",
    "ol = keras.layers.Dense(3,activation='softmax')(il)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "model.fit(x_train,y_train,epochs=10, verbose=1)\n",
    "pred = model.predict(x_test)\n",
    "pred[:5] # 합치면 확률값 =1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b4936-56b0-4659-a35c-f24f016b555f",
   "metadata": {},
   "source": [
    "* Hidden layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab5d1f-3c3d-4be5-80ae-f6c1a261c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ [Sequential API]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(13,)))\n",
    "model.add(keras.layers.Dense(32,activation='relu'))\n",
    "model.add(keras.layers.Dense(32,activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "@ [Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(30,))\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden1')(il)\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden2')(hl)\n",
    "ol = keras.layers.Dense(1,activation='sigmoid')(hl)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "@ [multi-Functional]\n",
    "keras.backend.clear_session()\n",
    "il = keras.layers.Input(shape=(4,))\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden1')(il)\n",
    "hl = keras.layers.Dense(32, activation='relu', name='hidden2')(hl)  # 변수명 같아도 상관없음\n",
    "ol = keras.layers.Dense(3,activation='softmax')(hl)\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " # optimizer=keras.optimizers.Adam(0.01)-> eta\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066a064-fb8b-457c-93af-792304ffbdb9",
   "metadata": {},
   "source": [
    "## 딥러닝[ANN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6361238-7234-4dd4-937c-62c28c1ad4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참조코드\n",
    "'''\n",
    "matplolib inline 명령어를 통해서\n",
    "matplot으로 그리는 플롯들을 주피터 노트북 내에서 볼 수 있게 해준다.\n",
    "포맷을 retina로 바꾸면 그래프의 화질이 훨씬 좋아진다.\n",
    "'''\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20445e-b94f-47b6-b20a-c81a42dedc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) 전처리\n",
    "x = wine.data\n",
    "y = wine.target\n",
    "x.shape, y.shape\n",
    "data.target_names\n",
    "\n",
    "## reshape -> flatten하면 필요없음\n",
    "train_x.shape\n",
    "train_x = train_x.reshape([train_x.shape[0],-1])\n",
    "test_x = test_x.reshape([test_x.shape[0],-1])\n",
    "train_x.shape # 28*28\n",
    "## min-max scaling\n",
    "max_n, min_n = train_x.max(), train_x.min()\n",
    "max_n, min_n\n",
    "train_x = (train_x - min_n) / (max_n - min_n)\n",
    "test_x = (test_x - min_n) / (max_n - min_n)\n",
    "print(f'max : {train_x.max()} / min : {train_x.min()}')\n",
    "## target feature : One-hot Encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "len_y = len(set(train_y))\n",
    "train_y = to_categorical(train_y, len_y)\n",
    "test_y = to_categorical(test_y, len_y)\n",
    "\n",
    "2) 모델링\n",
    "train_x.shape, train_y.shape\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(train_x.shape[1]))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.01),metrics='accuracy')\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss',  # 무얼 관찰할지(관측대상)\n",
    "                   min_delta=0,         # 최소한 나빠지지 않으면 괜찮아\n",
    "                   patience=5,          # 중요! 몇번이나 참을지(거기까지 개선 안되면 멈출거야)\n",
    "                   verbose=1,            \n",
    "                   restore_best_weights=True)  # (반드시 사용)학습이 멈췄을 때, 최적의 가중치로 전환해줌\n",
    "model.fit(train_x, train_y, \n",
    "          validation_split=0.2,  # Train data의 20%를 Validation data로!\n",
    "          callbacks=[es],        # Early Stopping 적용\n",
    "          verbose=1, epochs=50)\n",
    "\n",
    "3) 예측\n",
    "pred_train = model.predict(train_x)\n",
    "pred_test = model.predict(test_x)\n",
    "single_pred_train = pred_train.argmax(axis=1)\n",
    "single_pred_test = pred_test.argmax(axis=1)\n",
    "logi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\n",
    "logi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n",
    "print('트레이닝 정확도 : {:.2f}%'.format(logi_train_accuracy*100))\n",
    "print('테스트 정확도 : {:.2f}%'.format(logi_test_accuracy*100))\n",
    "\n",
    "4) 확인\n",
    "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "for i, index in enumerate(np.random.choice(test_x.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(test_x[index].reshape([28,-1])), cmap='gray' )\n",
    "    \n",
    "    predict_index = pred_test[index].argmax(axis=0)\n",
    "    true_index = test_y[index].argmax(axis=0)\n",
    "    # Set the title for each image\n",
    "    ax.set_title(f\"{mnist_labels[predict_index]} ({mnist_labels[true_index]})\",\n",
    "                 color=(\"green\" if predict_index == true_index else \"red\"))\n",
    "    \n",
    "5) 오답확인\n",
    "true_false = (test_y.argmax(axis=1) == single_pred_test)\n",
    "f_id = np.where(true_false == False)[0]\n",
    "f_n = len(f_id)\n",
    "id = f_id[rd.randrange(0,f_n)]\n",
    "print(f'id = {id}' )\n",
    "print(f'다음 그림은 숫자 {test_y.argmax(axis=1)[id]} 입니다.')\n",
    "print(f'모델의 예측 : {single_pred_test[id]}')\n",
    "print(f'모델의 카테고리별 확률 : {np.floor(pred_test[id]*100)}')\n",
    "if test_y.argmax(axis=1)[id] == single_pred_test[id] :\n",
    "    print('===============')\n",
    "    print('정답입니다')\n",
    "    print('===============')\n",
    "else : \n",
    "    print('===============')\n",
    "    print('틀렸어요')\n",
    "    print('===============')\n",
    "plt.imshow(test_x[id].reshape([28,-1]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "6) 평가\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe819b5d-4d0f-4b45-af16-e768a4fb3bff",
   "metadata": {},
   "source": [
    "## Modeling : multi-input & Concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7af6d6-ab4f-49b4-b2fa-3bf9e6b15d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) 데이터 불러오기\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "print(data.DESCR) \n",
    "df_x = pd.DataFrame(x, columns=iris.feature_names)\n",
    "# null값 확인 필요\n",
    "iris.target_names\n",
    "\n",
    "2) train set, test set 구분하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_x, y, test_size=0.1, random_state=2022)\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape\n",
    "\n",
    "추가) Scaling (데이터 수치->너무 편차가 커서(min_max 필요))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "train_x = mm_scaler.fit_transform(train_x)\n",
    "test_x = mm_scaler.transform(test_x)\n",
    "pd.DataFrame(train_x, columns=iris.feature_names).describe()\n",
    "train_x = pd.DataFrame(train_x, columns=iris.feature_names)\n",
    "test_x = pd.DataFrame(test_x, columns=iris.feature_names)\n",
    "\n",
    "3) length끼리, width끼리\n",
    "print(df_x.columns)\n",
    "tr_x_l = train_x.loc[:, ['sepal length (cm)', 'petal length (cm)'] ]\n",
    "tr_x_w = train_x.loc[:, ['sepal width (cm)', 'petal width (cm)'] ]\n",
    "tr_x_l.shape, tr_x_w.shape\n",
    "te_x_l = test_x.loc[:, ['sepal length (cm)', 'petal length (cm)'] ]\n",
    "te_x_w = test_x.loc[:, ['sepal width (cm)', 'petal width (cm)'] ]\n",
    "\n",
    "4) One-hot Encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_y = to_categorical(train_y, 3)\n",
    "test_y = to_categorical(test_y, 3)\n",
    "train_y.shape\n",
    "\n",
    "5-1) Modeling : multi-input & Concatenate layer\n",
    "@ Functional API만 가능!!!!\n",
    "# 1. 세션 클리어\n",
    "clear_session()\n",
    "# 2. 레이어 사슬처럼 엮기 : input 2개!\n",
    "il_l = Input( shape=(2,) )\n",
    "hl_l = Dense(2, activation=relu)(il_l)\n",
    "il_w = Input( shape=(2,) )\n",
    "hl_w = Dense(2, activation=relu)(il_w)\n",
    "cl = Concatenate()([hl_l, hl_w])\n",
    "ol = Dense(3, activation=softmax)(cl)\n",
    "# 3. 모델 시작과 끝 지정\n",
    "model = Model([il_l, il_w], ol)\n",
    "# 4. 모델 컴파일\n",
    "model.compile(loss=categorical_crossentropy, metrics=['accuracy'],\n",
    "              optimizer=Adam())\n",
    "model.summary()\n",
    "\n",
    "5-2) Modeling : multi-input & Add layer\n",
    "tr_x_p.shape, train_y.shape\n",
    "keras.backend.clear_session()\n",
    "il_s = keras.layers.Input(shape=(2,))\n",
    "hl_s = keras.layers.Dense(6,activation='swish')(il_s)\n",
    "il_p = keras.layers.Input(shape=(2,))\n",
    "hl_p = keras.layers.Dense(6,activation='swish')(il_p)\n",
    "add_l = keras.layers.Add()([hl_s, hl_p])\n",
    "ol = keras.layers.Dense(3,activation='softmax')(add_l)\n",
    "model = keras.models.Model([il_s,il_p],ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "6) 모델 시각화\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)\n",
    "\n",
    "7) 학습\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "model.fit([tr_x_l, tr_x_w], train_y, validation_split=0.1, epochs=1000, verbose=1, callbacks=[es])\n",
    "        # 모델에 붓는 순서 지켜야됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c88908-5b03-4c91-a051-dc4506ec43ed",
   "metadata": {},
   "source": [
    "## 시각지능 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddd25f-c347-485b-ab54-d37c107c3a0c",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bd33f-550a-4886-a70d-99e29451d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = io.loadmat(\"notMNIST_small.mat\")\n",
    "\n",
    "# transform data\n",
    "X = data['images']\n",
    "y = data['labels']\n",
    "resolution = 28\n",
    "classes = 10\n",
    "\n",
    "X = np.transpose(X, (2, 0, 1))\n",
    "\n",
    "y = y.astype('int32')\n",
    "X = X.astype('float32') #/ 255.\n",
    "\n",
    "# shape: (sample, x, y, channel)\n",
    "X = X.reshape((-1, resolution, resolution, 1))\n",
    "\n",
    "# looking at data; some fonts are strange\n",
    "i = np.random.randint(0, 18723)\n",
    "print(i)\n",
    "plt.imshow( X[i,:,:,0] )\n",
    "plt.title( \"ABCDEFGHIJ\"[y[i]] )\n",
    "\n",
    "# random letters\n",
    "rows = 6\n",
    "fig, axs = plt.subplots(rows, classes, figsize=(classes, rows))\n",
    "\n",
    "for letter_id in range(10):\n",
    "    letters = X[y == letter_id]\n",
    "    for i in range(rows):\n",
    "        ax = axs[i, letter_id]\n",
    "        ax.imshow(letters[np.random.randint(len(letters)),:,:,0],\n",
    "                  cmap='Greys', interpolation='none')\n",
    "        ax.axis('off')\n",
    "        \n",
    "# splitting data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2022)\n",
    "\n",
    "x_train.shape, y_train.shape\n",
    "\n",
    "max_n, min_n = x_train.max(),x_train.min()\n",
    "\n",
    "x_train = (x_train - min_n)/ (max_n - min_n)\n",
    "x_test = (x_test - min_n)/ (max_n - min_n)\n",
    "\n",
    "len(np.unique(y_train))\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324770b9-89db-4637-81b7-f9369f2567ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(28,28,1,))\n",
    "hl = keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu',)(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu')(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "\n",
    "hl = keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "\n",
    "hl = keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.Dropout(.25)(ml)\n",
    "\n",
    "hl = keras.layers.Flatten()(hl)\n",
    "hl = keras.layers.Dense(512,)(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl) \n",
    "ol = keras.layers.Dense(10, activation='softmax')(hl)\n",
    "\n",
    "model = keras.models.Model(il,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4a828-c809-4b9f-9b7e-409f10f1c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(28,28,1))\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(il)\n",
    "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same')(hl)\n",
    "hl = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(.25)(hl)\n",
    "\n",
    "hl = keras.layers.Flatten()(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "hl = keras.layers.Dense(1024, activation='relu')(hl)\n",
    "ol = keras.layers.Dense(10, activation='softmax')(hl)\n",
    "\n",
    "model = keras.models.Model(il ,ol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3af6c7-0138-4488-acee-7d699c10745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, restore_best_weights=True)\n",
    "model.fit(x_train, y_train, validation_split=.2, batch_size=1024, epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e329d13-50dd-461f-8122-7937a58416e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "pred_array = np.zeros(shape=(y_pred.shape[0], y_pred.shape[1]))\n",
    "idx = 0\n",
    "\n",
    "for arr_val in y_pred :\n",
    "    # print(arr_val)\n",
    "    pred_array[idx][arr_val.argmax()] = 1\n",
    "    idx += 1\n",
    "    \n",
    "pred_array.shape\n",
    "\n",
    "@ 성능평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "print( f'{accuracy_score(y_test, pred_array):.4f}' )\n",
    "\n",
    "@ 문자 이미지 시각화\n",
    "import random as rd\n",
    "character = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J'}\n",
    "\n",
    "rand_n = rd.randrange(0, 3744)\n",
    "\n",
    "print(f'id = {rand_n}')\n",
    "print(f'실제 문자 : {character[y_test[rand_n].argmax()]}')\n",
    "print(f'모델의 문자 예측 : {character[y_pred[rand_n].argmax()]}' )\n",
    "print(f'모델의 문자별 예측 확률 : {np.round(y_pred[rand_n]*100)}')\n",
    "# print(f'모델의 문자들 총 확률 : {sum(np.round(y_pred[rand_n]*100))}')\n",
    "\n",
    "print('====================================================')\n",
    "\n",
    "if y_test[rand_n].argmax() == y_pred[rand_n].argmax() :\n",
    "    print('정답')\n",
    "else :\n",
    "    print('오답')\n",
    "\n",
    "print('====================================================')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_test[rand_n].reshape(28, 28), cmap='gray')\n",
    "plt.title(\"ABCDEFGHIJ\"[y_test[rand_n].argmax()] )\n",
    "plt.show()\n",
    "\n",
    "# 틀린 문자만 확인\n",
    "t_f = ( y_test.argmax(axis=1) == y_pred.argmax(axis=1) )\n",
    "false_id = np.where(t_f==False)[0]\n",
    "false_n = len(false_id)\n",
    "\n",
    "id = false_id[rd.randrange(0, false_n)]\n",
    "\n",
    "print(f'id = {id}')\n",
    "print(f'실제 문자 : {character[y_test[id].argmax()]}')\n",
    "print(f'모델의 문자 예측 : {character[y_pred[id].argmax()]}' )\n",
    "print(f'모델의 문자별 예측 확률 : {np.round(y_pred[id]*100)}')\n",
    "# print(f'모델의 문자들 총 확률 : {sum(np.round(y_pred[rand_n]*100))}')\n",
    "\n",
    "print('====================================================')\n",
    "\n",
    "if y_test[id].argmax() == y_pred[id].argmax() :\n",
    "    print('정답')\n",
    "else :\n",
    "    print('오답')\n",
    "\n",
    "print('====================================================')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_test[id].reshape(28, 28), cmap='gray')\n",
    "plt.title(\"ABCDEFGHIJ\"[y_pred[id].argmax()] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b244a83-691d-4558-9251-8e9552c8c508",
   "metadata": {},
   "source": [
    "### UltraLytics YOLO v3 Image Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d32db-9414-4d3c-bbfc-1086f5e495d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) UltraLytics git에서 복사하기\n",
    "!git clone https://github.com/ultralytics/yolov3.git\n",
    "\n",
    "2) yolov3 폴더 이동 및 requirements.txt 내부 패키지 설치\n",
    "!cd yolov3; pip install -r /content/yolov3/requirements.txt\n",
    "\n",
    "3) Image Detection\n",
    "3-1) 예제 이미지 다운로드 => !wget -O [저장할 파일명] [파일 주소]\n",
    "!wget -O /content/yolov3/data/images/14th_street.jpg\\\n",
    "https://raw.githubusercontent.com/DrKAI/image/main/14th_Street_2005.jpg\n",
    "\n",
    "3-2) COCO Dataset(성능지표)으로 pretrained 된 weights 다운로드 [weights가 없으면 자동 다운로드] \n",
    "=> !mkdir [경로/디렉토리 명]\n",
    "=> pretrained weights 다운로드\n",
    "!mkdir /content/yolov3/pretrained\n",
    "!wget -O /content/yolov3/pretrained/yolov3-tiny.pt\\\n",
    "https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3-tiny.pt\n",
    "\n",
    "3-3) detect.py를 python으로 직접 호출하여 수행 => 명령어 도움말 : !cd yolo3; python detect.py -h\n",
    "!cd yolov3; python detect.py -h\n",
    "!cd yolov3; python detect.py \\\n",
    "    --weights '/content/yolov3/pretrained/yolov3.pt' \\\n",
    "    --source '/content/yolov3/data/images' \\\n",
    "    --project '/content/yolov3/detected' \\\n",
    "    --name 'images' \\\n",
    "    --img 640 \\\n",
    "    --conf-thres 0.1 \\\n",
    "    --iou-thres 0.4 \\\n",
    "    --line-thickness 2 \\\n",
    "    --exist-ok \\# 덮어쓰기\n",
    "    --device CPU\n",
    "\n",
    "@ Detect Image 살펴보기\n",
    "from IPython.display import Image\n",
    "from google.colab import files\n",
    "\n",
    "# Image(filename=[파일 경로])\n",
    "Image(filename='/content/yolov3/detected/images/14th_street.jpg', width=850)\n",
    "\n",
    "# files.download(filename=[파일 경로])\n",
    "files.download(filename='/content/yolov3/detected/images/14th_street.jpg')\n",
    "\n",
    "# zip\n",
    "!zip -r /content/detected_image.zip /content/yolov3/detected/images2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b633ee0-0881-4d27-b266-086b66b5e510",
   "metadata": {},
   "source": [
    "### UltraLytics_YOLOv3_VideoDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5675720-bd1b-4f39-83fa-f24b59aae4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov3.git\n",
    "\n",
    "!cd yolov3; pip install -r /content/yolov3/requirements.txt\n",
    "\n",
    "!mkdir /content/yolov3/data/videos\n",
    "!wget -O /content/yolov3/data/videos/noway.mp4\\\n",
    "https://github.com/DrKAI/image/raw/main/No_Way_This_Happened.mp4\n",
    "\n",
    "!mkdir /content/yolov3/pretrained\n",
    "!wget -O /content/yolov3/pretrained/yolov3.pt\\\n",
    "https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt\n",
    "\n",
    "# !cd yolov3; python detect.py -h\n",
    "!cd yolov3; python detect.py \\\n",
    "    --weights '/content/yolov3/pretrained/yolov3.pt' \\\n",
    "    --source '/content/yolov3/data/videos/' \\\n",
    "    --project '/content/yolov3/detected' \\\n",
    "    --name 'videos' \\\n",
    "    --img 640 \\\n",
    "    --conf-thres 0.5 \\\n",
    "    --iou-thres 0.4 \\\n",
    "    --line-thickness 2 \\\n",
    "    --exist-ok\n",
    "    # --device CPU\n",
    "    \n",
    "from google.colab import files\n",
    "## colab은 멀티 다운로드 지원X\n",
    "## 폴더 압축하여 파일 하나로 만들고 다운로드\n",
    "!zip -r /content/detected_videos.zip /content/yolov3/detected/videos/\n",
    "\n",
    "files.download(filename='/content/yolov3/detected/videos/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f69e8-44c7-408a-b75b-1453c5f2fb68",
   "metadata": {},
   "source": [
    "### UltraLytics_YOLOv5_CustomData_ImageDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d2333-3ea6-476f-9ec0-068da8150e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "    \n",
    "!cd yolov5; pip install -r requirements.txt\n",
    "\n",
    "@ Image Detection\n",
    "1) 사전 작업된 CustomData yaml 다운로드\n",
    "!wget -O /content/yolov5/data/street.yaml\\\n",
    "https://raw.githubusercontent.com/DrKAI/CV/main/street_example.yaml\n",
    "\n",
    "2) pretrained 된 weights 다운로드 => weights가 없으면 자동 다운로드\n",
    "!mkdir /content/yolov5/pretrained\n",
    "!wget -O /content/yolov5/pretrained/yolov5s.pt\\\n",
    "https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt\n",
    "\n",
    "3) train용 이미지 다운로드\n",
    "!mkdir /content/datasets; mkdir /content/datasets/street\n",
    "!mkdir /content/datasets/street/images; mkdir /content/datasets/street/images/train\n",
    "!mkdir /content/datasets/street/labels; mkdir /content/datasets/street/labels/train\n",
    "\n",
    "!wget -O /content/street_images1.zip https://github.com/DrKAI/CV/raw/main/street_images1.zip\n",
    "!wget -O /content/street_images2.zip https://github.com/DrKAI/CV/raw/main/street_images2.zip\n",
    "!wget -O /content/street_images3.zip https://github.com/DrKAI/CV/raw/main/street_images3.zip\n",
    "\n",
    "!wget -O /content/street_labels1.zip https://github.com/DrKAI/CV/raw/main/street_labels1.zip\n",
    "!wget -O /content/street_labels2.zip https://github.com/DrKAI/CV/raw/main/street_labels2.zip\n",
    "!wget -O /content/street_labels3.zip https://github.com/DrKAI/CV/raw/main/street_labels3.zip\n",
    "    \n",
    "!unzip /content/street_images1.zip -d /content/datasets/street/images/train\n",
    "!unzip /content/street_images2.zip -d /content/datasets/street/images/train\n",
    "!unzip /content/street_images3.zip -d /content/datasets/street/images/train\n",
    "\n",
    "!unzip /content/street_labels1.zip -d /content/datasets/street/labels/train\n",
    "!unzip /content/street_labels2.zip -d /content/datasets/street/labels/train\n",
    "!unzip /content/street_labels3.zip -d /content/datasets/street/labels/train\n",
    "\n",
    "4) train.py 실행\n",
    "!cd yolov5; python train.py -h\n",
    "!cd yolov5; python train.py \\\n",
    "    --data '/content/yolov5/data/street.yaml' \\\n",
    "    --cfg '/content/yolov5/models/yolov5s.yaml' \\\n",
    "    --weights '/content/yolov5/pretrained/yolov5s.pt' \\\n",
    "    --epochs 1000 \\\n",
    "    --patience 7 \\\n",
    "    --img 640 \\\n",
    "    --project 'trained' \\\n",
    "    --name 'train_street' \\\n",
    "    --exist-ok\n",
    "    # --device cpu\n",
    "\n",
    "5) detect용 이미지 다운로드\n",
    "!wget -O /content/yolov5/data/images/street01.jpeg https://github.com/DrKAI/image/raw/main/001.jpeg\n",
    "!wget -O /content/yolov5/data/images/street02.jpg https://github.com/DrKAI/image/raw/main/14th_Street_2005.jpg\n",
    "!wget -O /content/yolov5/data/images/street03.jpg https://github.com/DrKAI/image/raw/main/street02.jpg\n",
    "!wget -O /content/yolov5/data/images/street04.jpg https://github.com/DrKAI/image/raw/main/street03.jpg\n",
    "!wget -O /content/yolov5/data/images/street05.jpg https://github.com/DrKAI/image/raw/main/street04.jpg\n",
    "!wget -O /content/yolov5/data/images/street06.jpg https://github.com/DrKAI/image/raw/main/street05.jpg\n",
    "\n",
    "\n",
    "6) detect.py 실행\n",
    "!cd yolov5; python detect.py -h\n",
    "\n",
    "!cd yolov5; python detect.py \\\n",
    "    --weights '/content/yolov5/trained/train_street/weights/best.pt' \\\n",
    "    --source '/content/yolov5/data/images/' \\\n",
    "    --project '/content/yolov5/detected' \\\n",
    "    --name 'images' \\\n",
    "    --img 640 \\\n",
    "    --conf-thres 0.25 \\\n",
    "    --iou-thres 0.5 \\\n",
    "    --line-thickness 2 \\\n",
    "    --exist-ok \n",
    "    # --device CPU\n",
    "\n",
    "7) Detect Image 살펴보기\n",
    "from IPython.display import Image\n",
    "from google.colab import files\n",
    "\n",
    "Image(filename='/content/yolov5/detected/images/street01.jpeg', width=640)\n",
    "\n",
    "## colab은 멀티 다운로드를 지원하지 않는다\n",
    "## 폴더를 압축하여 파일 하나로 만들고 다운로드 한다\n",
    "\n",
    "!zip -r /content/detected_images.zip /content/yolov5/detected/images\n",
    "\n",
    "files.download(filename='/content/detected_images.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706d8f3-326a-4946-891b-a470b77cfac7",
   "metadata": {},
   "source": [
    "## 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57fddd-9cc4-40fe-b90a-47dd69c00c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests 이용\n",
    "받아오는 문자열에 따라 두가지 방법으로 구분\n",
    "json 문자열로 받아서 파싱하는 방법 : 주로 동적 페이지 크롤링할때 사용\n",
    "html 문자열로 받아서 파싱하는 방법 : 주로 정적 페이지 크롤링할때 사용\n",
    "selenium 이용\n",
    "브라우져를 직접 열어서 데이터를 받는 방법\n",
    "크롤링 방법에 따른 속도\n",
    "requests json > requests html > selenium\n",
    "# summary\n",
    "# web : server-client : url\n",
    "# request, response : get,post\n",
    "# 웹서비스의 구조\n",
    "# 웹페이지의 종류\n",
    "# - 동적페이지 : URL 변경 X > 데이터 수정 : JSON : API\n",
    "# - 정적페이지 : URL 변경 O > 데이터 수정 : HTML : css selector > BeautifulSoup : select(), select_one()\n",
    "\n",
    "\n",
    "# html : 웹페이지에서 레이아웃, 텍스트 등의 데이터를 작성\n",
    "# 구성요소: document, element, tag, attr, text\n",
    "# element 계층적 구조\n",
    "# tag 종류 : p, span, ul, li, table, a, img, iframe, div\n",
    "\n",
    "# css selector : html의 element에 style을 적용시킬때 element를 선택하는 방법\n",
    "# element 선택 : tag(span), class(.), id(#), attr([value=\"no1\"])\n",
    "# n번째 element 선택 : .py:nth-child(2) : 2번째 엘리먼트중에 클래스가 py인 엘리먼트\n",
    "# 계층적 element 선택 : 모든 하위 엘리먼트 선택(.wrap p), 한단계 하위 엘리먼트 선택(.wrap > p), 여러개 선택(.no1, .no2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49620ab6-88c5-4ddc-8858-69529f3ea12a",
   "metadata": {},
   "source": [
    "### Selenium\n",
    "- 브라우져의 자동화 목적으로 만들어진 다양한 브라우져와 언어를 지원하는 라이브러리\n",
    "- 브라우져를 파이썬 코드로 컨트롤 해서 브라우져에 있는 데이터를 수집\n",
    "\n",
    "#### 크롤링 방법\n",
    "- 1. requests : json : 웹페이지의 API 트래픽을 분석해서 데이터 수집 : naver stock\n",
    "- 2. requests : json : 공식적으로 제공하는 API를 application key 받아서 데이터 수집 : naver api(papago, trend)\n",
    "- 3. requests : html, BeautifulSoup(css selector) : 웹페이지의 html 코드 받아서 데이터 수집 : gmarket\n",
    "- 4. selenium : browser - python : 브라우져를 파이썬 코드로 컨트롤 해서 데이터 수집 : ted\n",
    "- 크롤링할때 좋은 순서 : 2 > 1 > 3 > 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6973869f-8ad4-408b-86f5-05fb2098994b",
   "metadata": {},
   "source": [
    "### 동적페이지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0ee8b-075f-48c3-b624-7f1eb7f9f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 페이지 데이터 수집 프로세스\n",
    "# 1. 웹서비스 분석(개발자도구) : URL\n",
    "# 2. request(url, params, header) > response(json) : JSON(str)\n",
    "# 3. JSON(str) > list, dict > DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0f089-4c10-41a8-8129-205f475a03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "1) pc 웹페이지가 복잡하면 mobile 웹페이지에서 수집\n",
    "2) 서버에 데이터 요청 : request(url) > response : json(str)\n",
    "- response의 status code가 200이 나오는지 확인\n",
    "- 403이나 500이 나오면 request가 잘못되거나 web server에서 수집이 안되도록 설정이 된것임\n",
    "  -> header 설정 또는 selenium 사용\n",
    "- 200이 나오더라도 response 안에 있는 내용을 확인 > 확인하는 방법 : response.text[:200]\n",
    "3) 서버에서 받은 데이터 파싱(데이터 형태를 변경) : json(str) > list, dict > DataFrame\n",
    "4) 함수로 만들기\n",
    "\n",
    "def stock_price(pagesize, page, code=\"KOSPI\"):\n",
    "    \"\"\"This function is crawling stock price form naver webpage.\n",
    "    Params\n",
    "    ------\n",
    "    pagesize : int : one page size\n",
    "    page : int : page number\n",
    "    code : str : KOSPI or KOSDAQ\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    type : DataFrame : display date, price columns\n",
    "    \"\"\"\n",
    "    url = f\"https://m.stock.naver.com/api/index/{code}/price?pageSize={pagesize}&page={page}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return pd.DataFrame(data)[[\"localTradedAt\",\"closePrice\"]]\n",
    "\n",
    "kospi = stock_price(60,1,\"KOSPI\")\n",
    "kosdaq = stock_price(60,1,\"KOSDAQ\")\n",
    "\n",
    "# 데이터 전처리\n",
    "df = kospi.copy()\n",
    "df[\"kosdaq\"]=kosdaq[\"closePrice\"]\n",
    "df[\"usd\"] = usd['closePrice']\n",
    "df = df.rename(columns={\"closePrice\":\"kospi\"})\n",
    "df\n",
    "\n",
    "# docstring[\"\"\"\"\"\"] : 함수를 사용하는 방법을 문자열로 작성 \n",
    "#help()이용, Shift + tab\n",
    "help(stock_price)\n",
    "\n",
    "df = pd.DataFrame([{'age': 23},{'age': 36},{'age': 27}])  # 데이터프레임 만들기\n",
    "df\n",
    "\n",
    "@ 시각화\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 수집\n",
    "page_size = 60\n",
    "kospi_df = stock_price(\"KOSPI\", page_size=page_size)\n",
    "kosdaq_df = stock_price(\"KOSDAQ\", page_size=page_size)\n",
    "usd_df = exchage_rate(\"FX_USDKRW\", page_size=page_size)\n",
    "eur_df = exchage_rate(\"FX_EURKRW\", page_size=page_size)\n",
    "\n",
    "# 데이터 전처리 1 : 데이터 타입 변경\n",
    "print(kospi_df.dtypes)\n",
    "kospi_df[\"kospi\"] = kospi_df[\"closePrice\"].apply(lambda data: float(data.replace(\",\", \"\")))\n",
    "kospi_df = kospi_df.drop(columns=[\"closePrice\"])\n",
    "print(kospi_df.dtypes)\n",
    "\n",
    "kosdaq_df[\"kosdaq\"] = kosdaq_df[\"closePrice\"].apply(lambda data: float(data.replace(\",\", \"\")))\n",
    "usd_df[\"usd\"] = usd_df[\"closePrice\"].apply(lambda data: float(data.replace(\",\", \"\")))\n",
    "eur_df[\"eur\"] = eur_df[\"closePrice\"].apply(lambda data: float(data.replace(\",\", \"\")))\n",
    "\n",
    "kosdaq_df = kosdaq_df.drop(columns=[\"closePrice\"])\n",
    "usd_df = usd_df.drop(columns=[\"closePrice\"])\n",
    "eur_df = eur_df.drop(columns=[\"closePrice\"])\n",
    "\n",
    "# 데이터 전처리 2 : 날짜 데이터 맞추기 : merge\n",
    "merge_df_1 = pd.merge(kospi_df, kosdaq_df, on=\"localTradedAt\")\n",
    "merge_df_2 = pd.merge(merge_df_1, usd_df, on=\"localTradedAt\")\n",
    "merge_df_3 = pd.merge(merge_df_2, eur_df, on=\"localTradedAt\")\n",
    "merge_df = merge_df_3.copy()\n",
    "merge_df.tail(2)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(20, 5))\n",
    "columns = merge_df.columns[1:]\n",
    "for column in columns:\n",
    "    plt.plot(merge_df[\"localTradedAt\"], merge_df[column], label=column)\n",
    "\n",
    "xticks_count = 11\n",
    "plt.xticks(merge_df[\"localTradedAt\"][::int(len(merge_df) // xticks_count) + 1])\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "corr_df = merge_df[merge_df.columns[1:]].corr()\n",
    "corr_df\n",
    "\n",
    "# 결정계수 : r-squared \n",
    "# 1과 가까울수록 강한 관계, 0과 가까울수록 약한 관계\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.heatmap(corr_df**2, cmap=\"YlGnBu\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92a181-e776-4208-91a2-032e56cf19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼의 데이터 타입 변경 : str > float\n",
    "# df[column].apply() : 모든 데이터를 함수에 대입한 결과를 출력\n",
    "# apply(func) : 모든 데이터를 func을 적용시킨 결과 출력\n",
    "df.dtypes\n",
    "\n",
    "# 피어슨 상관계수 : df.corr()\n",
    "# 1과 가까울수록 강한 양의 상관관계를 갖는다.\n",
    "# -1과 가까울수록 강한 음의 상관관계를 갖는다.\n",
    "# 0과 가까울수록 관계가 없다.\n",
    "df[['kospi','kosdaq','usd']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58329ff-519b-4c70-bfbd-262752375141",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b48f4b-7dc6-485e-82b1-45e3e360447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "application programing interface\n",
    "api 를 사용해서 데이터를 수집하는것은 서비스에 데이터를 제공한는 공식적인 방법으로 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1f72e-7afc-42ce-a3ec-d487dbdb901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API를 이용한 데이터 수집\n",
    "# 1. APP 등록 : application key \n",
    "# 2. API 문서 : URL\n",
    "# 3. request(url, params, header(application key)) > response(json) : JSON(str)\n",
    "# 4. JSON(str) > list, dict > DataFrame or Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c258821c-0a5d-4f7f-88f2-523a3a5139de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68d416-17b4-40ce-9268-a47074cd698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID, CLIENT_SECRET = \"KE2M4YcO4Sv9P7HrFXJ1\", \"9X0zM51ZRf\"\n",
    "\n",
    "# json.dumps() : 인터넷 트래픽에서는 영문, 숫자, 특수문자만 사용가능\n",
    "# 한글과 같은 문자를 인코딩(영문,숫자,특수문자)\n",
    "txt= \"파이썬은 재미있습니다.\"\n",
    "url = \"https://openapi.naver.com/v1/papago/n2mt\" \n",
    "params = {\"source\": \"ko\", \"target\": \"en\", \"text\": txt}\n",
    "headers = {\"Content-Type\": \"application/json\", \n",
    "           \"X-Naver-Client-Id\": CLIENT_ID,\n",
    "           \"X-Naver-Client-Secret\": CLIENT_SECRET}\n",
    "\n",
    "response = requests.post(url, json.dumps(params),headers=headers)\n",
    "response\n",
    "\n",
    "response.text\n",
    "\n",
    "txt_en = response.json()[\"message\"][\"result\"][\"translatedText\"]\n",
    "txt_en\n",
    "\n",
    "# 이렇게 가져올수 있다[다음 환율]\n",
    "datas = response.json()[\"data\"]\n",
    "df = pd.DataFrame(datas)\n",
    "df.head(1)\n",
    "\n",
    "def translate(txt):\n",
    "    CLIENT_ID, CLIENT_SECRET = \"KE2M4YcO4Sv9P7HrFXJ1\",\"9X0zM51ZRf\" \n",
    "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
    "    params = {\"source\": \"ko\", \"target\": \"en\", \"text\": txt}\n",
    "    headers = {\"Content-Type\": \"application/json\", \n",
    "           \"X-Naver-Client-Id\": CLIENT_ID,\n",
    "           \"X-Naver-Client-Secret\": CLIENT_SECRET}\n",
    "    response = requests.post(url, json.dumps(params), headers=headers)\n",
    "    txt_en = response.json()[\"message\"][\"result\"][\"translatedText\"]\n",
    "    return txt_en\n",
    "\n",
    "txt= \"웹크롤링은 재미있습니다.\"\n",
    "txt_en = translate(txt)\n",
    "txt_en\n",
    "\n",
    "@ 한글 excel 파일을 영문 excel 파일로 변경\n",
    "\n",
    "%ls\n",
    "\n",
    "covid = pd.read_excel(\"covid.xlsx\")[[\"category\",\"title\"]]\n",
    "covid.tail(2)\n",
    "\n",
    "covid_en = covid[\"title\"].apply(translate)\n",
    "\n",
    "covid[\"title_en\"] = covid_en\n",
    "covid\n",
    "\n",
    "# utf-8-sig : excel에서 사용하는 인코딩 방식과 호환이 되는 utf-8인 인코딩 방식 \n",
    "covid.to_excel(\"covid_en.xlsx\", index = False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d8888-7d77-4ea1-9b61-173c3796e550",
   "metadata": {},
   "source": [
    "### 통합검색어 트렌드 api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ee8a0-4758-428d-a301-f2dbe2437d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. URL\n",
    "url = \"https://openapi.naver.com/v1/datalab/search\"\n",
    "\n",
    "# 2. request > response\n",
    "params = {\n",
    "    \"startDate\": \"2018-01-01\",\n",
    "    \"endDate\": \"2022-01-31\",\n",
    "    \"timeUnit\": \"month\",\n",
    "    \"keywordGroups\": [\n",
    "        {\"groupName\": \"트위터\", \"keywords\": [\"트위터\", \"트윗\"]},\n",
    "        {\"groupName\": \"페이스북\", \"keywords\": [\"페이스북\", \"페북\"]},\n",
    "        {\"groupName\": \"인스타그램\", \"keywords\": [\"인스타그램\", \"인스타\"]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-Naver-Client-Id\": CLIENT_ID,\n",
    "    \"X-Naver-Client-Secret\": CLIENT_SECRET,    \n",
    "}\n",
    "\n",
    "response = requests.post(url, data=json.dumps(params), headers=headers)\n",
    "response\n",
    "\n",
    "# 3. parsing\n",
    "datas = response.json()[\"results\"]\n",
    "\n",
    "# 4. preprocessing\n",
    "result_df = pd.concat(dfs, ignore_index=True)\n",
    "result_df.tail(2)\n",
    "\n",
    "pivot_df = result_df.pivot(\"period\", \"title\", \"ratio\")\n",
    "pivot_df.columns = [\"instagram\", \"twitter\", \"facebook\"]\n",
    "pivot_df.tail(2)\n",
    "\n",
    "# 5. visualization\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot_df.plot(figsize=(20, 5))\n",
    "plt.legend(loc=0)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8271533-a62e-415f-9a5b-7ac6fd1aa285",
   "metadata": {},
   "source": [
    "### 위도 경도로 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a584b0-0446-4bd9-a872-034d0a336b16",
   "metadata": {},
   "source": [
    "- 절차\n",
    "    - 동이름으로 위도 경도 구하기\n",
    "    - 위도 경도로 geohash 알아내기\n",
    "    - geohash로 매물 아이디 가져오기\n",
    "    - 매물 아이디로 매물 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bbc48-ffad-4cfd-9dd9-94e3a2c8a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 동이름으로 위도 경도 구하기\n",
    "addr = \"망원동\"\n",
    "url = f\"https://apis.zigbang.com/v2/search?leaseYn=N&q={addr}&serviceType=원룸\"\n",
    "response = requests.get(url)\n",
    "data = response.json()[\"items\"][0]\n",
    "lat, lng = data[\"lat\"], data[\"lng\"]\n",
    "lat, lng\n",
    "\n",
    "# 2. 위도 경도로 geohash 알아내기\n",
    "# install geohash2\n",
    "# !pip install geohash2\n",
    "import geohash2\n",
    "\n",
    "# precision이 커질수록 영역이 작아짐\n",
    "geohash = geohash2.encode(lat, lng, precision=5)\n",
    "geohash\n",
    "\n",
    "# 3. geohash로 매물 아이디 가져오기\n",
    "url = f\"https://apis.zigbang.com/v2/items?deposit_gteq=0&domain=zigbang\\\n",
    "&geohash={geohash}&needHasNoFiltered=true&rent_gteq=0&sales_type_in=전세|월세\\\n",
    "&service_type_eq=원룸\"\n",
    "response = requests.get(url)\n",
    "datas = response.json()[\"items\"]\n",
    "# len(datas), datas[0]\n",
    "ids = [data[\"item_id\"] for data in datas]\n",
    "len(ids), ids[:5]\n",
    "\n",
    "# 4. 매물 아이디로 매물 정보 가져오기\n",
    "# 1000개 넘어가면 나눠서 수집해야 함\n",
    "url = \"https://apis.zigbang.com/v2/items/list\"\n",
    "params = {\n",
    "    \"domain\": \"zigbang\",\n",
    "    \"withCoalition\": \"true\",\n",
    "    \"item_ids\": ids\n",
    "}\n",
    "response = requests.post(url, params)\n",
    "response\n",
    "\n",
    "datas = response.json()[\"items\"]\n",
    "df = pd.DataFrame(datas)\n",
    "df.tail(2)\n",
    "\n",
    "# 필요한 컬럼만 필터링\n",
    "columns = [\"item_id\", \"sales_type\", \"deposit\", \"rent\", \"size_m2\", \"floor\", \"building_floor\",\n",
    "           \"address1\", \"manage_cost\"]\n",
    "filtered_column_df = df[columns]\n",
    "filtered_column_df.tail(2)\n",
    "\n",
    "# 주소에 망원동이 있는 데이터만 필터링\n",
    "result_df = filtered_column_df[filtered_column_df[\"address1\"].str.contains(\"망원동\")]\n",
    "result_df = result_df.reset_index(drop=True)\n",
    "result_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f877474-7e76-4bf1-aa09-127db92a7c4b",
   "metadata": {},
   "source": [
    "### 이미지 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b357db-f6fb-4011-adf9-5c7f01eb8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, os\n",
    "\n",
    "# 1. 디렉토리 생성 : data\n",
    "path = \"data\"\n",
    "if not os.path.exists(\"data\"): # 디렉토리 존재 유무 확인\n",
    "    os.makedirs(path)\n",
    "    \n",
    "%ls\n",
    "# 2. csv 파일을 로드 : image link\n",
    "df = pd.read_csv(\"gmarket.csv\")\n",
    "df.tail(2)\n",
    "\n",
    "img_link = df.loc[0, 'img']\n",
    "img_link\n",
    "\n",
    "# 3. download images : requests\n",
    "response = requests.get(img_link)\n",
    "response\n",
    "\n",
    "with open(f'{path}/test.png', \"wb\") as file: # 파일저장 wb, 읽기는 rd\n",
    "    file.write(response.content)\n",
    "    \n",
    "%ls data\n",
    "\n",
    "# 4. display image : pillow\n",
    "from PIL import Image as pil\n",
    "pil.open(f'{path}/test.png') \n",
    "\n",
    "# 5. 여러개의 이미지 다운로드\n",
    "df[:3]\n",
    "for idx, data in df[:5].iterrows():\n",
    "    filename = '0' * (3 - len(str(idx))) + str(idx) + '.png'\n",
    "    print(idx, filename, data['img'])\n",
    "    response = requests.get(data['img'])\n",
    "    with open(f'{path}/{filename}', \"wb\") as file: # 파일저장 wb, 읽기는 rd\n",
    "        file.write(response.content)\n",
    "\n",
    "pil.open(f'{path}/004.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5772e5b-415e-4e75-8425-b9a8407e0bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af21c7-3a20-4620-9aed-2ec046660fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f23eb8-7d2a-4838-9529-e3894a6db0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74dd4d7-a4a9-45b4-bc67-27d3d69c4531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12574e-2655-46fa-99f8-66c8f0241808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
